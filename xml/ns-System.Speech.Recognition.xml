<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.2" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="ns-System.Speech.Recognition.xml" source-language="en-US" target-language="ja-JP">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-efd8310" tool-company="Microsoft" />
      <xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">5a83ea4b-dd12-480b-bfc8-267272ef1864be08311c812e33ac449fae40c2d2494af9dc7fe5.skl</xliffext:skl_file_name>
      <xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version>
      <xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">be08311c812e33ac449fae40c2d2494af9dc7fe5</xliffext:ms.openlocfilehash>
      <xliffext:ms.sourcegitcommit xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">df6cf590aa3087f6c7c202712eee781c6a3c8f96</xliffext:ms.sourcegitcommit>
      <xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">05/10/2018</xliffext:ms.lasthandoff>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>The <ph id="ph1">&lt;see cref="N:System.Speech.Recognition" /&gt;</ph> namespace contains Windows Desktop Speech technology types for implementing speech recognition.</source>
          <target state="translated"><ph id="ph1">&lt;see cref="N:System.Speech.Recognition" /&gt;</ph> 名前空間には、音声認識の実装に必要な Windows Desktop Speech テクノロジの型が含まれています。</target>       </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve" extradata="MT">
          <source>The Windows Desktop Speech Technology software offers a basic speech recognition infrastructure that digitizes acoustical signals, and recovers words and speech elements from audio input.</source>
          <target state="translated">Windows デスクトップ Speech 技術ソフトウェアは、音響の信号をデジタル化して、オーディオ入力からの単語と音声の要素を復旧する基本的な音声認識インフラストラクチャを提供します。</target>       </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve" extradata="MT">
          <source>Applications use the <ph id="ph1">&lt;xref:System.Speech.Recognition&gt;</ph> namespace to access and extend this basic speech recognition technology by defining algorithms for identifying and acting on specific phrases or word patterns, and by managing the runtime behavior of this speech infrastructure.</source>
          <target state="translated">アプリケーションを使用して、<ph id="ph1">&lt;xref:System.Speech.Recognition&gt;</ph>名前空間にアクセスし、識別し、特定の語句、単語パターンなどで機能するためのアルゴリズムを定義することで、この音声インフラストラクチャの実行時の動作を管理することによって、この基本的な音声認識のテクノロジを拡張します。</target>       </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve" extradata="MT">
          <source><bpt id="p1">**</bpt>Create Grammars<ept id="p1">**</ept></source>
          <target state="translated"><bpt id="p1">**</bpt>文法を作成します<ept id="p1">**</ept></target>       </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve" extradata="MT">
          <source>You create grammars, which consist of a set of rules or constraints, to define words and phrases that your application will recognize as meaningful input.</source>
          <target state="translated">一連のルールや制約、意味のある入力として、アプリケーションが認識できる語句を定義するので構成される文法を作成します。</target>       </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve" extradata="MT">
          <source>Using a constructor for the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> class, you can create a grammar object at runtime from <ph id="ph2">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> or <ph id="ph3">&lt;xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument&gt;</ph> instances, or from a file, a string, or a stream that contains a definition of a grammar.</source>
          <target state="translated">コンス トラクターを使用して、<ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph>クラスから実行時に文法オブジェクトを作成することができます<ph id="ph2">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph>または<ph id="ph3">&lt;xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument&gt;</ph>インスタンス、または、ファイル、文字列、または、文法の定義を含むストリーム。</target>       </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve" extradata="MT">
          <source>Using the <ph id="ph1">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.Choices&gt;</ph> classes, you can programmatically create grammars of low to medium complexity that can be used to perform recognition for many common scenarios.</source>
          <target state="translated">使用して、<ph id="ph1">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph>と<ph id="ph2">&lt;xref:System.Speech.Recognition.Choices&gt;</ph>クラス、多くの一般的なシナリオについて認識を実行するために使用される中程度の複雑さを低の文法プログラムで作成できます。</target>       </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve" extradata="MT">
          <source>To create grammars programmatically that conform to the <bpt id="p1">[</bpt>Speech Recognition Grammar Specification 1.0 (SRGS)<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=201761)</ept> and take advantage of the authoring flexibility of SRGS, use the types of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SrgsGrammar&gt;</ph> namespace.</source>
          <target state="translated">文法に準拠するプログラムを作成する、<bpt id="p1">[</bpt>音声認識の文法仕様 1.0 (SRGS)<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=201761)</ept>と SRGS のオーサリングの柔軟性を利用、および使用の種類、<ph id="ph1">&lt;xref:System.Speech.Recognition.SrgsGrammar&gt;</ph>名前空間。</target>       </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can also create XML-format SRGS grammars using any text editor and use the result to create <ph id="ph1">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument&gt;</ph> , or <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">任意のテキストを使用して XML 形式 SRGS 文法にエディターを作成して、作成する結果を使用することができますも<ph id="ph1">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph>、 <ph id="ph2">&lt;xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument&gt;</ph> 、または<ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph>オブジェクト。</target>       </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve" extradata="MT">
          <source>In addition, the <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph> class provides a special-case grammar to support a conventional dictation model.</source>
          <target state="translated">さらに、<ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph>クラスには、従来のディクテーション モデルをサポートするために特別なケースの文法が用意されています。</target>       </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve" extradata="MT">
          <source>See <bpt id="p1">[</bpt>Create Grammars<ept id="p1">](http://msdn.microsoft.com/library/dbea278c-21a5-4816-aee7-5fd88ef993dd)</ept> in the <bpt id="p2">[</bpt>System Speech Programming Guide for .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept> for more information and examples.</source>
          <target state="translated">参照してください<bpt id="p1">[</bpt>作成文法<ept id="p1">](http://msdn.microsoft.com/library/dbea278c-21a5-4816-aee7-5fd88ef993dd)</ept>で、<bpt id="p2">[</bpt>システム音声プログラミング ガイド .NET Framework 4.0 用<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept>詳細と例についてはします。</target>       </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve" extradata="MT">
          <source><bpt id="p1">**</bpt>Manage Speech Recognition Engines<ept id="p1">**</ept></source>
          <target state="translated"><bpt id="p1">**</bpt>音声認識エンジンを管理します。<ept id="p1">**</ept></target>       </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve" extradata="MT">
          <source>Instances of <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> supplied with <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects provide the primary access to the speech recognition engines of the Windows Desktop Speech Technology.</source>
          <target state="translated">インスタンス<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>と<ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>付属<ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph>オブジェクトが、音声認識エンジンに、Windows デスクトップ音声テクノロジのプライマリ アクセスを提供します。</target>       </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> class to create client applications that use the speech recognition technology provided by Windows, which you can configure through the <bpt id="p1">**</bpt>Control Panel<ept id="p1">**</ept>.</source>
          <target state="translated">使用することができます、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>クライアントを構成することができる Windows によって提供される音声認識のテクノロジを使用するアプリケーションを作成するクラス、<bpt id="p1">**</bpt>コントロール パネルの <ept id="p1">**</ept>です。</target>       </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve" extradata="MT">
          <source>Such applications accept input through a computer's default audio input mechanism.</source>
          <target state="translated">このようなアプリケーションでは、入力を受け入れて、コンピューターの既定のオーディオ入力メカニズムを利用します。</target>       </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more control over the configuration and type of recognition engine, build an application using <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, which runs in-process.</source>
          <target state="translated">構成と認識エンジンの種類をより細かく制御は、ビルドを使用して、アプリケーション<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>インプロセスで実行します。</target>       </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve" extradata="MT">
          <source>Using the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> class, you can also dynamically select audio input from devices, files, or streams.</source>
          <target state="translated">使用して、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>クラス、オーディオ デバイス、ファイル、またはストリームからの入力を動的に選択できます。</target>       </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve" extradata="MT">
          <source>See <bpt id="p1">[</bpt>Initialize and Manage a Speech Recognition Engine<ept id="p1">](http://msdn.microsoft.com/library/6eed5b59-1258-4013-8a4c-a1ddabd93ae4)</ept> in the <bpt id="p2">[</bpt>System Speech Programming Guide for .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept> for more information.</source>
          <target state="translated">参照してください<bpt id="p1">[</bpt>初期化し、音声認識エンジンの管理<ept id="p1">](http://msdn.microsoft.com/library/6eed5b59-1258-4013-8a4c-a1ddabd93ae4)</ept>で、<bpt id="p2">[</bpt>システム音声プログラミング ガイド .NET Framework 4.0 用<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept>詳細についてはします。</target>       </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve" extradata="MT">
          <source><bpt id="p1">**</bpt>Respond to Events<ept id="p1">**</ept></source>
          <target state="translated"><bpt id="p1">**</bpt>イベントに応答します。<ept id="p1">**</ept></target>       </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve" extradata="MT">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> objects generate events in response to audio input to the speech recognition engine.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> および<ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>オブジェクトは、音声認識エンジンにオーディオの入力への応答内のイベントを生成します。</target>       </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">`AudioLevelUpdated`</ph>, <ph id="ph2">`AudioSignalProblemOccurred`</ph>, <ph id="ph3">`AudioStateChanged`</ph> events are raised in response to changes in the incoming signal.</source>
          <target state="translated"><ph id="ph1">`AudioLevelUpdated`</ph>、 <ph id="ph2">`AudioSignalProblemOccurred`</ph>、<ph id="ph3">`AudioStateChanged`</ph>入力信号の変更に応答でイベントが発生します。</target>       </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">`SpeechDetected`</ph> event is raised when the speech recognition engine identifies incoming audio as speech.</source>
          <target state="translated"><ph id="ph1">`SpeechDetected`</ph>イベントは、音声認識エンジンが音声入力として受信オーディオを識別します。</target>       </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve" extradata="MT">
          <source>The speech recognition engine raises the <ph id="ph1">`SpeechRecognized`</ph> event when it matches speech input to one of its loaded grammars, and raises the <ph id="ph2">`SpeechRecognitionRejected`</ph> when speech input does not match any of its loaded grammars.</source>
          <target state="translated">音声認識エンジンを発生させる、<ph id="ph1">`SpeechRecognized`</ph>の読み込まれた文法の 1 つに音声入力に一致し、発生したときにイベント、<ph id="ph2">`SpeechRecognitionRejected`</ph>ときに音声入力と一致しません、読み込まれた文法のいずれか。</target>       </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve" extradata="MT">
          <source>Other types of events include the <ph id="ph1">`LoadGrammarCompleted`</ph> event which a speech recognition engine raises when it has loaded a grammar.</source>
          <target state="translated">その他の種類イベントにはが含まれて、<ph id="ph1">`LoadGrammarCompleted`</ph>文法が読み込まれたときに、音声認識エンジンが発生するイベントです。</target>       </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> is exclusive to the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> class, which raises the event when the state of Windows Speech Recognition changes.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph>が専用で、<ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>クラスは、Windows 音声認識の状態が変更されたときにイベントを発生させます。</target>       </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can register to be notified for events that the speech recognition engine raises and create handlers using the <ph id="ph1">`EventsArgs`</ph> classes associated with each of these events to program your application's behavior when an event is raised.</source>
          <target state="translated">音声認識エンジンを発生させるイベントの通知を受け取るしを使用してハンドラーを作成するを登録することができます、<ph id="ph1">`EventsArgs`</ph>のイベントが発生したときに、アプリケーションの動作をプログラムするには、各イベントに関連付けられているクラスです。</target>       </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve" extradata="MT">
          <source>See <bpt id="p1">[</bpt>Using Speech Recognition Events<ept id="p1">](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482)</ept> in the <bpt id="p2">[</bpt>System Speech Programming Guide for .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept> for more information.</source>
          <target state="translated">参照してください<bpt id="p1">[</bpt>音声認識イベントを使用した<ept id="p1">](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482)</ept>で、<bpt id="p2">[</bpt>システム音声プログラミング ガイド .NET Framework 4.0 用<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept>詳細についてはします。</target>       </trans-unit>
      </group>
    </body>
  </file>
</xliff>