<Type Name="RecognizerState" FullName="System.Speech.Recognition.RecognizerState">
  <Metadata><Meta Name="ms.openlocfilehash" Value="f5b640ed1cb602559a7f842753c580aa066c67e8" /><Meta Name="ms.sourcegitcommit" Value="434f60616a9793fa8436744549fc856e94f7a648" /><Meta Name="ms.translationtype" Value="MT" /><Meta Name="ms.contentlocale" Value="ja-JP" /><Meta Name="ms.lasthandoff" Value="08/25/2018" /><Meta Name="ms.locfileid" Value="37756178" /></Metadata><TypeSignature Language="C#" Value="public enum RecognizerState" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi sealed RecognizerState extends System.Enum" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.RecognizerState" />
  <TypeSignature Language="VB.NET" Value="Public Enum RecognizerState" />
  <TypeSignature Language="C++ CLI" Value="public enum class RecognizerState" />
  <TypeSignature Language="F#" Value="type RecognizerState = " />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Enum</BaseTypeName>
  </Base>
  <Docs>
    <summary>認識エンジンの状態の値を列挙します。</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <xref:System.Speech.Recognition.RecognizerState> 使用してクライアントの既定の音声認識エンジンの実行中の状態をカプセル化<xref:System.Speech.Recognition.SpeechRecognizer>Windows Desktop Speech Recognition テクノロジ サービスにアクセスします。  
  
 アプリケーションとデスクトップの認識エンジンの現在の状態を取得できます、<xref:System.Speech.Recognition.RecognizerState>オブジェクト クエリを実行して、<xref:System.Speech.Recognition.SpeechRecognizer.State%2A>プロパティを<xref:System.Speech.Recognition.SpeechRecognizer>インスタンス。  アプリケーションのクエリを変更後のデスクトップの認識エンジンの状態を取得することができます、<xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A>のプロパティ、<xref:System.Speech.Recognition.StateChangedEventArgs>のハンドラーに渡されるオブジェクト<xref:System.Speech.Recognition.SpeechRecognizer.StateChanged>イベント。  
  
> [!NOTE]
>  <xref:System.Speech.Recognition.SpeechRecognitionEngine> インスタンスでプロセスを実行して、実行中の状態は、アプリケーションの管理。 そのため、<xref:System.Speech.Recognition.SpeechRecognitionEngine>を返すプロパティが含まれていない、<xref:System.Speech.Recognition.RecognizerState>オブジェクト。  
  
 デスクトップの音声認識のサーバーの状態は読み取り専用プロパティで、プログラムによって制御されることはできません。 ユーザーが音声認識のユーザー インターフェイス (UI) を使用して、共有音声認識エンジンの状態を変更または、**音声認識**メンバーは、Windows の**コントロール パネルの **します。  
  
 両方の**で**と**スリープ**音声認識の UI での設定に対応して、`Listening`状態。 **オフ**音声認識の UI での設定は停止に対応します。  
  
 <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> 受信および音声入力を処理する共有音声認識エンジンの準備状態に影響するその他のプロパティです。 使用することができます<xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>共有音声認識エンジンの文法が非アクティブの認識にいるかどうかを制御します。 ただし、変更、<xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>プロパティも何も起こりません、<xref:System.Speech.Recognition.RecognizerState>プロパティ。  
  
 説明、サポートされているカルチャとオーディオの形式では、認識エンジンの名前などの情報がカプセル化、<xref:System.Speech.Recognition.RecognizerInfo>型。  
  
   
  
## Examples  
 アプリケーションがのハンドラーの実装で認識エンジンの状態を表示する次の例で、<xref:System.Speech.Recognition.SpeechRecognizer.StateChanged>イベント。  
  
```  
  
_recognizer.StateChanged +=  
    delegate(object sender, StateChangedEventArgs eventArgs) {  
        _recognizerStateLabel.Text = "Speech Recognizer State: " + eventArgs.RecognizerState.ToString();  
    };  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="P:System.Speech.Recognition.StateChangedEventArgs.RecognizerState" />
    <altmember cref="T:System.Speech.Recognition.SpeechRecognizer" />
    <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Enabled" />
    <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.State" />
    <altmember cref="T:System.Speech.Recognition.StateChangedEventArgs" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.StateChanged" />
  </Docs>
  <Members>
    <Member MemberName="Listening">
      <MemberSignature Language="C#" Value="Listening" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype System.Speech.Recognition.RecognizerState Listening = int32(1)" />
      <MemberSignature Language="DocId" Value="F:System.Speech.Recognition.RecognizerState.Listening" />
      <MemberSignature Language="VB.NET" Value="Listening" />
      <MemberSignature Language="C++ CLI" Value="Listening" />
      <MemberSignature Language="F#" Value="Listening = 1" Usage="System.Speech.Recognition.RecognizerState.Listening" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizerState</ReturnType>
      </ReturnValue>
      <MemberValue>1</MemberValue>
      <Docs>
        <summary>認識エンジンはオーディオ入力を受信して分析できます。</summary>
      </Docs>
    </Member>
    <Member MemberName="Stopped">
      <MemberSignature Language="C#" Value="Stopped" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype System.Speech.Recognition.RecognizerState Stopped = int32(0)" />
      <MemberSignature Language="DocId" Value="F:System.Speech.Recognition.RecognizerState.Stopped" />
      <MemberSignature Language="VB.NET" Value="Stopped" />
      <MemberSignature Language="C++ CLI" Value="Stopped" />
      <MemberSignature Language="F#" Value="Stopped = 0" Usage="System.Speech.Recognition.RecognizerState.Stopped" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizerState</ReturnType>
      </ReturnValue>
      <MemberValue>0</MemberValue>
      <Docs>
        <summary>認識エンジンは、オーディオ入力を受信または分析していません。</summary>
      </Docs>
    </Member>
  </Members>
</Type>