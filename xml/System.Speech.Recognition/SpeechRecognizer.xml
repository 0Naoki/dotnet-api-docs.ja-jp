<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.2" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="SpeechRecognizer.xml" source-language="en-US" target-language="ja-JP">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-15c36f0" tool-company="Microsoft" />
      <xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">02cd5861-7ce2-4a82-b358-31f8435a0ac5bc77257cd77c3fc2c078698df4cc6e968d3bf09a.skl</xliffext:skl_file_name>
      <xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version>
      <xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">bc77257cd77c3fc2c078698df4cc6e968d3bf09a</xliffext:ms.openlocfilehash>
      <xliffext:ms.sourcegitcommit xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">d31dc2ede16f6f7bc64e90d9f897ff54c4e3869b</xliffext:ms.sourcegitcommit>
      <xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">04/03/2018</xliffext:ms.lasthandoff>
      <xliffext:moniker_ids xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">netframework-4.5.1,netframework-4.5.2,netframework-4.5,netframework-4.6.1,netframework-4.6.2,netframework-4.6,netframework-4.7.1,netframework-4.7</xliffext:moniker_ids>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Provides access to the shared speech recognition service available on the Windows desktop.</source>
          <target state="translated">Windows デスクトップで使用できる共有音声認識サービスへのアクセスを提供します。</target>       </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Applications use the shared recognizer to access Windows Speech Recognition.</source>
          <target state="translated">アプリケーションは、Windows 音声認識にアクセスするのに、共有認識エンジンを使用します。</target>       </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> object to add to the Windows speech user experience.</source>
          <target state="translated">使用して、 <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> Windows 音声ユーザー エクスペリエンスに追加するオブジェクト。</target>       </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>This class provides control over various aspects of the speech recognition process:</source>
          <target state="translated">このクラスは、音声認識プロセスのさまざまな側面を制御を提供します。</target>       </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To manage speech recognition grammars, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A&gt;</ph>, and <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A&gt;</ph>.</source>
          <target state="translated">音声認識の文法を管理するを使用して、 <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A&gt;</ph>、 <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph>、 <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A&gt;</ph>、 <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A&gt;</ph>、および<ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A&gt;</ph>です。</target>       </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To get information about current speech recognition operations, subscribe to the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>’s <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> events.</source>
          <target state="translated">情報を取得する現在の音声認識操作、サブスクライブ、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>の<ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>、 <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>、 <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>、および<ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph>イベント。</target>       </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To view or modify the number of alternate results the recognizer returns, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A&gt;</ph> property.</source>
          <target state="translated">を表示または認識エンジンが返す代替結果の数を変更するには、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A&gt;</ph>プロパティです。</target>       </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The recognizer returns recognition results in a <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object.</source>
          <target state="translated">認識エンジンで認識の結果が返されます、<ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph>オブジェクト。</target>       </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To access or monitor the state of the shared recognizer, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph>, <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph>, <ph id="ph6">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph>, and <ph id="ph7">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> properties and the <ph id="ph8">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated&gt;</ph>, <ph id="ph9">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred&gt;</ph>, <ph id="ph10">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged&gt;</ph>, and <ph id="ph11">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> events.</source>
          <target state="translated">アクセスまたは、共有認識エンジンの状態を監視、使用、 <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph>、 <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph>、 <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph>、 <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph>、 <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph>、 <ph id="ph6">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph>、および<ph id="ph7">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph>プロパティおよび<ph id="ph8">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated&gt;</ph>、 <ph id="ph9">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred&gt;</ph>、 <ph id="ph10">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged&gt;</ph>、および<ph id="ph11">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph>イベント。</target>       </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To synchronize changes to the recognizer, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">認識エンジンへの変更を同期するために使用して、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph>メソッドです。</target>       </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The shared recognizer uses more than one thread to perform tasks.</source>
          <target state="translated">共有認識エンジンでは、複数のスレッドを使用して、タスクを実行します。</target>       </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To emulate input to the shared recognizer, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> methods.</source>
          <target state="translated">使用して、共有認識エンジンへの入力をエミュレートするために、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph>と<ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph>メソッドです。</target>       </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The configuration of Windows Speech Recognition is managed by the use of the <bpt id="p1">**</bpt>Speech Properties<ept id="p1">**</ept> dialog in the <bpt id="p2">**</bpt>Control Panel<ept id="p2">**</ept>.</source>
          <target state="translated">Windows 音声認識の構成が使用することで管理されている、<bpt id="p1">**</bpt>音声プロパティ<ept id="p1">**</ept>] ダイアログ ボックス、<bpt id="p2">**</bpt>コントロール パネルの [<ept id="p2">**</ept>です。</target>       </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>This interface is used to select the default desktop speech recognition engine and language, the audio input device, and the sleep behavior of speech recognition.</source>
          <target state="translated">このインターフェイスを使用すると、既定のデスクトップの音声認識エンジンと言語、オーディオ入力デバイス、および音声認識のスリープ状態の動作を選択します。</target>       </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If the configuration of Windows Speech Recognition is changed while the application is running, (for instance, if speech recognition is disabled or the input language is changed), the change affects all <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> objects.</source>
          <target state="translated">アプリケーションの実行中に、(たとえば、音声認識が無効か、入力言語が変更された) Windows 音声認識の構成が変更された場合、すべての変更に影響<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>オブジェクト。</target>       </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To create an in-process speech recognizer that is independent of Windows Speech Recognition, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> class.</source>
          <target state="translated">Windows 音声認識から独立しているプロセスで音声認識エンジンを作成するには、使用、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>クラスです。</target>       </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Always call <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A&gt;</ph> before you release your last reference to the speech recognizer.</source>
          <target state="translated">常に呼び出す<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A&gt;</ph>音声認識エンジンへの参照を解放する前にします。</target>       </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Otherwise, the resources it is using will not be freed until the garbage collector calls the recognizer object's <ph id="ph1">`Finalize`</ph> method.</source>
          <target state="translated">それ以外の場合、使用されているリソースは解放されませんガベージ コレクターは、認識エンジン オブジェクトのまで<ph id="ph1">`Finalize`</ph>メソッドです。</target>       </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">次の例は、音声認識の文法を読み込んで、非同期エミュー レートされた入力、関連付けられている認識の結果、音声認識エンジンによって生成される関連付けられたイベントを説明するコンソール アプリケーションの一部です。</target>       </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Windows 音声認識が実行されていない場合、このアプリケーションの起動と Windows 音声認識が開始もします。</target>       </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> always returns null.</source>
          <target state="translated">Windows 音声認識がの場合、<bpt id="p1">**</bpt>休止中<ept id="p1">**</ept>状態にある場合、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph>常に null を返します。</target>       </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.#ctor">
          <source>Initializes a new instance of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> class.</source>
          <target state="translated"><ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> クラスの新しいインスタンスを初期化します。</target>       </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.#ctor">
          <source>Each <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> object maintains a separate set of speech recognition grammars.</source>
          <target state="translated">各<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>オブジェクトが別の音声認識の文法のセットを保持します。</target>       </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.#ctor">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">次の例は、音声認識の文法を読み込んで、非同期エミュー レートされた入力、関連付けられている認識の結果、音声認識エンジンによって生成される関連付けられたイベントを説明するコンソール アプリケーションの一部です。</target>       </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.#ctor">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Windows 音声認識が実行されていない場合、このアプリケーションの起動と Windows 音声認識が開始もします。</target>       </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.#ctor">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> always returns null.</source>
          <target state="translated">Windows 音声認識がの場合、<bpt id="p1">**</bpt>休止中<ept id="p1">**</ept>状態にある場合、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph>常に null を返します。</target>       </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioFormat">
          <source>Gets the format of the audio being received by the speech recognizer.</source>
          <target state="translated">音声認識エンジンによって受け取られるオーディオの形式を取得します。</target>       </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioFormat">
          <source>The audio input format for the speech recognizer, or <ph id="ph1">&lt;see langword="null" /&gt;</ph> if the input to the recognizer is not configured.</source>
          <target state="translated">音声認識エンジンのオーディオ入力形式、または認識エンジンへの入力が構成されていない場合は <ph id="ph1">&lt;see langword="null" /&gt;</ph>。</target>       </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioLevel">
          <source>Gets the level of the audio being received by the speech recognizer.</source>
          <target state="translated">音声認識エンジンによって受け取られるオーディオのレベルを取得します。</target>       </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioLevel">
          <source>The audio level of the input to the speech recognizer, from 0 through 100.</source>
          <target state="translated">音声認識エンジンへの入力のオーディオ レベル (0 ～ 100)。</target>       </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>Occurs when the shared recognizer reports the level of its audio input.</source>
          <target state="translated">共有認識機能がオーディオ入力のレベルを報告すると発生します。</target>       </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>The recognizer raises this event multiple times per second.</source>
          <target state="translated">認識エンジンは、1 秒間に複数回、このイベントを発生させます。</target>       </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>The frequency with which the event is raised depends on the computer on which the application is running.</source>
          <target state="translated">イベントが発生する頻度は、アプリケーションが実行されているコンピューターによって異なります。</target>       </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>To get the audio level at the time of the event, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt;</ph>.</source>
          <target state="translated">イベントの時点で、オーディオ レベルを取得する、 <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A&gt;</ph> 、関連するプロパティ<ph id="ph2">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt;</ph>です。</target>       </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>To get the current audio level of the input to the recognizer, use the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph> property.</source>
          <target state="translated">認識エンジンへの入力の現在のオーディオ レベルを取得するには、認識エンジンを使用<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph>プロパティです。</target>       </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>When you create a delegate for an <ph id="ph1">`AudioLevelUpdated`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">デリゲートを作成する場合、<ph id="ph1">`AudioLevelUpdated`</ph>イベント、イベントを処理するメソッドを指定します。</target>       </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</target>       </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</target>       </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">イベント ハンドラー デリゲートの詳細については、次を参照してください。<bpt id="p1">[</bpt>イベントとデリゲート<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>です。</target>       </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>The following example adds a handler for the <ph id="ph1">`AudioLevelUpdated`</ph> event to a <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> object.</source>
          <target state="translated">次の例は、ハンドラーを追加、<ph id="ph1">`AudioLevelUpdated`</ph>イベントを<ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>オブジェクト。</target>       </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated">
          <source>The handler outputs the new audio level to the console.</source>
          <target state="translated">ハンドラーは、コンソールに新しいオーディオ レベルを出力します。</target>       </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>Gets the current location in the audio stream being generated by the device that is providing input to the speech recognizer.</source>
          <target state="translated">音声認識エンジンに入力を提供しているデバイスによって生成されているオーディオ ストリーム内の現在の位置を取得します。</target>       </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>The current location in the speech recognizer's audio input stream through which it has received input.</source>
          <target state="translated">入力を受け取った音声認識エンジンのオーディオ入力ストリームの現在の位置。</target>       </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>The shared recognizer receives input while the desktop speech recognition is running.</source>
          <target state="translated">デスクトップの音声認識が実行中に、共有認識エンジンは入力を受け取ります。</target>       </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>The <ph id="ph1">`AudioPosition`</ph> property references the input device's position in its generated audio stream.</source>
          <target state="translated"><ph id="ph1">`AudioPosition`</ph>プロパティは、生成されたオーディオ ストリーム内の入力デバイスの位置を参照します。</target>       </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>By contrast, the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> property references the recognizer's position in processing audio input.</source>
          <target state="translated">これに対し、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph>プロパティは、オーディオ入力の処理の認識エンジンの位置を参照します。</target>       </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>These positions can be different.</source>
          <target state="translated">これらの位置は別にすることはできます。</target>       </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>For example, if the recognizer has received input for which it has not yet generated a recognition result then the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> property is less than the value of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> property.</source>
          <target state="translated">たとえば、認識エンジンが受信した場合どの it されていない入力が、認識結果が次の値を生成、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph>プロパティは、の値より小さい、<ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph>プロパティです。</target>       </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>In the following example, the shared speech recognizer uses a dictation grammar to match speech input.</source>
          <target state="translated">次の例では、共有音声認識エンジンは、音声入力に一致するのに、ディクテーション文法を使用します。</target>       </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition">
          <source>A handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> event writes to the console the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph>, and  <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph> when the speech recognizer detects speech at its input.</source>
          <target state="translated">ハンドラーを<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>イベントは、コンソールを書き込みます、 <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph>、 <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph>、および<ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph>音声認識エンジンが入力に音声を検出したときにします。</target>       </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>Occurs when the recognizer encounters a problem in the audio signal.</source>
          <target state="translated">認識機能がオーディオ信号で問題を検出したときに発生します。</target>       </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>To get which problem occurred, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt;</ph>.</source>
          <target state="translated">どのような問題が発生させるを使用して、 <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A&gt;</ph> 、関連するプロパティ<ph id="ph2">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt;</ph>です。</target>       </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>When you create a delegate for an <ph id="ph1">`AudioSignalProblemOccurred`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">デリゲートを作成する場合、<ph id="ph1">`AudioSignalProblemOccurred`</ph>イベント、イベントを処理するメソッドを指定します。</target>       </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</target>       </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</target>       </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">イベント ハンドラー デリゲートの詳細については、次を参照してください。<bpt id="p1">[</bpt>イベントとデリゲート<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>です。</target>       </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred">
          <source>The following example defines an event handler that gathers information about an <ph id="ph1">`AudioSignalProblemOccurred`</ph> event.</source>
          <target state="translated">次の例に関する情報を収集するイベント ハンドラーを定義する、<ph id="ph1">`AudioSignalProblemOccurred`</ph>イベント。</target>       </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioState">
          <source>Gets the state of the audio being received by the speech recognizer.</source>
          <target state="translated">音声認識エンジンによって受け取られるオーディオの状態を取得します。</target>       </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.AudioState">
          <source>The state of the audio input to the speech recognizer.</source>
          <target state="translated">音声レコグナイザーへのオーディオ入力の状態。</target>       </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>Occurs when the state changes in the audio being received by the recognizer.</source>
          <target state="translated">オーディオの状態変化が認識機能によって受け取られると発生します。</target>       </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>To get the audio state at the time of the event, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs&gt;</ph>.</source>
          <target state="translated">イベントの時点でオーディオの状態を取得する、 <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A&gt;</ph> 、関連するプロパティ<ph id="ph2">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs&gt;</ph>です。</target>       </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>To get the current audio state of the input to the recognizer, use the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph> property.</source>
          <target state="translated">認識エンジンへの入力の現在のオーディオ状態を取得するには、使用、認識エンジンの<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph>プロパティです。</target>       </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>For more information about audio state, see the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> enumeration.</source>
          <target state="translated">オーディオの状態に関する詳細については、次を参照してください。、<ph id="ph1">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph>列挙します。</target>       </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>When you create a delegate for an <ph id="ph1">`AudioStateChanged`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">デリゲートを作成する場合、<ph id="ph1">`AudioStateChanged`</ph>イベント、イベントを処理するメソッドを指定します。</target>       </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</target>       </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</target>       </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">イベント ハンドラー デリゲートの詳細については、次を参照してください。<bpt id="p1">[</bpt>イベントとデリゲート<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>です。</target>       </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged">
          <source>The following example uses a handler for the <ph id="ph1">`AudioStateChanged`</ph> event to write the recognizer's new <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph> to the console each time it changes using a member of the <ph id="ph3">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> enumeration.</source>
          <target state="translated">次の例のハンドラーを使用して、 <ph id="ph1">`AudioStateChanged`</ph> 、認識エンジンを書き込むイベントの新しい<ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph>コンソールに変更されるたびのメンバーを使用して、<ph id="ph3">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph>列挙します。</target>       </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Disposes the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object.</source>
          <target state="translated"><ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> オブジェクトを破棄します。</target>       </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.Dispose">
          <source>Disposes the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object.</source>
          <target state="translated"><ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> オブジェクトを破棄します。</target>       </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.Dispose(System.Boolean)">
          <source><ph id="ph1">&lt;see langword="true" /&gt;</ph> to release both managed and unmanaged resources; <ph id="ph2">&lt;see langword="false" /&gt;</ph> to release only unmanaged resources.</source>
          <target state="translated">マネージ リソースとアンマネージ リソースの両方を解放する場合は <ph id="ph1">&lt;see langword="true" /&gt;</ph>。アンマネージ リソースだけを解放する場合は <ph id="ph2">&lt;see langword="false" /&gt;</ph>。</target>       </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.Dispose(System.Boolean)">
          <source>Disposes the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object and releases resources used during the session.</source>
          <target state="translated"><ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> オブジェクトを破棄し、セッション中に使用するリソースを解放します。</target>       </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Emulates input to the shared speech recognizer, using text instead of audio for synchronous speech recognition.</source>
          <target state="translated">同期音声認識に音声ではなくテキストを使用して、共有音声認識エンジンに対する入力をエミュレートします。</target>       </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>These methods bypass the system audio input.</source>
          <target state="translated">これらのメソッドは、システムのオーディオ入力をバイパスします。</target>       </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>This can be helpful when you are testing or debugging an application or grammar.</source>
          <target state="translated">これは、ことができますをテストまたはアプリケーションまたは文法をデバッグするとき。</target>       </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then these methods return <ph id="ph1">`null`</ph>.</source>
          <target state="translated">Windows 音声認識がの場合、<bpt id="p1">**</bpt>休止中<ept id="p1">**</ept>状態にある場合、これらのメソッドを返します<ph id="ph1">`null`</ph>です。</target>       </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The shared recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> events as if the recognition operation is not emulated.</source>
          <target state="translated">共有認識エンジンが発生し、 <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>、 <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>、 <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>、および<ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph>イベント認識操作がエミュレートされていない場合と同様です。</target>       </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The recognizer ignores new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">認識エンジンでは、新しい行と余分な空白は無視されます、リテラルの入力として区切り記号を扱います。</target>       </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object generated by the shared recognizer in response to emulated input has a value of <ph id="ph2">`null`</ph> for its <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph> property.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph>エミュー レートされた入力に応答することで、共有の認識エンジンによって生成されたオブジェクトの値を持つ<ph id="ph2">`null`</ph>の<ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph>プロパティです。</target>       </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To emulate asynchronous recognition, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> method.</source>
          <target state="translated">非同期の認識をエミュレートするために使用して、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph>メソッドです。</target>       </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>The input for the recognition operation.</source>
          <target state="translated">認識操作の入力。</target>       </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>Emulates input of a phrase to the shared speech recognizer, using text instead of audio for synchronous speech recognition.</source>
          <target state="translated">同期音声認識に音声ではなくテキストを使用して、共有音声認識エンジンに対する語句の入力をエミュレートします。</target>       </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>The recognition result for the recognition operation, or <ph id="ph1">&lt;see langword="null" /&gt;</ph>, if the operation is not successful or Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state.</source>
          <target state="translated">認識操作の認識結果。操作に成功しなかった場合や、Windows の音声認識が<bpt id="p1">**</bpt>スリープ<ept id="p1">**</ept>状態である場合は <ph id="ph1">&lt;see langword="null" /&gt;</ph>。</target>       </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case and character width when applying grammar rules to the input phrase.</source>
          <target state="translated">Vista および Windows 7 に付属しているレコグナイザーは、大文字小文字を区別し、入力の語句に文法ルールを適用するときに幅を文字です。</target>       </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>For more information about this type of comparison, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration values <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> and <ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>.</source>
          <target state="translated">この種類の比較の詳細については、次を参照してください。、<ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph>列挙値<ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph>と<ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>です。</target>       </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
          <target state="translated">認識は、新しい行と余分な空白を無視し、リテラルの入力として句読点を扱います。</target>       </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>The following example loads a sample grammar to the shared recognizer and emulates input to the recognizer.</source>
          <target state="translated">次の例、共有認識エンジンにサンプルの文法を読み込んで、認識エンジンへの入力をエミュレートします。</target>       </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Windows 音声認識が実行されていない場合、このアプリケーションの起動と Windows 音声認識が開始もします。</target>       </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> always returns null.</source>
          <target state="translated">Windows 音声認識がの場合、<bpt id="p1">**</bpt>休止中<ept id="p1">**</ept>状態にある場合、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph>常に null を返します。</target>       </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>An array of word units that contains the input for the recognition operation.</source>
          <target state="translated">認識操作のための必要を格納する単語単位の配列。</target>       </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">エミュレートされた認識操作に使用する比較の種類を示す列挙値のビットごとの組み合わせ。</target>       </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>Emulates input of specific words to the shared speech recognizer, using text instead of audio for synchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the words and the loaded speech recognition grammars.</source>
          <target state="translated">同期音声認識にオーディオではなくテキストを使用して、共有された音声認識エンジンに対する特定の語の入力をエミュレートし、語と読み込まれている音声認識文法との間で認識エンジンが Unicode 比較をどのように行うかを指定します。</target>       </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognition result for the recognition operation, or <ph id="ph1">&lt;see langword="null" /&gt;</ph>, if the operation is not successful or Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state.</source>
          <target state="translated">認識操作の認識結果。操作に成功しなかった場合や、Windows の音声認識が<bpt id="p1">**</bpt>スリープ<ept id="p1">**</ept>状態である場合は <ph id="ph1">&lt;see langword="null" /&gt;</ph>。</target>       </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>This method creates a <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object using the information provided in the <ph id="ph2">`wordUnits`</ph> parameter.</source>
          <target state="translated">このメソッドを作成、<ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph>オブジェクトで提供される情報を使用して、<ph id="ph2">`wordUnits`</ph>パラメーター。</target>       </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizer uses the <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">認識エンジンを使用して、<ph id="ph1">`compareOptions`</ph>ときに適用される文法ルール語句を入力します。</target>       </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
          <target state="translated">Vista および Windows 7 に付属しているレコグナイザーが場合は、大文字小文字を区別、<ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph>または<ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph>値が存在します。</target>       </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">認識は、常に文字幅を無視し、カナ型を無視することはありません。</target>       </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">レコグナイザーは、新しい行と余分な空白を無視する、リテラルの入力として区切り記号を扱います。</target>       </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
          <target state="translated">詳細については、文字幅、ひらがなとカタカナは、次を参照してください。、<ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph>列挙します。</target>       </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The input phrase for the recognition operation.</source>
          <target state="translated">認識操作の入力語句。</target>       </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">エミュレートされた認識操作に使用する比較の種類を示す列挙値のビットごとの組み合わせ。</target>       </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>Emulates input of a phrase to the shared speech recognizer, using text instead of audio for synchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the phrase and the loaded speech recognition grammars.</source>
          <target state="translated">同期音声認識にオーディオではなくテキストを使用して、共有された音声認識エンジンに対するフレーズの入力をエミュレートし、フレーズと読み込まれている音声認識文法との間で認識エンジンが Unicode 比較をどのように行うかを指定します。</target>       </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognition result for the recognition operation, or <ph id="ph1">&lt;see langword="null" /&gt;</ph>, if the operation is not successful or Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state.</source>
          <target state="translated">認識操作の認識結果。操作に成功しなかった場合や、Windows の音声認識が<bpt id="p1">**</bpt>スリープ<ept id="p1">**</ept>状態である場合は <ph id="ph1">&lt;see langword="null" /&gt;</ph>。</target>       </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizer uses the <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">認識エンジンを使用して、<ph id="ph1">`compareOptions`</ph>ときに適用される文法ルール語句を入力します。</target>       </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
          <target state="translated">Vista および Windows 7 に付属しているレコグナイザーが場合は、大文字小文字を区別、<ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph>または<ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph>値が存在します。</target>       </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">認識は、常に文字幅を無視し、カナ型を無視することはありません。</target>       </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">レコグナイザーは、新しい行と余分な空白を無視する、リテラルの入力として区切り記号を扱います。</target>       </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
          <target state="translated">詳細については、文字幅、ひらがなとカタカナは、次を参照してください。、<ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph>列挙します。</target>       </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Emulates input to the shared speech recognizer, using text instead of audio for asynchronous speech recognition.</source>
          <target state="translated">非同期音声認識に音声ではなくテキストを使用して、共有音声認識エンジンに対する入力をエミュレートします。</target>       </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>These methods bypass the system audio input.</source>
          <target state="translated">これらのメソッドは、システムのオーディオ入力をバイパスします。</target>       </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>This can be helpful when you are testing or debugging an application or grammar.</source>
          <target state="translated">これは、ことができますをテストまたはアプリケーションまたは文法をデバッグするとき。</target>       </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The shared recognizer raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> events as if the recognition operation is not emulated.</source>
          <target state="translated">共有認識エンジンが発生し、 <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>、 <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>、 <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>、および<ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph>イベント認識操作がエミュレートされていない場合と同様です。</target>       </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>When the recognizer completes the asynchronous recognition operation, it raises the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph> event.</source>
          <target state="translated">認識エンジンには、非同期の認識操作が完了すると、それを発生させる、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph>イベント。</target>       </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The recognizer ignores new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">認識エンジンでは、新しい行と余分な空白は無視されます、リテラルの入力として区切り記号を扱います。</target>       </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then the shared recognizer does not process input and does not raise the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> and related events, but still raises the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph> event.</source>
          <target state="translated">Windows 音声認識がの場合、<bpt id="p1">**</bpt>休止中<ept id="p1">**</ept>状態にある場合、共有認識エンジンが入力を処理しませんし、発生しません、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>と関連するイベントは、ですが、まだが発生し、<ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph>イベント。</target>       </trans-unit>
        <trans-unit id="216" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object generated by the shared recognizer in response to emulated input has a value of <ph id="ph2">`null`</ph> for its <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph> property.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph>エミュー レートされた入力に応答することで、共有の認識エンジンによって生成されたオブジェクトの値を持つ<ph id="ph2">`null`</ph>の<ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph>プロパティです。</target>       </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To emulate synchronous recognition, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> method.</source>
          <target state="translated">同期の認識をエミュレートするために使用して、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph>メソッドです。</target>       </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>The input for the recognition operation.</source>
          <target state="translated">認識操作の入力。</target>       </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>Emulates input of a phrase to the shared speech recognizer, using text instead of audio for asynchronous speech recognition.</source>
          <target state="translated">非同期音声認識に音声ではなくテキストを使用して、共有音声認識エンジンに対する語句の入力をエミュレートします。</target>       </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case and character width when applying grammar rules to the input phrase.</source>
          <target state="translated">Vista および Windows 7 に付属しているレコグナイザーは、大文字小文字を区別し、入力の語句に文法ルールを適用するときに幅を文字です。</target>       </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>For more information about this type of comparison, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration values <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> and <ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>.</source>
          <target state="translated">この種類の比較の詳細については、次を参照してください。、<ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph>列挙値<ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph>と<ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>です。</target>       </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
          <target state="translated">認識は、新しい行と余分な空白を無視し、リテラルの入力として句読点を扱います。</target>       </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">次の例は、音声認識の文法を読み込んで、非同期エミュー レートされた入力、関連付けられている認識の結果、音声認識エンジンによって生成される関連付けられたイベントを説明するコンソール アプリケーションの一部です。</target>       </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Windows 音声認識が実行されていない場合、このアプリケーションの起動と Windows 音声認識が開始もします。</target>       </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> always returns null.</source>
          <target state="translated">Windows 音声認識がの場合、<bpt id="p1">**</bpt>休止中<ept id="p1">**</ept>状態にある場合、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph>常に null を返します。</target>       </trans-unit>
        <trans-unit id="226" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>An array of word units that contains the input for the recognition operation.</source>
          <target state="translated">認識操作のための必要を格納する単語単位の配列。</target>       </trans-unit>
        <trans-unit id="227" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">エミュレートされた認識操作に使用する比較の種類を示す列挙値のビットごとの組み合わせ。</target>       </trans-unit>
        <trans-unit id="228" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>Emulates input of specific words to the shared speech recognizer, using text instead of audio for asynchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the words and the loaded speech recognition grammars.</source>
          <target state="translated">非同期音声認識にオーディオではなくテキストを使用して、共有された音声認識エンジンに対する特定の語の入力をエミュレートし、語と読み込まれている音声認識文法との間で認識エンジンが Unicode 比較をどのように行うかを指定します。</target>       </trans-unit>
        <trans-unit id="229" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>This method creates a <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object using the information provided in the <ph id="ph2">`wordUnits`</ph> parameter.</source>
          <target state="translated">このメソッドを作成、<ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph>オブジェクトで提供される情報を使用して、<ph id="ph2">`wordUnits`</ph>パラメーター。</target>       </trans-unit>
        <trans-unit id="230" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizer uses the <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">認識エンジンを使用して、<ph id="ph1">`compareOptions`</ph>ときに適用される文法ルール語句を入力します。</target>       </trans-unit>
        <trans-unit id="231" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
          <target state="translated">Vista および Windows 7 に付属しているレコグナイザーが場合は、大文字小文字を区別、<ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph>または<ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph>値が存在します。</target>       </trans-unit>
        <trans-unit id="232" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">認識は、常に文字幅を無視し、カナ型を無視することはありません。</target>       </trans-unit>
        <trans-unit id="233" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">レコグナイザーは、新しい行と余分な空白を無視する、リテラルの入力として区切り記号を扱います。</target>       </trans-unit>
        <trans-unit id="234" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
          <target state="translated">詳細については、文字幅、ひらがなとカタカナは、次を参照してください。、<ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph>列挙します。</target>       </trans-unit>
        <trans-unit id="235" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The input phrase for the recognition operation.</source>
          <target state="translated">認識操作の入力語句。</target>       </trans-unit>
        <trans-unit id="236" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
          <target state="translated">エミュレートされた認識操作に使用する比較の種類を示す列挙値のビットごとの組み合わせ。</target>       </trans-unit>
        <trans-unit id="237" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>Emulates input of a phrase to the shared speech recognizer, using text instead of audio for asynchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the phrase and the loaded speech recognition grammars.</source>
          <target state="translated">非同期音声認識にオーディオではなくテキストを使用して、共有された音声認識エンジンに対するフレーズの入力をエミュレートし、フレーズと読み込まれている音声認識文法との間で認識エンジンが Unicode 比較をどのように行うかを指定します。</target>       </trans-unit>
        <trans-unit id="238" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizer uses the <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
          <target state="translated">認識エンジンを使用して、<ph id="ph1">`compareOptions`</ph>ときに適用される文法ルール語句を入力します。</target>       </trans-unit>
        <trans-unit id="239" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
          <target state="translated">Vista および Windows 7 に付属しているレコグナイザーが場合は、大文字小文字を区別、<ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph>または<ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph>値が存在します。</target>       </trans-unit>
        <trans-unit id="240" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
          <target state="translated">認識は、常に文字幅を無視し、カナ型を無視することはありません。</target>       </trans-unit>
        <trans-unit id="241" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</source>
          <target state="translated">レコグナイザーは、新しい行と余分な空白を無視する、リテラルの入力として区切り記号を扱います。</target>       </trans-unit>
        <trans-unit id="242" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
          <target state="translated">詳細については、文字幅、ひらがなとカタカナは、次を参照してください。、<ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph>列挙します。</target>       </trans-unit>
        <trans-unit id="243" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>Occurs when the shared recognizer finalizes an asynchronous recognition operation for emulated input.</source>
          <target state="translated">共有認識機能がエミュレートされた入力の非同期認識操作を終了すると発生します。</target>       </trans-unit>
        <trans-unit id="244" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>Each <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> method begins an asynchronous recognition operation.</source>
          <target state="translated">各<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph>メソッドが非同期認識操作を開始します。</target>       </trans-unit>
        <trans-unit id="245" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>The recognizer raises the <ph id="ph1">`EmulateRecognizeCompleted`</ph> event when it finalizes the asynchronous operation.</source>
          <target state="translated">認識エンジンが発生し、<ph id="ph1">`EmulateRecognizeCompleted`</ph>非同期操作を終了したときにイベント。</target>       </trans-unit>
        <trans-unit id="246" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>The asynchronous recognition operation can raise the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> events.</source>
          <target state="translated">非同期の認識操作を発生させることができます、 <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>、 <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>、 <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>、および<ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph>イベント。</target>       </trans-unit>
        <trans-unit id="247" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph> event is the last such event that the recognizer raises for a given operation.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph>イベントが最後にそのようなイベントが、認識エンジンは、指定した操作を発生させます。</target>       </trans-unit>
        <trans-unit id="248" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>When you create a delegate for an <ph id="ph1">`EmulateRecognizeCompleted`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">デリゲートを作成する場合、<ph id="ph1">`EmulateRecognizeCompleted`</ph>イベント、イベントを処理するメソッドを指定します。</target>       </trans-unit>
        <trans-unit id="249" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</target>       </trans-unit>
        <trans-unit id="250" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</target>       </trans-unit>
        <trans-unit id="251" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">イベント ハンドラー デリゲートの詳細については、次を参照してください。<bpt id="p1">[</bpt>イベントとデリゲート<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>です。</target>       </trans-unit>
        <trans-unit id="252" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">次の例は、音声認識の文法を読み込んで、非同期エミュー レートされた入力、関連付けられている認識の結果、音声認識エンジンによって生成される関連付けられたイベントを説明するコンソール アプリケーションの一部です。</target>       </trans-unit>
        <trans-unit id="253" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Windows 音声認識が実行されていない場合、このアプリケーションの起動と Windows 音声認識が開始もします。</target>       </trans-unit>
        <trans-unit id="254" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> mode, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> always returns null.</source>
          <target state="translated">Windows 音声認識がの場合、<bpt id="p1">**</bpt>休止中<ept id="p1">**</ept>モード、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph>常に null を返します。</target>       </trans-unit>
        <trans-unit id="255" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source>Gets or sets a value that indicates whether this <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object is ready to process speech.</source>
          <target state="translated">この <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> オブジェクトが音声を処理する準備ができたかどうかを示す値を取得または設定します。</target>       </trans-unit>
        <trans-unit id="256" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source><ph id="ph1">&lt;see langword="true" /&gt;</ph> if this <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object is performing speech recognition; otherwise, <ph id="ph3">&lt;see langword="false" /&gt;</ph>.</source>
          <target state="translated">この <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> オブジェクトが音声認識を行っている場合は <ph id="ph1">&lt;see langword="true" /&gt;</ph>。それ以外の場合は <ph id="ph3">&lt;see langword="false" /&gt;</ph>。</target>       </trans-unit>
        <trans-unit id="257" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source>Changes to this property do not affect other instances of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> class.</source>
          <target state="translated">このプロパティに対する変更の他のインスタンスには影響しません、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>クラスです。</target>       </trans-unit>
        <trans-unit id="258" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source>By default, the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> property is <ph id="ph2">`true`</ph> for a newly instantiated instance of <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>.</source>
          <target state="translated">既定では、値、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph>プロパティは<ph id="ph2">`true`</ph>の新しくインスタンス化されたインスタンスに対して<ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>です。</target>       </trans-unit>
        <trans-unit id="259" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source>While the recognizer is disabled, none of the recognizer's speech recognition grammars are available for recognition operations.</source>
          <target state="translated">認識エンジンが無効にしたままの認識エンジンの音声認識の文法は一切認識操作に使用できます。</target>       </trans-unit>
        <trans-unit id="260" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Enabled">
          <source>Setting the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> property has no effect on the recognizer's <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> property.</source>
          <target state="translated">設定する認識エンジンの<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph>プロパティは、認識エンジンの上の影響を与えません<ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph>プロパティです。</target>       </trans-unit>
        <trans-unit id="261" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.Grammars">
          <source>Gets a collection of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> objects that are loaded in this <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> instance.</source>
          <target state="translated">この <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> インスタンスに読み込まれる <ph id="ph2">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> オブジェクトのコレクションを取得します。</target>       </trans-unit>
        <trans-unit id="262" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Grammars">
          <source>A collection of the <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> objects that the application loaded into the current instance of the shared recognizer.</source>
          <target state="translated">アプリケーションが共有認識エンジンの現在のインスタンスに読み込んだ <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.Grammar" /&gt;</ph> オブジェクトのコレクション。</target>       </trans-unit>
        <trans-unit id="263" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Grammars">
          <source>This property does not return any speech recognition grammars loaded by another application.</source>
          <target state="translated">このプロパティは返されません、音声認識文法が別のアプリケーションによって読み込まれます。</target>       </trans-unit>
        <trans-unit id="264" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.Grammars">
          <source>The following example outputs information to the console for each speech recognition grammar loaded into the shared speech recognizer.</source>
          <target state="translated">次の例では、共有音声認識エンジンに読み込まれる各音声認識の文法のコンソールに情報を出力します。</target>       </trans-unit>
        <trans-unit id="265" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>The speech recognition grammar to load.</source>
          <target state="translated">読み込む音声認識文法。</target>       </trans-unit>
        <trans-unit id="266" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>Loads a speech recognition grammar.</source>
          <target state="translated">音声認識文法を読み込みます。</target>       </trans-unit>
        <trans-unit id="267" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>The shared recognizer throws an exception if the speech recognition grammar is already loaded, is being asynchronously loaded, or has failed to load into any recognizer.</source>
          <target state="translated">共有認識エンジンは、音声認識の文法が既に読み込まれて、非同期的に読み込まれる、またはがすべての認識エンジンに読み込めませんだった場合に例外をスローします。</target>       </trans-unit>
        <trans-unit id="268" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>If the recognizer is running, applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">認識エンジンが実行されている場合、アプリケーションが使用する必要があります<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph>を読み込み、アンロードが有効にすると、または、文法を無効にする前に、音声認識エンジンを一時停止します。</target>       </trans-unit>
        <trans-unit id="269" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>To load a speech recognition grammar asynchronously, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph> method.</source>
          <target state="translated">音声認識の文法を非同期的に読み込むを使用して、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph>メソッドです。</target>       </trans-unit>
        <trans-unit id="270" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">次の例は、音声認識の文法を読み込んで、非同期エミュー レートされた入力、関連付けられている認識の結果、音声認識エンジンによって生成される関連付けられたイベントを説明するコンソール アプリケーションの一部です。</target>       </trans-unit>
        <trans-unit id="271" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Windows 音声認識が実行されていない場合、このアプリケーションの起動と Windows 音声認識が開始もします。</target>       </trans-unit>
        <trans-unit id="272" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)">
          <source>If Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state, then <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> always returns null.</source>
          <target state="translated">Windows 音声認識がの場合、<bpt id="p1">**</bpt>休止中<ept id="p1">**</ept>状態にある場合、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph>常に null を返します。</target>       </trans-unit>
        <trans-unit id="273" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>The speech recognition grammar to load.</source>
          <target state="translated">読み込む音声認識文法。</target>       </trans-unit>
        <trans-unit id="274" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>Asynchronously loads a speech recognition grammar.</source>
          <target state="translated">非同期的に音声認識文法を読み込みます。</target>       </trans-unit>
        <trans-unit id="275" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>When the recognizer completes this asynchronous operation, it raises a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted&gt;</ph> event.</source>
          <target state="translated">認識エンジンには、この非同期操作が完了すると、それを発生させる、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted&gt;</ph>イベント。</target>       </trans-unit>
        <trans-unit id="276" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>The recognizer throws an exception if the speech recognition grammar is already loaded, is being asynchronously loaded, or has failed to load into any recognizer.</source>
          <target state="translated">認識エンジンは、音声認識の文法が既に読み込まれて、非同期的に読み込まれる、またはがすべての認識エンジンに読み込めませんだった場合に例外をスローします。</target>       </trans-unit>
        <trans-unit id="277" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>If the recognizer is running, applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">認識エンジンが実行されている場合、アプリケーションが使用する必要があります<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph>を読み込み、アンロードが有効にすると、または、文法を無効にする前に、音声認識エンジンを一時停止します。</target>       </trans-unit>
        <trans-unit id="278" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)">
          <source>To load a speech recognition grammar synchronously, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A&gt;</ph> method.</source>
          <target state="translated">音声認識の文法を同期的に読み込むを使用して、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A&gt;</ph>メソッドです。</target>       </trans-unit>
        <trans-unit id="279" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>Occurs when the recognizer finishes the asynchronous loading of a speech recognition grammar.</source>
          <target state="translated">認識機能が音声認識文法の非同期読み込みを終了すると発生します。</target>       </trans-unit>
        <trans-unit id="280" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>The recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph> method initiates an asynchronous operation.</source>
          <target state="translated">認識エンジンの<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph>メソッドが非同期操作を開始します。</target>       </trans-unit>
        <trans-unit id="281" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>The recognizer raises the <ph id="ph1">`LoadGrammarCompleted`</ph> event when it completes the operation.</source>
          <target state="translated">認識エンジンが発生し、<ph id="ph1">`LoadGrammarCompleted`</ph>イベント、操作が完了するとします。</target>       </trans-unit>
        <trans-unit id="282" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>To get the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object that the recognizer loaded, use the <ph id="ph2">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A&gt;</ph> property of the associated <ph id="ph3">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt;</ph>.</source>
          <target state="translated">取得する、 <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> 、認識エンジンが読み込まれているオブジェクトを使用して、 <ph id="ph2">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A&gt;</ph> 、関連するプロパティ<ph id="ph3">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt;</ph>です。</target>       </trans-unit>
        <trans-unit id="283" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>To get the current <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects the recognizer has loaded, use the recognizer's <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A&gt;</ph> property.</source>
          <target state="translated">現在の取得に<ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph>、認識エンジンが読み込まれたオブジェクトは、認識エンジンを使用して<ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A&gt;</ph>プロパティです。</target>       </trans-unit>
        <trans-unit id="284" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>When you create a delegate for a <ph id="ph1">`LoadGrammarCompleted`</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">デリゲートを作成する場合、<ph id="ph1">`LoadGrammarCompleted`</ph>イベント、イベントを処理するメソッドを指定します。</target>       </trans-unit>
        <trans-unit id="285" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</target>       </trans-unit>
        <trans-unit id="286" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</target>       </trans-unit>
        <trans-unit id="287" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">イベント ハンドラー デリゲートの詳細については、次を参照してください。<bpt id="p1">[</bpt>イベントとデリゲート<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>です。</target>       </trans-unit>
        <trans-unit id="288" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>The following example creates a shared speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation.</source>
          <target state="translated">次の例では、共有音声認識を作成し、特定の単語を認識するため、空きディクテーションを受け入れるための文法の 2 種類が作成されます。</target>       </trans-unit>
        <trans-unit id="289" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>The example asynchronously loads all the created grammars to the recognizer.</source>
          <target state="translated">例は、認識エンジンに作成されたすべての文法を非同期的に読み込みます。</target>       </trans-unit>
        <trans-unit id="290" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted">
          <source>Handlers for the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> events write to the console the name of the grammar that was used to perform the recognition and the text of the recognition result, respectively.</source>
          <target state="translated">認識エンジンのハンドラー<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted&gt;</ph>と<ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph>イベントでは、認識と認識の結果のテキストをそれぞれ実行に使用されている文法の名前をコンソールに書き込みます。</target>       </trans-unit>
        <trans-unit id="291" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.MaxAlternates">
          <source>Gets or sets the maximum number of alternate recognition results that the shared recognizer returns for each recognition operation.</source>
          <target state="translated">共有認識エンジンが各認識操作に対して返す代替認識結果の最大数を取得または設定します。</target>       </trans-unit>
        <trans-unit id="292" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.MaxAlternates">
          <source>The maximum number of alternate results that the speech recognizer returns for each recognition operation.</source>
          <target state="translated">各認識操作に対して音声認識エンジンが返す代替結果の最大数。</target>       </trans-unit>
        <trans-unit id="293" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.MaxAlternates">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> property of the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> class contains the collection of <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;</ph> objects that represent other candidate interpretations of the input.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph>のプロパティ、<ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph>クラスのコレクションを格納する<ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;</ph>入力の他の候補の解釈を表すオブジェクト。</target>       </trans-unit>
        <trans-unit id="294" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.MaxAlternates">
          <source>The default value for <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A&gt;</ph> is 10.</source>
          <target state="translated">既定値<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A&gt;</ph>10 です。</target>       </trans-unit>
        <trans-unit id="295" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>Gets or sets a value that indicates whether the shared recognizer pauses recognition operations while an application is handling a <ph id="ph1">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /&gt;</ph> event.</source>
          <target state="translated">アプリケーションが <ph id="ph1">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /&gt;</ph> イベントを処理している間、共有認識エンジンが認識操作を一時停止するかどうかを示す値を取得または設定します。</target>       </trans-unit>
        <trans-unit id="296" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source><ph id="ph1">&lt;see langword="true" /&gt;</ph> if the shared recognizer waits to process input while any application is handling the <ph id="ph2">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /&gt;</ph> event; otherwise, <ph id="ph3">&lt;see langword="false" /&gt;</ph>.</source>
          <target state="translated">いずれかのアプリケーションが <ph id="ph2">&lt;see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /&gt;</ph> イベントを処理している間、共有レコグナイザーが入力の処理を待機している場合は <ph id="ph1">&lt;see langword="true" /&gt;</ph>。それ以外の場合は <ph id="ph3">&lt;see langword="false" /&gt;</ph>。</target>       </trans-unit>
        <trans-unit id="297" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>Set this property to <ph id="ph1">`true`</ph>, if within the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event handler your application needs to change the state of the speech recognition service or change the loaded or enabled speech recognition grammars before the speech recognition service processes more input.</source>
          <target state="translated">このプロパティを設定<ph id="ph1">`true`</ph>場合は、内で、<ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>イベント ハンドラーが、アプリケーションは、音声認識サービスの状態を変更するか、音声認識サービスは、複数の入力を処理する前に読み込まれたまたは有効な音声認識の文法を変更する必要があります。</target>       </trans-unit>
        <trans-unit id="298" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>Setting the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> property to <ph id="ph2">`true`</ph> causes each <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event handler in every application to block the Windows speech recognition service.</source>
          <target state="translated">設定、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>プロパティを<ph id="ph2">`true`</ph>と、 <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> Windows 音声認識サービスをブロックするすべてのアプリケーション内のイベント ハンドラー。</target>       </trans-unit>
        <trans-unit id="299" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>To synchronize the changes to the shared recognizer with your application state, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">アプリケーションの状態で、共有認識エンジンへの変更を同期するために使用して、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph>メソッドです。</target>       </trans-unit>
        <trans-unit id="300" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>When <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph> is <ph id="ph2">`true`</ph>, during the execution of the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> handler the speech recognition service pauses and buffers new audio input as it arrives.</source>
          <target state="translated">ときに<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph>は<ph id="ph2">`true`</ph>の実行中に、<ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>ハンドラー、音声認識サービスが一時停止し、受信する新しいオーディオ入力をバッファーします。</target>       </trans-unit>
        <trans-unit id="301" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>Once the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event handler exits, the speech recognition service resumes recognition and starts processing information from its input buffer.</source>
          <target state="translated">1 回、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph>イベント ハンドラーが終了する音声の認識サービスを再開し、入力バッファーからの情報の処理を開始します。</target>       </trans-unit>
        <trans-unit id="302" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition">
          <source>To enable or disable the speech recognition service, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> property.</source>
          <target state="translated">を有効にするにまたは音声認識サービスを無効にするには、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph>プロパティです。</target>       </trans-unit>
        <trans-unit id="303" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>Gets the current location of the recognizer in the audio input that it is processing.</source>
          <target state="translated">処理中のオーディオ入力内の認識エンジンの現在の位置を取得します。</target>       </trans-unit>
        <trans-unit id="304" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>The position of the recognizer in the audio input that it is processing.</source>
          <target state="translated">処理中のオーディオ入力の認識エンジンの位置。</target>       </trans-unit>
        <trans-unit id="305" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>The <ph id="ph1">`RecognizerAudioPosition`</ph> property references the recognizer's position in processing its audio input.</source>
          <target state="translated"><ph id="ph1">`RecognizerAudioPosition`</ph>プロパティは、オーディオ入力の処理の認識エンジンの位置を参照します。</target>       </trans-unit>
        <trans-unit id="306" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>By contrast, the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> property references the input device's position in its generated audio stream.</source>
          <target state="translated">これに対し、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph>プロパティは、生成されたオーディオ ストリーム内の入力デバイスの位置を参照します。</target>       </trans-unit>
        <trans-unit id="307" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>These positions can be different.</source>
          <target state="translated">これらの位置は別にすることはできます。</target>       </trans-unit>
        <trans-unit id="308" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition">
          <source>For example, if the recognizer has received input for which it has not yet generated a recognition result then the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> property is less than the value of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> property.</source>
          <target state="translated">たとえば、認識エンジンが受信した場合どの it されていない入力が、認識結果が次の値を生成、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph>プロパティは、の値より小さい、<ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph>プロパティです。</target>       </trans-unit>
        <trans-unit id="309" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerInfo">
          <source>Gets information about the shared speech recognizer.</source>
          <target state="translated">共有音声認識エンジンに関する情報を取得します。</target>       </trans-unit>
        <trans-unit id="310" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerInfo">
          <source>Information about the shared speech recognizer.</source>
          <target state="translated">共有音声認識エンジンに関する情報です。</target>       </trans-unit>
        <trans-unit id="311" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerInfo">
          <source>This property returns information about the speech recognizer in use by Windows Speech Recognition.</source>
          <target state="translated">このプロパティは、Windows 音声認識で使用中の音声認識エンジンに関する情報を返します。</target>       </trans-unit>
        <trans-unit id="312" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.RecognizerInfo">
          <source>The following example sends information about the shared recognizer to the console.</source>
          <target state="translated">次の例では、コンソールに、共有認識エンジンに関する情報を送信します。</target>       </trans-unit>
        <trans-unit id="313" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>Occurs when the recognizer pauses to synchronize recognition and other operations.</source>
          <target state="translated">認識機能が認識と他の操作を同期するために一時停止すると発生します。</target>       </trans-unit>
        <trans-unit id="314" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>Applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> to pause a running instance of <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> before modifying its <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">アプリケーションを使用する必要があります<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph>を実行中のインスタンスを一時停止する<ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>変更する前にその<ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph>オブジェクト。</target>       </trans-unit>
        <trans-unit id="315" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>For example, while the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> is paused, you can load, unload, enable, and disable <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">などの<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>が一時停止していることができますをロード、アンロード、有効にするには、または無効化する<ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph>オブジェクト。</target>       </trans-unit>
        <trans-unit id="316" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> raises this event when it is ready to accept modifications.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>変更を受け入れる準備ができたときにこのイベントを発生させます。</target>       </trans-unit>
        <trans-unit id="317" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">デリゲートを作成する場合、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph>イベント、イベントを処理するメソッドを指定します。</target>       </trans-unit>
        <trans-unit id="318" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</target>       </trans-unit>
        <trans-unit id="319" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</target>       </trans-unit>
        <trans-unit id="320" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">イベント ハンドラー デリゲートの詳細については、次を参照してください。<bpt id="p1">[</bpt>イベントとデリゲート<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>です。</target>       </trans-unit>
        <trans-unit id="321" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>The following example shows a console application that loads and unloads <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">次の例では、コンソール アプリケーションをロードおよびアンロード<ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph>オブジェクト。</target>       </trans-unit>
        <trans-unit id="322" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>The application uses the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method to request the speech recognition engine to pause so it can receive an update.</source>
          <target state="translated">アプリケーションを使用して、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph>音声認識エンジンの更新プログラムを受信できるようにを一時停止を要求するメソッド。</target>       </trans-unit>
        <trans-unit id="323" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>The application then loads or unloads a <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object.</source>
          <target state="translated">アプリケーションが読み込むか、アンロード、<ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph>オブジェクト。</target>       </trans-unit>
        <trans-unit id="324" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>At each update, a handler for <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event writes the name and status of the currently loaded <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects to the console.</source>
          <target state="translated">各更新プログラムのハンドラーで<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph>イベントが現在読み込み済みの状態と名前を書き込みます<ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph>オブジェクトをコンソールです。</target>       </trans-unit>
        <trans-unit id="325" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached">
          <source>As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.</source>
          <target state="translated">ように文法では、読み込まれ、アンロードすることが、アプリケーションは、ファーム動物の名前、果物の名前およびファーム動物の名前にし果物の名前だけに最初認識します。</target>       </trans-unit>
        <trans-unit id="326" translate="yes" xml:space="preserve" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Requests that the shared recognizer pause and update its state.</source>
          <target state="translated">共有認識エンジンがその状態を更新および停止するように要求します。</target>       </trans-unit>
        <trans-unit id="327" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>Use this method to synchronize changes to the shared recognizer.</source>
          <target state="translated">このメソッドを共有認識エンジンへの変更を同期するために使用します。</target>       </trans-unit>
        <trans-unit id="328" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>For example, if you load or unload a speech recognition grammar while the recognizer is processing input, use this method and the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event to synchronize your application behavior with the state of the recognizer.</source>
          <target state="translated">たとえば、読み込み、認識エンジンが入力の処理中に音声認識の文法をアンロードするか、このメソッドを使用し、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph>認識エンジンの状態とアプリケーションの動作を同期するイベントです。</target>       </trans-unit>
        <trans-unit id="329" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>When this method is called, the recognizer pauses or completes asynchronous operations and generates a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event.</source>
          <target state="translated">このメソッドが呼び出されると、一時停止または非同期操作が完了して、レコグナイザーが生成されます、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph>イベント。</target>       </trans-unit>
        <trans-unit id="330" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>A <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event handler can then modify the state of the recognizer in between recognition operations.</source>
          <target state="translated">A<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph>イベント ハンドラーは認識操作の間、認識エンジンの状態を変更できます。</target>       </trans-unit>
        <trans-unit id="331" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>When this method is called:</source>
          <target state="translated">このメソッドが呼び出されたとき。</target>       </trans-unit>
        <trans-unit id="332" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If the recognizer is not processing input, the recognizer immediately generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event.</source>
          <target state="translated">認識エンジンが直ちに生成、認識エンジンが入力を処理されていない場合、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph>イベント。</target>       </trans-unit>
        <trans-unit id="333" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If the recognizer is processing input that consists of silence or background noise, the recognizer pauses the recognition operation and generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event.</source>
          <target state="translated">認識エンジンが認識操作を一時停止し、生成、認識エンジンがサイレント状態のバック グラウンド ノイズで構成される入力を処理している場合、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph>イベント。</target>       </trans-unit>
        <trans-unit id="334" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>If the recognizer is processing input that does not consist of silence or background noise, the recognizer completes the recognition operation and then generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event.</source>
          <target state="translated">認識エンジンが認識操作を完了し、生成、認識エンジンがサイレント状態またはバック グラウンド ノイズ数に達していない入力を処理している場合、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph>イベント。</target>       </trans-unit>
        <trans-unit id="335" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>While the recognizer is handling the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event:</source>
          <target state="translated">認識エンジンが処理中に、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph>イベント。</target>       </trans-unit>
        <trans-unit id="336" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The recognizer does not process input, and the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> property remains the same.</source>
          <target state="translated">認識エンジンでは、入力、およびの値は処理されません、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph>プロパティは変わりません。</target>       </trans-unit>
        <trans-unit id="337" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The recognizer continues to collect input, and the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> property can change.</source>
          <target state="translated">認識エンジンを継続して入力を収集しの値、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph>プロパティを変更することができます。</target>       </trans-unit>
        <trans-unit id="338" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>To change whether the shared recognizer pauses recognition operations while an application is handling a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event, use the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph> property.</source>
          <target state="translated">アプリケーションの処理中に、共有認識エンジンが認識操作を一時停止するかどうかを変更する、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph>イベントを使用して、<ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph>プロパティです。</target>       </trans-unit>
        <trans-unit id="339" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The following example shows a console application that loads and unloads <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">次の例では、コンソール アプリケーションをロードおよびアンロード<ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph>オブジェクト。</target>       </trans-unit>
        <trans-unit id="340" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The application uses the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method to request the speech recognition engine to pause so it can receive an update.</source>
          <target state="translated">アプリケーションを使用して、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph>音声認識エンジンの更新プログラムを受信できるようにを一時停止を要求するメソッド。</target>       </trans-unit>
        <trans-unit id="341" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>The application then loads or unloads a <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object.</source>
          <target state="translated">アプリケーションが読み込むか、アンロード、<ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph>オブジェクト。</target>       </trans-unit>
        <trans-unit id="342" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>At each update, a handler for <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event writes the name and status of the currently loaded <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects to the console.</source>
          <target state="translated">各更新プログラムのハンドラーで<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph>イベントが現在読み込み済みの状態と名前を書き込みます<ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph>オブジェクトをコンソールです。</target>       </trans-unit>
        <trans-unit id="343" translate="yes" xml:space="preserve" extradata="MT" uid="T:System.Speech.Recognition.SpeechRecognizer">
          <source>As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.</source>
          <target state="translated">ように文法では、読み込まれ、アンロードすることが、アプリケーションは、ファーム動物の名前、果物の名前およびファーム動物の名前にし果物の名前だけに最初認識します。</target>       </trans-unit>
        <trans-unit id="344" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate">
          <source>Requests that the shared recognizer pause and update its state.</source>
          <target state="translated">共有認識エンジンがその状態を更新および停止するように要求します。</target>       </trans-unit>
        <trans-unit id="345" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate">
          <source>When the recognizer generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event, the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> property of the <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> is <ph id="ph4">`null`</ph>.</source>
          <target state="translated">認識エンジンが生成するとき、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph>イベント、<ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph>のプロパティ、<ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph>は<ph id="ph4">`null`</ph>します。</target>       </trans-unit>
        <trans-unit id="346" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate">
          <source>To provide a user token, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">ユーザー トークンを指定するには、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph>または<ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph>メソッドです。</target>       </trans-unit>
        <trans-unit id="347" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate">
          <source>To specify an audio position offset, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">オーディオの位置のオフセットを指定するには、使用、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph>メソッドです。</target>       </trans-unit>
        <trans-unit id="348" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)">
          <source>User-defined information that contains information for the operation.</source>
          <target state="translated">操作に関する情報を含むユーザー定義情報。</target>       </trans-unit>
        <trans-unit id="349" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)">
          <source>Requests that the shared recognizer pause and update its state and provides a user token for the associated event.</source>
          <target state="translated">共有認識エンジンがその状態を停止および更新し、関連イベントのユーザー トークンを提供するように要求します。</target>       </trans-unit>
        <trans-unit id="350" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)">
          <source>When the recognizer generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event, the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> property of the <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> contains the value of the <ph id="ph4">`userToken`</ph> parameter.</source>
          <target state="translated">認識エンジンが生成するとき、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph>イベント、<ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph>のプロパティ、<ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph>の値が含まれています、<ph id="ph4">`userToken`</ph>パラメーター。</target>       </trans-unit>
        <trans-unit id="351" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)">
          <source>To specify an audio position offset, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
          <target state="translated">オーディオの位置のオフセットを指定するには、使用、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph>メソッドです。</target>       </trans-unit>
        <trans-unit id="352" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>User-defined information that contains information for the operation.</source>
          <target state="translated">操作に関する情報を含むユーザー定義情報。</target>       </trans-unit>
        <trans-unit id="353" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>The offset from the current <ph id="ph1">&lt;see cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" /&gt;</ph> to delay the request.</source>
          <target state="translated">要求を遅延するための、現在の <ph id="ph1">&lt;see cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" /&gt;</ph> からのオフセット。</target>       </trans-unit>
        <trans-unit id="354" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>Requests that the shared recognizer pause and update its state and provides an offset and a user token for the associated event.</source>
          <target state="translated">共有認識エンジンがその状態を停止および更新し、関連イベントのオフセットとユーザー トークンを提供するように要求します。</target>       </trans-unit>
        <trans-unit id="355" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>The recognizer does not initiate the recognizer update request until the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> equals the current <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> plus the value of the <ph id="ph3">`audioPositionAheadToRaiseUpdate`</ph> parameter.</source>
          <target state="translated">認識エンジンが認識エンジンのまで認識エンジンの更新要求を開始できません<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph>現在に等しい<ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph>の値に加えて、<ph id="ph3">`audioPositionAheadToRaiseUpdate`</ph>パラメーター。</target>       </trans-unit>
        <trans-unit id="356" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)">
          <source>When the recognizer generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event, the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> property of the <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> contains the value of the <ph id="ph4">`userToken`</ph> parameter.</source>
          <target state="translated">認識エンジンが生成するとき、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph>イベント、<ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph>のプロパティ、<ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph>の値が含まれています、<ph id="ph4">`userToken`</ph>パラメーター。</target>       </trans-unit>
        <trans-unit id="357" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>Occurs when the recognizer detects input that it can identify as speech.</source>
          <target state="translated">認識機能が音声として識別できる入力を検出すると発生します。</target>       </trans-unit>
        <trans-unit id="358" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The shared recognizer can raise this event in response to input.</source>
          <target state="translated">共有認識エンジンには、このイベントの入力に応答を生成できます。</target>       </trans-unit>
        <trans-unit id="359" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs&gt;</ph> object indicates location in the input stream where the recognizer detected speech.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A&gt;</ph> 、関連するプロパティ<ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs&gt;</ph>オブジェクトを認識エンジンが音声を認識する場合、入力ストリーム内の場所を示します。</target>       </trans-unit>
        <trans-unit id="360" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>For more information see the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> properties and the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> methods.</source>
          <target state="translated">詳細については、次を参照してください。、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph>と<ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph>プロパティおよび<ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph>と<ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph>メソッドです。</target>       </trans-unit>
        <trans-unit id="361" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">デリゲートを作成する場合、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>イベント、イベントを処理するメソッドを指定します。</target>       </trans-unit>
        <trans-unit id="362" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</target>       </trans-unit>
        <trans-unit id="363" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</target>       </trans-unit>
        <trans-unit id="364" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">イベント ハンドラー デリゲートの詳細については、次を参照してください。<bpt id="p1">[</bpt>イベントとデリゲート<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>です。</target>       </trans-unit>
        <trans-unit id="365" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The following example is part of a console application for choosing origin and destination cities for a flight.</source>
          <target state="translated">次の例は、フライトの送信元と送信先の都市を選択するためのコンソール アプリケーションの一部です。</target>       </trans-unit>
        <trans-unit id="366" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The application recognizes phrases such as "I want to fly from Miami to Chicago."</source>
          <target state="translated">アプリケーションが語句を認識する Miami からシカゴにスライドします"など</target>       </trans-unit>
        <trans-unit id="367" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected">
          <source>The example uses the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> event to report the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> each time speech is detected.</source>
          <target state="translated">この例では、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>イベント レポートを<ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph>各時間音声が検出されました。</target>       </trans-unit>
        <trans-unit id="368" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>Occurs when the recognizer has recognized a word or words that may be a component of multiple complete phrases in a grammar.</source>
          <target state="translated">認識機能が文法の複数の完全な語句のコンポーネントである可能性がある単語を認識した場合に発生します。</target>       </trans-unit>
        <trans-unit id="369" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>The shared recognizer can raise this event when the input is ambiguous.</source>
          <target state="translated">共有認識エンジンには、入力があいまいな場合は、このイベントを生成できます。</target>       </trans-unit>
        <trans-unit id="370" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>For example, for a speech recognition grammar that supports recognition of either "new game please" or "new game", "new game please" is an unambiguous input, and "new game" is an ambiguous input.</source>
          <target state="translated">たとえば、いずれかの認識をサポートする音声認識文法"新しいゲームをしてください。"または"新しいゲーム"、"新しいゲームをしてください"、あいまいさのない入力は、"新しいゲーム"はあいまいな入力です。</target>       </trans-unit>
        <trans-unit id="371" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">デリゲートを作成する場合、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>イベント、イベントを処理するメソッドを指定します。</target>       </trans-unit>
        <trans-unit id="372" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</target>       </trans-unit>
        <trans-unit id="373" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</target>       </trans-unit>
        <trans-unit id="374" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">イベント ハンドラー デリゲートの詳細については、次を参照してください。<bpt id="p1">[</bpt>イベントとデリゲート<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>です。</target>       </trans-unit>
        <trans-unit id="375" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>The following example recognizes phrases such as "Display the list of artists in the jazz category".</source>
          <target state="translated">次の例では、「ジャズのカテゴリのアーティストの一覧を表示する」などの語句を認識します。</target>       </trans-unit>
        <trans-unit id="376" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized">
          <source>The example uses the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph> event to display incomplete phrase fragments in the console as they are recognized.</source>
          <target state="translated">この例では、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>認識するように、コンソールで不完全な語句フラグメントを表示するイベントです。</target>       </trans-unit>
        <trans-unit id="377" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>Occurs when the recognizer receives input that does not match any of the speech recognition grammars it has loaded.</source>
          <target state="translated">認識機能が読み込んだ音声認識文法のいずれにも一致しない入力を受け取ると発生します。</target>       </trans-unit>
        <trans-unit id="378" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>The shared recognizer raises this event if it determines that input does not match with sufficient confidence any of the loaded speech recognition grammars.</source>
          <target state="translated">共有認識エンジンは、入力が一致しないことための十分な信頼で読み込まれた音声認識の文法のいずれかを判断した場合、このイベントを発生させます。</target>       </trans-unit>
        <trans-unit id="379" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> property of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph> contains the rejected <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph>のプロパティ、 <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph> 、拒否されたを含む<ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph>オブジェクト。</target>       </trans-unit>
        <trans-unit id="380" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>Confidence thresholds for the shared recognizer, managed by <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>, are associated with a user profile and stored in the Windows registry.</source>
          <target state="translated">信頼度のしきい値によって管理される共有認識エンジンを<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>のユーザー プロファイルに関連付けられているし、Windows レジストリに格納します。</target>       </trans-unit>
        <trans-unit id="381" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>Applications should not write changes to the registry for the properties of the shared recognizer.</source>
          <target state="translated">アプリケーションは、プロパティ、共有認識エンジンのレジストリに変更を書き込めません必要があります。</target>       </trans-unit>
        <trans-unit id="382" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">デリゲートを作成する場合、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>イベント、イベントを処理するメソッドを指定します。</target>       </trans-unit>
        <trans-unit id="383" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</target>       </trans-unit>
        <trans-unit id="384" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</target>       </trans-unit>
        <trans-unit id="385" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">イベント ハンドラー デリゲートの詳細については、次を参照してください。<bpt id="p1">[</bpt>イベントとデリゲート<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>です。</target>       </trans-unit>
        <trans-unit id="386" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>The following example recognizes phrases such as "Display the list of artists in the jazz category" or "Display albums gospel".</source>
          <target state="translated">次の例では、「ジャズ カテゴリのアーティストの一覧を表示する」や「表示アルバム考えないで」などの語句を認識します。</target>       </trans-unit>
        <trans-unit id="387" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected">
          <source>The example uses a handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph> event to display a notification in the console when the speech input cannot be matched to the contents of the grammar with sufficient confidence to produce a successful recognition.</source>
          <target state="translated">この例のハンドラーを使用して、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>成功認識を生成するために十分な信頼度と文法の内容に一致することはできません、音声の入力時に、コンソールで、通知を表示するイベントです。</target>       </trans-unit>
        <trans-unit id="388" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>Occurs when the recognizer receives input that matches one of its speech recognition grammars.</source>
          <target state="translated">認識機能が読み込んだ音声認識文法のいずれかに一致する入力を受け取ると発生します。</target>       </trans-unit>
        <trans-unit id="389" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The recognizer raises the <ph id="ph1">`SpeechRecognized`</ph> event if it determines with sufficient confidence that input matches one of the loaded and enabled speech recognition grammars.</source>
          <target state="translated">認識エンジンが発生し、<ph id="ph1">`SpeechRecognized`</ph>自信のための十分な入力はアンロードされ、有効な音声認識の文法の 1 つに一致するいると判断した場合のイベントです。</target>       </trans-unit>
        <trans-unit id="390" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> property of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph> contains the accepted <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph>のプロパティ、<ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph>承諾が含まれています<ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph>オブジェクト。</target>       </trans-unit>
        <trans-unit id="391" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>Confidence thresholds for the shared recognizer, managed by <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>, are associated with a user profile and stored in the Windows registry.</source>
          <target state="translated">信頼度のしきい値によって管理される共有認識エンジンを<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>のユーザー プロファイルに関連付けられているし、Windows レジストリに格納します。</target>       </trans-unit>
        <trans-unit id="392" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>Applications should not write changes to the registry for the properties of the shared recognizer.</source>
          <target state="translated">アプリケーションは、プロパティ、共有認識エンジンのレジストリに変更を書き込めません必要があります。</target>       </trans-unit>
        <trans-unit id="393" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>When the recognizer receives input that matches a grammar, the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object can raise the <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">認識エンジンが、文法に一致する入力を受け取るときに、<ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph>オブジェクトを発生させることができます、<ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph>イベント。</target>       </trans-unit>
        <trans-unit id="394" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object's <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> event is raised prior to the speech recognizer's <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph>オブジェクトの<ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph>音声認識エンジンの前にイベントが発生した<ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph>イベント。</target>       </trans-unit>
        <trans-unit id="395" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">デリゲートを作成する場合、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph>イベント、イベントを処理するメソッドを指定します。</target>       </trans-unit>
        <trans-unit id="396" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</target>       </trans-unit>
        <trans-unit id="397" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</target>       </trans-unit>
        <trans-unit id="398" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">イベント ハンドラー デリゲートの詳細については、次を参照してください。<bpt id="p1">[</bpt>イベントとデリゲート<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>です。</target>       </trans-unit>
        <trans-unit id="399" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The following example is part of a console application that loads a speech recognition grammar and demonstrates speech input to the shared recognizer, the associated recognition results, and the associated events raised by the speech recognizer.</source>
          <target state="translated">次の例は、音声認識の文法を読み込んで、音声入力を共有認識エンジン、関連付けられている認識の結果、および音声認識エンジンによって生成される関連するイベントについて説明するコンソール アプリケーションです。</target>       </trans-unit>
        <trans-unit id="400" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</source>
          <target state="translated">Windows 音声認識が実行されていない場合、このアプリケーションの起動と Windows 音声認識が開始もします。</target>       </trans-unit>
        <trans-unit id="401" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>Spoken input such as "I want to fly from Chicago to Miami" will trigger a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">「する Miami にシカゴからスライド」をトリガーするように入力を読み上げ、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph>イベント。</target>       </trans-unit>
        <trans-unit id="402" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>Speaking the phrase "Fly me from Houston to Chicago " will not trigger a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event.</source>
          <target state="translated">"飛行 me ヒューストンからシカゴに"という語句を話すはトリガーされません、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph>イベント。</target>       </trans-unit>
        <trans-unit id="403" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized">
          <source>The example uses a handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event to display successfully recognized phrases and the semantics they contain in the console.</source>
          <target state="translated">例では、ハンドラーを使用して、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph>を正常に表示するイベントには、語句と、コンソールに含まれているセマンティクスが認識されています。</target>       </trans-unit>
        <trans-unit id="404" translate="yes" xml:space="preserve" uid="P:System.Speech.Recognition.SpeechRecognizer.State">
          <source>Gets the state of a <ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> object.</source>
          <target state="translated"><ph id="ph1">&lt;see cref="T:System.Speech.Recognition.SpeechRecognizer" /&gt;</ph> オブジェクトの状態を取得します。</target>       </trans-unit>
        <trans-unit id="405" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.State">
          <source>The state of the <ph id="ph1">&lt;see langword="SpeechRecognizer" /&gt;</ph> object.</source>
          <target state="translated"><ph id="ph1">&lt;see langword="SpeechRecognizer" /&gt;</ph> オブジェクトの状態。</target>       </trans-unit>
        <trans-unit id="406" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.State">
          <source>This read-only property indicates whether the shared recognizer resident in Windows is in the <ph id="ph1">`Stopped`</ph> or the <ph id="ph2">`Listening`</ph> state.</source>
          <target state="translated">この読み取り専用プロパティは、Windows に常駐している、共有認識エンジンがかどうかを示す、<ph id="ph1">`Stopped`</ph>または<ph id="ph2">`Listening`</ph>状態です。</target>       </trans-unit>
        <trans-unit id="407" translate="yes" xml:space="preserve" extradata="MT" uid="P:System.Speech.Recognition.SpeechRecognizer.State">
          <source>For more information, see the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerState&gt;</ph> enumeration.</source>
          <target state="translated">詳細については、<ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerState&gt;</ph> 列挙型のページをご覧ください。</target>       </trans-unit>
        <trans-unit id="408" translate="yes" xml:space="preserve" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>Occurs when the running state of the Windows Desktop Speech Technology recognition engine changes.</source>
          <target state="translated">Windows Desktop Speech テクノロジ音声認識エンジンの実行状態が変更されると発生します。</target>       </trans-unit>
        <trans-unit id="409" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>The shared recognizer raises this event when the state of Windows Speech Recognition changes to the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerState.Listening&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerState.Stopped&gt;</ph> state.</source>
          <target state="translated">共有認識エンジンが Windows 音声認識の状態に変更したときに、このイベントを発生させる、<ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerState.Listening&gt;</ph>または<ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerState.Stopped&gt;</ph>状態です。</target>       </trans-unit>
        <trans-unit id="410" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>To get the state of the shared recognizer at the time of the event, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.StateChangedEventArgs&gt;</ph>.</source>
          <target state="translated">イベントの時点で、共有認識エンジンの状態を取得する、 <ph id="ph1">&lt;xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A&gt;</ph> 、関連するプロパティ<ph id="ph2">&lt;xref:System.Speech.Recognition.StateChangedEventArgs&gt;</ph>です。</target>       </trans-unit>
        <trans-unit id="411" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>To get the current state of the shared recognizer, use the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> property.</source>
          <target state="translated">共有認識エンジンの現在の状態を取得するには、認識エンジンを使用<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph>プロパティです。</target>       </trans-unit>
        <trans-unit id="412" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> event, you identify the method that will handle the event.</source>
          <target state="translated">デリゲートを作成する場合、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph>イベント、イベントを処理するメソッドを指定します。</target>       </trans-unit>
        <trans-unit id="413" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
          <target state="translated">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</target>       </trans-unit>
        <trans-unit id="414" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
          <target state="translated">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</target>       </trans-unit>
        <trans-unit id="415" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
          <target state="translated">イベント ハンドラー デリゲートの詳細については、次を参照してください。<bpt id="p1">[</bpt>イベントとデリゲート<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>です。</target>       </trans-unit>
        <trans-unit id="416" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>The following example creates a shared speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation.</source>
          <target state="translated">次の例では、共有音声認識を作成し、特定の単語を認識するため、空きディクテーションを受け入れるための文法の 2 種類が作成されます。</target>       </trans-unit>
        <trans-unit id="417" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>The example asynchronously loads all the created grammars to the recognizer.</source>
          <target state="translated">例は、認識エンジンに作成されたすべての文法を非同期的に読み込みます。</target>       </trans-unit>
        <trans-unit id="418" translate="yes" xml:space="preserve" extradata="MT" uid="E:System.Speech.Recognition.SpeechRecognizer.StateChanged">
          <source>A handler for the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> event uses the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> method to put Windows Recognition in "listening" mode.</source>
          <target state="translated">ハンドラーを<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph>イベントを使用して、 <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> 「リッスン」モードに Windows 認識するメソッド。</target>       </trans-unit>
        <trans-unit id="419" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars">
          <source>Unloads all speech recognition grammars from the shared recognizer.</source>
          <target state="translated">共有認識エンジンから、すべての音声認識文法をアンロードします。</target>       </trans-unit>
        <trans-unit id="420" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars">
          <source>If the recognizer is currently loading a grammar asynchronously, this method waits until the grammar is loaded, before it unloads all of the recognizer's grammars.</source>
          <target state="translated">場合は、認識エンジンが現在を読み込んで、文法に非同期的に、このメソッドは、文法が読み込まれるまで、すべての認識エンジンの文法がアンロードする前に待機します。</target>       </trans-unit>
        <trans-unit id="421" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars">
          <source>To unload a specific grammar, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A&gt;</ph> method.</source>
          <target state="translated">特定の文法をアンロードするを使用して、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A&gt;</ph>メソッドです。</target>       </trans-unit>
        <trans-unit id="422" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>The grammar to unload.</source>
          <target state="translated">アンロードする文法。</target>       </trans-unit>
        <trans-unit id="423" translate="yes" xml:space="preserve" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>Unloads a specified speech recognition grammar from the shared recognizer.</source>
          <target state="translated">共有認識エンジンから、指定された音声認識文法をアンロードします。</target>       </trans-unit>
        <trans-unit id="424" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>If the recognizer is running, applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
          <target state="translated">認識エンジンが実行されている場合、アプリケーションが使用する必要があります<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph>を読み込み、アンロードが有効にすると、または、文法を無効にする前に、音声認識エンジンを一時停止します。</target>       </trans-unit>
        <trans-unit id="425" translate="yes" xml:space="preserve" extradata="MT" uid="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)">
          <source>To unload all grammars, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A&gt;</ph> method.</source>
          <target state="translated">すべての文法をアンロードするを使用して、<ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A&gt;</ph>メソッドです。</target>       </trans-unit>
      </group>
    </body>
  </file>
</xliff>