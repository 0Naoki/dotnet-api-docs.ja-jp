<Type Name="SpeechRecognizer" FullName="System.Speech.Recognition.SpeechRecognizer">
  <Metadata><Meta Name="ms.openlocfilehash" Value="7f19e98d364cd16bffbf58714877f22e676a4052" /><Meta Name="ms.sourcegitcommit" Value="0e1f030650a307c745ee84ed547ef858acaea587" /><Meta Name="ms.translationtype" Value="HT" /><Meta Name="ms.contentlocale" Value="ja-JP" /><Meta Name="ms.lasthandoff" Value="11/29/2018" /><Meta Name="ms.locfileid" Value="52596030" /></Metadata><TypeSignature Language="C#" Value="public class SpeechRecognizer : IDisposable" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit SpeechRecognizer extends System.Object implements class System.IDisposable" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.SpeechRecognizer" />
  <TypeSignature Language="VB.NET" Value="Public Class SpeechRecognizer&#xA;Implements IDisposable" />
  <TypeSignature Language="C++ CLI" Value="public ref class SpeechRecognizer : IDisposable" />
  <TypeSignature Language="F#" Value="type SpeechRecognizer = class&#xA;    interface IDisposable" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces>
    <Interface>
      <InterfaceName>System.IDisposable</InterfaceName>
    </Interface>
  </Interfaces>
  <Docs>
    <summary><span data-ttu-id="52bef-101">Windows デスクトップで使用できる共有音声認識サービスへのアクセスを提供します。</span><span class="sxs-lookup"><span data-stu-id="52bef-101">Provides access to the shared speech recognition service available on the Windows desktop.</span></span></summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-102">アプリケーションでは、Windows 音声認識にアクセスするのに共有認識エンジンを使用します。</span><span class="sxs-lookup"><span data-stu-id="52bef-102">Applications use the shared recognizer to access Windows Speech Recognition.</span></span> <span data-ttu-id="52bef-103">使用して、 <xref:System.Speech.Recognition.SpeechRecognizer> Windows 音声認識のユーザー エクスペリエンスに追加するオブジェクト。</span><span class="sxs-lookup"><span data-stu-id="52bef-103">Use the <xref:System.Speech.Recognition.SpeechRecognizer> object to add to the Windows speech user experience.</span></span>  
  
 <span data-ttu-id="52bef-104">このクラスには、音声認識のプロセスのさまざまな角度から制御が用意されています。</span><span class="sxs-lookup"><span data-stu-id="52bef-104">This class provides control over various aspects of the speech recognition process:</span></span>  
  
-   <span data-ttu-id="52bef-105">音声認識文法を管理するを使用して、 <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A>、 <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>、 <xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A>、 <xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A>、および<xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A>します。</span><span class="sxs-lookup"><span data-stu-id="52bef-105">To manage speech recognition grammars, use the <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A>, and <xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A>.</span></span>  
  
-   <span data-ttu-id="52bef-106">サブスクライブする認識操作を現在の音声に関する情報を取得する、<xref:System.Speech.Recognition.SpeechRecognizer>の<xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>、 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>、 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>、および<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>イベント。</span><span class="sxs-lookup"><span data-stu-id="52bef-106">To get information about current speech recognition operations, subscribe to the <xref:System.Speech.Recognition.SpeechRecognizer>'s <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>, and <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> events.</span></span>  
  
-   <span data-ttu-id="52bef-107">を表示または変更、認識エンジンが返す代替結果の数を使用して、<xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A>プロパティ。</span><span class="sxs-lookup"><span data-stu-id="52bef-107">To view or modify the number of alternate results the recognizer returns, use the <xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A> property.</span></span> <span data-ttu-id="52bef-108">認識エンジンで認識の結果を返します、<xref:System.Speech.Recognition.RecognitionResult>オブジェクト。</span><span class="sxs-lookup"><span data-stu-id="52bef-108">The recognizer returns recognition results in a <xref:System.Speech.Recognition.RecognitionResult> object.</span></span>  
  
-   <span data-ttu-id="52bef-109">アクセスまたは共有認識エンジンの状態を監視、使用、 <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A>、 <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>、 <xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A>、 <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>、 <xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A>、 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>、および<xref:System.Speech.Recognition.SpeechRecognizer.State%2A>プロパティおよび<xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated>、 <xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred>、 <xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged>、および<xref:System.Speech.Recognition.SpeechRecognizer.StateChanged>イベント。</span><span class="sxs-lookup"><span data-stu-id="52bef-109">To access or monitor the state of the shared recognizer, use the <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>, and <xref:System.Speech.Recognition.SpeechRecognizer.State%2A> properties and the <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated>, <xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred>, <xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged>, and <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> events.</span></span>  
  
-   <span data-ttu-id="52bef-110">認識エンジンへの変更を同期するには、使用、<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>メソッド。</span><span class="sxs-lookup"><span data-stu-id="52bef-110">To synchronize changes to the recognizer, use the <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> method.</span></span> <span data-ttu-id="52bef-111">共有認識エンジンでは、1 つ以上のスレッドを使用して、タスクを実行します。</span><span class="sxs-lookup"><span data-stu-id="52bef-111">The shared recognizer uses more than one thread to perform tasks.</span></span>  
  
-   <span data-ttu-id="52bef-112">共有認識エンジンに対する入力をエミュレートするために使用して、<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>と<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>メソッド。</span><span class="sxs-lookup"><span data-stu-id="52bef-112">To emulate input to the shared recognizer, use the <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> and <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> methods.</span></span>  
  
 <span data-ttu-id="52bef-113">Windows 音声認識の構成を使用して管理、**音声プロパティ**ダイアログで、**コントロール パネルの** します。</span><span class="sxs-lookup"><span data-stu-id="52bef-113">The configuration of Windows Speech Recognition is managed by the use of the **Speech Properties** dialog in the **Control Panel**.</span></span> <span data-ttu-id="52bef-114">このインターフェイスは、既定のデスクトップの音声認識エンジンと言語、オーディオ入力デバイス、および音声認識のスリープ状態の動作の選択に使用されます。</span><span class="sxs-lookup"><span data-stu-id="52bef-114">This interface is used to select the default desktop speech recognition engine and language, the audio input device, and the sleep behavior of speech recognition.</span></span> <span data-ttu-id="52bef-115">アプリケーションの実行中に、(たとえば、音声認識が無効であるか、入力言語が変更された) Windows 音声認識の構成が変更された場合、変更はすべてに影響<xref:System.Speech.Recognition.SpeechRecognizer>オブジェクト。</span><span class="sxs-lookup"><span data-stu-id="52bef-115">If the configuration of Windows Speech Recognition is changed while the application is running, (for instance, if speech recognition is disabled or the input language is changed), the change affects all <xref:System.Speech.Recognition.SpeechRecognizer> objects.</span></span>  
  
 <span data-ttu-id="52bef-116">Windows 音声認識から独立したインプロセス音声認識エンジンを作成するには、使用、<xref:System.Speech.Recognition.SpeechRecognitionEngine>クラス。</span><span class="sxs-lookup"><span data-stu-id="52bef-116">To create an in-process speech recognizer that is independent of Windows Speech Recognition, use the <xref:System.Speech.Recognition.SpeechRecognitionEngine> class.</span></span>  
  
> [!NOTE]
>  <span data-ttu-id="52bef-117">常に呼び出す<xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A>音声レコグナイザーへの最後の参照を解放する前にします。</span><span class="sxs-lookup"><span data-stu-id="52bef-117">Always call <xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A> before you release your last reference to the speech recognizer.</span></span> <span data-ttu-id="52bef-118">それ以外の場合、使用されているリソースは解放されませんガベージ コレクターは、認識エンジン オブジェクトのまで`Finalize`メソッド。</span><span class="sxs-lookup"><span data-stu-id="52bef-118">Otherwise, the resources it is using will not be freed until the garbage collector calls the recognizer object's `Finalize` method.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="52bef-119">次の例は、音声認識文法を読み込みますを非同期のエミュレートされた入力、関連付けられている認識結果、および音声認識エンジンによって生成される、関連するイベントを示すコンソール アプリケーションの一部です。</span><span class="sxs-lookup"><span data-stu-id="52bef-119">The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</span></span>  <span data-ttu-id="52bef-120">Windows 音声認識が実行されていない場合、このアプリケーションの開始と Windows 音声認識が開始もします。</span><span class="sxs-lookup"><span data-stu-id="52bef-120">If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</span></span> <span data-ttu-id="52bef-121">Windows 音声認識がある場合、**スリープ**し、状態<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>常に null を返します。</span><span class="sxs-lookup"><span data-stu-id="52bef-121">If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.</span></span>  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
  
    // Indicate whether the asynchronous emulate recognition  
    // operation has completed.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=  
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // Start asynchronous emulated recognition.   
        // This matches the grammar and generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // Start asynchronous emulated recognition.  
        // This does not match the grammar or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  
    // Handle the SpeechRecognizeCompleted event.  
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      // Indicate the asynchronous operation is complete.  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
    <altmember cref="T:System.Speech.Recognition.Grammar" />
    <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
  </Docs>
  <Members>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechRecognizer ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.#ctor" />
      <MemberSignature Language="VB.NET" Value="Public Sub New ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; SpeechRecognizer();" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters />
      <Docs>
        <summary><span data-ttu-id="52bef-122"><see cref="T:System.Speech.Recognition.SpeechRecognizer" /> クラスの新しいインスタンスを初期化します。</span><span class="sxs-lookup"><span data-stu-id="52bef-122">Initializes a new instance of the <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> class.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-123">各<xref:System.Speech.Recognition.SpeechRecognizer>オブジェクトが音声認識文法の個別セットを保持します。</span><span class="sxs-lookup"><span data-stu-id="52bef-123">Each <xref:System.Speech.Recognition.SpeechRecognizer> object maintains a separate set of speech recognition grammars.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="52bef-124">次の例は、音声認識文法を読み込みますを非同期のエミュレートされた入力、関連付けられている認識結果、および音声認識エンジンによって生成される、関連するイベントを示すコンソール アプリケーションの一部です。</span><span class="sxs-lookup"><span data-stu-id="52bef-124">The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</span></span> <span data-ttu-id="52bef-125">Windows 音声認識が実行されていない場合、このアプリケーションの開始と Windows 音声認識が開始もします。</span><span class="sxs-lookup"><span data-stu-id="52bef-125">If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</span></span> <span data-ttu-id="52bef-126">Windows 音声認識がある場合、**スリープ**し、状態<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>常に null を返します。</span><span class="sxs-lookup"><span data-stu-id="52bef-126">If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.</span></span>  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
  
    // Indicate whether the asynchronous emulate recognition  
    // operation has completed.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=  
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // Start asynchronous emulated recognition.   
        // This matches the grammar and generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // Start asynchronous emulated recognition.  
        // This does not match the grammar or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  
    // Handle the SpeechRecognizeCompleted event.  
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      // Indicate the asynchronous operation is complete.  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
        <altmember cref="T:System.Speech.Recognition.Grammar" />
      </Docs>
    </Member>
    <Member MemberName="AudioFormat">
      <MemberSignature Language="C#" Value="public System.Speech.AudioFormat.SpeechAudioFormatInfo AudioFormat { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.AudioFormat.SpeechAudioFormatInfo AudioFormat" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.AudioFormat" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioFormat As SpeechAudioFormatInfo" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::AudioFormat::SpeechAudioFormatInfo ^ AudioFormat { System::Speech::AudioFormat::SpeechAudioFormatInfo ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioFormat : System.Speech.AudioFormat.SpeechAudioFormatInfo" Usage="System.Speech.Recognition.SpeechRecognizer.AudioFormat" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.AudioFormat.SpeechAudioFormatInfo</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="52bef-127">音声認識エンジンによって受け取られるオーディオの形式を取得します。</span><span class="sxs-lookup"><span data-stu-id="52bef-127">Gets the format of the audio being received by the speech recognizer.</span></span></summary>
        <value><span data-ttu-id="52bef-128">音声認識エンジンのオーディオ入力形式、または認識エンジンへの入力が構成されていない場合は <see langword="null" />。</span><span class="sxs-lookup"><span data-stu-id="52bef-128">The audio input format for the speech recognizer, or <see langword="null" /> if the input to the recognizer is not configured.</span></span></value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AudioLevel">
      <MemberSignature Language="C#" Value="public int AudioLevel { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance int32 AudioLevel" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.AudioLevel" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioLevel As Integer" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property int AudioLevel { int get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioLevel : int" Usage="System.Speech.Recognition.SpeechRecognizer.AudioLevel" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Int32</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="52bef-129">音声認識エンジンによって受け取られるオーディオのレベルを取得します。</span><span class="sxs-lookup"><span data-stu-id="52bef-129">Gets the level of the audio being received by the speech recognizer.</span></span></summary>
        <value><span data-ttu-id="52bef-130">音声認識エンジンへの入力のオーディオ レベル (0 ～ 100)。</span><span class="sxs-lookup"><span data-stu-id="52bef-130">The audio level of the input to the speech recognizer, from 0 through 100.</span></span></value>
        <remarks>To be added.</remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated" />
      </Docs>
    </Member>
    <Member MemberName="AudioLevelUpdated">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt; AudioLevelUpdated;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt; AudioLevelUpdated" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event AudioLevelUpdated As EventHandler(Of AudioLevelUpdatedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::AudioLevelUpdatedEventArgs ^&gt; ^ AudioLevelUpdated;" />
      <MemberSignature Language="F#" Value="member this.AudioLevelUpdated : EventHandler&lt;System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt; " Usage="member this.AudioLevelUpdated : System.EventHandler&lt;System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="52bef-131">共有認識機能がオーディオ入力のレベルを報告すると発生します。</span><span class="sxs-lookup"><span data-stu-id="52bef-131">Occurs when the shared recognizer reports the level of its audio input.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-132">認識エンジンは、1 秒間に複数回には、このイベントを発生させます。</span><span class="sxs-lookup"><span data-stu-id="52bef-132">The recognizer raises this event multiple times per second.</span></span> <span data-ttu-id="52bef-133">イベントが発生する頻度は、アプリケーションが実行されているコンピューターによって異なります。</span><span class="sxs-lookup"><span data-stu-id="52bef-133">The frequency with which the event is raised depends on the computer on which the application is running.</span></span>  
  
 <span data-ttu-id="52bef-134">イベントの時点で、オーディオ レベルを取得する、<xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A>プロパティ、関連付けられている<xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs>します。</span><span class="sxs-lookup"><span data-stu-id="52bef-134">To get the audio level at the time of the event, use the <xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A> property of the associated <xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs>.</span></span> <span data-ttu-id="52bef-135">現在、認識エンジンに対する入力のオーディオ レベルを取得する認識エンジンを使用して、<xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A>プロパティ。</span><span class="sxs-lookup"><span data-stu-id="52bef-135">To get the current audio level of the input to the recognizer, use the recognizer's <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A> property.</span></span>  
  
 <span data-ttu-id="52bef-136">デリゲートを作成するとき、`AudioLevelUpdated`イベント、イベントを処理するメソッドを識別します。</span><span class="sxs-lookup"><span data-stu-id="52bef-136">When you create a delegate for an `AudioLevelUpdated` event, you identify the method that will handle the event.</span></span> <span data-ttu-id="52bef-137">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</span><span class="sxs-lookup"><span data-stu-id="52bef-137">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="52bef-138">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</span><span class="sxs-lookup"><span data-stu-id="52bef-138">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="52bef-139">イベント ハンドラー デリゲートの詳細については、次を参照してください。[イベントとデリゲート](https://go.microsoft.com/fwlink/?LinkId=162418)します。</span><span class="sxs-lookup"><span data-stu-id="52bef-139">For more information about event-handler delegates, see [Events and Delegates](https://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="52bef-140">次の例は、ハンドラーを追加、`AudioLevelUpdated`イベントを<xref:System.Speech.Recognition.SpeechRecognizer>オブジェクト。</span><span class="sxs-lookup"><span data-stu-id="52bef-140">The following example adds a handler for the `AudioLevelUpdated` event to a <xref:System.Speech.Recognition.SpeechRecognizer> object.</span></span> <span data-ttu-id="52bef-141">ハンドラーは、コンソールに新しいオーディオ レベルを出力します。</span><span class="sxs-lookup"><span data-stu-id="52bef-141">The handler outputs the new audio level to the console.</span></span>  
  
```csharp  
private SpeechRecognizer recognizer;  
  
// Initialize the SpeechRecognizer object.   
private void Initialize()  
{  
  recognizer = new SpeechRecognizer();  
  
  // Add an event handler for the AudioLevelUpdated event.  
  recognizer.AudioLevelUpdated +=   
    new EventHandler<AudioLevelUpdatedEventArgs>(recognizer_AudioLevelUpdated);  
  
  // Add other initialization code here.  
  
}  
  
// Write the audio level to the console when the AudioLevelUpdated event is raised.  
void recognizer_AudioLevelUpdated(object sender, AudioLevelUpdatedEventArgs e)  
{  
  Console.WriteLine("The audio level is now: {0}.", e.AudioLevel);  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.AudioLevelUpdatedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioLevel" />
      </Docs>
    </Member>
    <Member MemberName="AudioPosition">
      <MemberSignature Language="C#" Value="public TimeSpan AudioPosition { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.TimeSpan AudioPosition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioPosition As TimeSpan" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property TimeSpan AudioPosition { TimeSpan get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioPosition : TimeSpan" Usage="System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.TimeSpan</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="52bef-142">音声認識エンジンに入力を提供しているデバイスによって生成されているオーディオ ストリーム内の現在の位置を取得します。</span><span class="sxs-lookup"><span data-stu-id="52bef-142">Gets the current location in the audio stream being generated by the device that is providing input to the speech recognizer.</span></span></summary>
        <value><span data-ttu-id="52bef-143">入力を受け取った音声認識エンジンのオーディオ入力ストリームの現在の位置。</span><span class="sxs-lookup"><span data-stu-id="52bef-143">The current location in the speech recognizer's audio input stream through which it has received input.</span></span></value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-144">共有認識エンジンは、デスクトップの音声認識の実行中に、入力を受け取ります。</span><span class="sxs-lookup"><span data-stu-id="52bef-144">The shared recognizer receives input while the desktop speech recognition is running.</span></span>  
  
 <span data-ttu-id="52bef-145">`AudioPosition`プロパティは、生成されたオーディオ ストリーム内の入力デバイスの位置を参照します。</span><span class="sxs-lookup"><span data-stu-id="52bef-145">The `AudioPosition` property references the input device's position in its generated audio stream.</span></span> <span data-ttu-id="52bef-146">これに対し、<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>プロパティがオーディオ入力の処理で認識エンジンの位置を参照します。</span><span class="sxs-lookup"><span data-stu-id="52bef-146">By contrast, the <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> property references the recognizer's position in processing audio input.</span></span> <span data-ttu-id="52bef-147">これらの位置は、さまざまなであることができます。</span><span class="sxs-lookup"><span data-stu-id="52bef-147">These positions can be different.</span></span>  <span data-ttu-id="52bef-148">たとえば、認識エンジンが受け取った場合どの it されていない入力が、認識結果が次の値を生成、<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>プロパティは、の値より小さい、<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>プロパティ。</span><span class="sxs-lookup"><span data-stu-id="52bef-148">For example, if the recognizer has received input for which it has not yet generated a recognition result then the value of the <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> property is less than the value of the <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> property.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="52bef-149">次の例では、共有音声認識エンジンは、音声入力に一致するのに口述文法を使用します。</span><span class="sxs-lookup"><span data-stu-id="52bef-149">In the following example, the shared speech recognizer uses a dictation grammar to match speech input.</span></span> <span data-ttu-id="52bef-150">ハンドラーを<xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>をコンソールに出力イベント、 <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>、 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>、および<xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A>音声認識エンジンがその入力に音声を検出した場合。</span><span class="sxs-lookup"><span data-stu-id="52bef-150">A handler for the <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected> event writes to the console the <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>, and  <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A> when the speech recognizer detects speech at its input.</span></span>  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
      // Add handlers for events.  
      recognizer.LoadGrammarCompleted +=   
        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
      recognizer.SpeechRecognized +=   
        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
      recognizer.StateChanged +=   
        new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
      recognizer.SpeechDetected +=   
        new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  
  
      // Create a dictation grammar.  
      Grammar dictation = new DictationGrammar();  
      dictation.Name = "Dictation";  
  
      // Load the grammar object to the recognizer.  
      recognizer.LoadGrammarAsync(dictation);  
  
      // Keep the console window open.  
      Console.ReadLine();  
    }  
  
    // Gather information about detected speech and write it to the console.  
    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  
    {  
      Console.WriteLine();  
      Console.WriteLine("Speech detected:");  
      Console.WriteLine("  Audio level: " + recognizer.AudioLevel);  
      Console.WriteLine("  Audio position: " + recognizer.AudioPosition);  
      Console.WriteLine("  Recognizer audio position: " + recognizer.RecognizerAudioPosition);  
    }  
  
    // Write the text of the recognition result to the console.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {   
      Console.WriteLine("Speech recognized: " + e.Result.Text);  
  
      // Add event handler code here.  
    }  
  
    // Write the name of the loaded grammar to the console.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
    }  
  
    // Put the shared speech recognizer into "listening" mode.  
    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
      if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="AudioSignalProblemOccurred">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt; AudioSignalProblemOccurred;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt; AudioSignalProblemOccurred" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event AudioSignalProblemOccurred As EventHandler(Of AudioSignalProblemOccurredEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::AudioSignalProblemOccurredEventArgs ^&gt; ^ AudioSignalProblemOccurred;" />
      <MemberSignature Language="F#" Value="member this.AudioSignalProblemOccurred : EventHandler&lt;System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt; " Usage="member this.AudioSignalProblemOccurred : System.EventHandler&lt;System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="52bef-151">認識機能がオーディオ信号で問題を検出したときに発生します。</span><span class="sxs-lookup"><span data-stu-id="52bef-151">Occurs when the recognizer encounters a problem in the audio signal.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-152">どのような問題が発生させるには、使用、<xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A>プロパティ、関連付けられている<xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>します。</span><span class="sxs-lookup"><span data-stu-id="52bef-152">To get which problem occurred, use the <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A> property of the associated <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>.</span></span>  
  
 <span data-ttu-id="52bef-153">デリゲートを作成するとき、`AudioSignalProblemOccurred`イベント、イベントを処理するメソッドを識別します。</span><span class="sxs-lookup"><span data-stu-id="52bef-153">When you create a delegate for an `AudioSignalProblemOccurred` event, you identify the method that will handle the event.</span></span> <span data-ttu-id="52bef-154">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</span><span class="sxs-lookup"><span data-stu-id="52bef-154">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="52bef-155">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</span><span class="sxs-lookup"><span data-stu-id="52bef-155">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="52bef-156">イベント ハンドラー デリゲートの詳細については、次を参照してください。[イベントとデリゲート](https://go.microsoft.com/fwlink/?LinkId=162418)します。</span><span class="sxs-lookup"><span data-stu-id="52bef-156">For more information about event-handler delegates, see [Events and Delegates](https://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="52bef-157">次の例は、に関する情報を収集するイベント ハンドラーを定義、`AudioSignalProblemOccurred`イベント。</span><span class="sxs-lookup"><span data-stu-id="52bef-157">The following example defines an event handler that gathers information about an `AudioSignalProblemOccurred` event.</span></span>  
  
```  
private SpeechRecognizer recognizer;  
  
// Initialize the speech recognition engine.  
private void Initialize()  
{  
  recognizer = new SpeechRecognizer();  
  
  // Add a handler for the AudioSignalProblemOccurred event.  
  recognizer.AudioSignalProblemOccurred +=   
    new EventHandler<AudioSignalProblemOccurredEventArgs>(  
      recognizer_AudioSignalProblemOccurred);  
}  
  
// Gather information when the AudioSignalProblemOccurred event is raised.  
void recognizer_AudioSignalProblemOccurred(object sender, AudioSignalProblemOccurredEventArgs e)  
{  
  StringBuilder details = new StringBuilder();  
  
  details.AppendLine("Audio signal problem information:");  
  details.AppendFormat(  
    " Audio level:               {0}" + Environment.NewLine +  
    " Audio position:            {1}" + Environment.NewLine +  
    " Audio signal problem:      {2}" + Environment.NewLine +  
    " Recognition engine audio position: {3}" + Environment.NewLine,  
    e.AudioLevel, e.AudioPosition,  e.AudioSignalProblem,  
    e.recoEngineAudioPosition);  
  
  // Insert additional event handler code here.  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.AudioSignalProblem" />
        <altmember cref="T:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs" />
      </Docs>
    </Member>
    <Member MemberName="AudioState">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.AudioState AudioState { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.Speech.Recognition.AudioState AudioState" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.AudioState" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioState As AudioState" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::AudioState AudioState { System::Speech::Recognition::AudioState get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioState : System.Speech.Recognition.AudioState" Usage="System.Speech.Recognition.SpeechRecognizer.AudioState" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.AudioState</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="52bef-158">音声認識エンジンによって受け取られるオーディオの状態を取得します。</span><span class="sxs-lookup"><span data-stu-id="52bef-158">Gets the state of the audio being received by the speech recognizer.</span></span></summary>
        <value><span data-ttu-id="52bef-159">音声レコグナイザーへのオーディオ入力の状態。</span><span class="sxs-lookup"><span data-stu-id="52bef-159">The state of the audio input to the speech recognizer.</span></span></value>
        <remarks>To be added.</remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged" />
      </Docs>
    </Member>
    <Member MemberName="AudioStateChanged">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.AudioStateChangedEventArgs&gt; AudioStateChanged;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.AudioStateChangedEventArgs&gt; AudioStateChanged" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event AudioStateChanged As EventHandler(Of AudioStateChangedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::AudioStateChangedEventArgs ^&gt; ^ AudioStateChanged;" />
      <MemberSignature Language="F#" Value="member this.AudioStateChanged : EventHandler&lt;System.Speech.Recognition.AudioStateChangedEventArgs&gt; " Usage="member this.AudioStateChanged : System.EventHandler&lt;System.Speech.Recognition.AudioStateChangedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.AudioStateChangedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="52bef-160">オーディオの状態変化が認識機能によって受け取られると発生します。</span><span class="sxs-lookup"><span data-stu-id="52bef-160">Occurs when the state changes in the audio being received by the recognizer.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-161">イベントの時点でオーディオの状態を取得する、<xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A>プロパティ、関連付けられている<xref:System.Speech.Recognition.AudioStateChangedEventArgs>します。</span><span class="sxs-lookup"><span data-stu-id="52bef-161">To get the audio state at the time of the event, use the <xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A> property of the associated <xref:System.Speech.Recognition.AudioStateChangedEventArgs>.</span></span> <span data-ttu-id="52bef-162">認識エンジンへの入力の現在のオーディオの状態を取得する認識エンジンを使用して、<xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A>プロパティ。</span><span class="sxs-lookup"><span data-stu-id="52bef-162">To get the current audio state of the input to the recognizer, use the recognizer's <xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A> property.</span></span> <span data-ttu-id="52bef-163">オーディオの状態に関する詳細については、次を参照してください。、<xref:System.Speech.Recognition.AudioState>列挙体。</span><span class="sxs-lookup"><span data-stu-id="52bef-163">For more information about audio state, see the <xref:System.Speech.Recognition.AudioState> enumeration.</span></span>  
  
 <span data-ttu-id="52bef-164">デリゲートを作成するとき、`AudioStateChanged`イベント、イベントを処理するメソッドを識別します。</span><span class="sxs-lookup"><span data-stu-id="52bef-164">When you create a delegate for an `AudioStateChanged` event, you identify the method that will handle the event.</span></span> <span data-ttu-id="52bef-165">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</span><span class="sxs-lookup"><span data-stu-id="52bef-165">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="52bef-166">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</span><span class="sxs-lookup"><span data-stu-id="52bef-166">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="52bef-167">イベント ハンドラー デリゲートの詳細については、次を参照してください。[イベントとデリゲート](https://go.microsoft.com/fwlink/?LinkId=162418)します。</span><span class="sxs-lookup"><span data-stu-id="52bef-167">For more information about event-handler delegates, see [Events and Delegates](https://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="52bef-168">次の例のハンドラーを使用して、`AudioStateChanged`レコグナイザーを記述するイベントの新しい<xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A>コンソールに変更されるたびのメンバーを使用して、<xref:System.Speech.Recognition.AudioState>列挙体。</span><span class="sxs-lookup"><span data-stu-id="52bef-168">The following example uses a handler for the `AudioStateChanged` event to write the recognizer's new <xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A> to the console each time it changes using a member of the <xref:System.Speech.Recognition.AudioState> enumeration.</span></span>  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
        // Create and load a grammar.  
        Grammar dictation = new DictationGrammar();  
        dictation.Name = "Dictation Grammar";  
        recognizer.LoadGrammar(dictation);  
  
        // Attach event handlers.  
        recognizer.AudioStateChanged +=  
          new EventHandler<AudioStateChangedEventArgs>(recognizer_AudioStateChanged);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.StateChanged +=  
          new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
  
    // Handle the AudioStateChanged event.  
    static void recognizer_AudioStateChanged(object sender, AudioStateChangedEventArgs e)  
    {  
      Console.WriteLine("The new audio state is: " + e.AudioState);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null && e.Result.Text != null)  
      {  
        Console.WriteLine();  
        Console.WriteLine("  Recognized text =  {0}", e.Result.Text);  
        Console.WriteLine();  
      }  
      else  
      {  
        Console.WriteLine("  Recognized text not available.");  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Done.");  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Put the recognizer into Listening mode.  
    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
      if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        Console.WriteLine();  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.AudioState" />
        <altmember cref="T:System.Speech.Recognition.AudioStateChangedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioState" />
      </Docs>
    </Member>
    <MemberGroup MemberName="Dispose">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary><span data-ttu-id="52bef-169"><see cref="T:System.Speech.Recognition.SpeechRecognizer" /> オブジェクトを破棄します。</span><span class="sxs-lookup"><span data-stu-id="52bef-169">Disposes the <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> object.</span></span></summary>
      </Docs>
    </MemberGroup>
    <Member MemberName="Dispose">
      <MemberSignature Language="C#" Value="public void Dispose ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig newslot virtual instance void Dispose() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.Dispose" />
      <MemberSignature Language="VB.NET" Value="Public Sub Dispose ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; virtual void Dispose();" />
      <MemberSignature Language="F#" Value="abstract member Dispose : unit -&gt; unit&#xA;override this.Dispose : unit -&gt; unit" Usage="speechRecognizer.Dispose " />
      <MemberType>Method</MemberType>
      <Implements>
        <InterfaceMember>M:System.IDisposable.Dispose</InterfaceMember>
      </Implements>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary><span data-ttu-id="52bef-170"><see cref="T:System.Speech.Recognition.SpeechRecognizer" /> オブジェクトを破棄します。</span><span class="sxs-lookup"><span data-stu-id="52bef-170">Disposes the <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> object.</span></span></summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Dispose">
      <MemberSignature Language="C#" Value="protected virtual void Dispose (bool disposing);" />
      <MemberSignature Language="ILAsm" Value=".method familyhidebysig newslot virtual instance void Dispose(bool disposing) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.Dispose(System.Boolean)" />
      <MemberSignature Language="VB.NET" Value="Protected Overridable Sub Dispose (disposing As Boolean)" />
      <MemberSignature Language="C++ CLI" Value="protected:&#xA; virtual void Dispose(bool disposing);" />
      <MemberSignature Language="F#" Value="abstract member Dispose : bool -&gt; unit&#xA;override this.Dispose : bool -&gt; unit" Usage="speechRecognizer.Dispose disposing" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="disposing" Type="System.Boolean" />
      </Parameters>
      <Docs>
        <param name="disposing"><span data-ttu-id="52bef-171">マネージド リソースとアンマネージド リソースの両方を解放する場合は <see langword="true" />。アンマネージド リソースだけを解放する場合は <see langword="false" />。</span><span class="sxs-lookup"><span data-stu-id="52bef-171"><see langword="true" /> to release both managed and unmanaged resources; <see langword="false" /> to release only unmanaged resources.</span></span></param>
        <summary><span data-ttu-id="52bef-172"><see cref="T:System.Speech.Recognition.SpeechRecognizer" /> オブジェクトを破棄し、セッション中に使用するリソースを解放します。</span><span class="sxs-lookup"><span data-stu-id="52bef-172">Disposes the <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> object and releases resources used during the session.</span></span></summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="EmulateRecognize">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary><span data-ttu-id="52bef-173">同期音声認識に音声ではなくテキストを使用して、共有音声認識エンジンに対する入力をエミュレートします。</span><span class="sxs-lookup"><span data-stu-id="52bef-173">Emulates input to the shared speech recognizer, using text instead of audio for synchronous speech recognition.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-174">これらのメソッドは、システム オーディオの入力をバイパスします。</span><span class="sxs-lookup"><span data-stu-id="52bef-174">These methods bypass the system audio input.</span></span> <span data-ttu-id="52bef-175">これは、アプリケーションまたは文法のデバッグまたはテストするときに役立ちます。</span><span class="sxs-lookup"><span data-stu-id="52bef-175">This can be helpful when you are testing or debugging an application or grammar.</span></span>  
  
> [!NOTE]
>  <span data-ttu-id="52bef-176">Windows 音声認識がある場合、**スリープ**状態では、これらのメソッドが返す`null`します。</span><span class="sxs-lookup"><span data-stu-id="52bef-176">If Windows Speech Recognition is in the **Sleeping** state, then these methods return `null`.</span></span>  
  
 <span data-ttu-id="52bef-177">共有認識エンジンが発生、 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>、 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>、 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>、および<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>イベント認識操作がエミュレートされていない場合と同様です。</span><span class="sxs-lookup"><span data-stu-id="52bef-177">The shared recognizer raises the <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>, and <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> events as if the recognition operation is not emulated.</span></span> <span data-ttu-id="52bef-178">認識エンジンは、新しい行と余分な空白を無視し、区切り記号をリテラルの入力として扱います。</span><span class="sxs-lookup"><span data-stu-id="52bef-178">The recognizer ignores new lines and extra white space and treats punctuation as literal input.</span></span>  
  
> [!NOTE]
>  <span data-ttu-id="52bef-179"><xref:System.Speech.Recognition.RecognitionResult>エミュレートされた入力に応答共有認識エンジンによって生成されたオブジェクトの値を持つ`null`の<xref:System.Speech.Recognition.RecognitionResult.Audio%2A>プロパティ。</span><span class="sxs-lookup"><span data-stu-id="52bef-179">The <xref:System.Speech.Recognition.RecognitionResult> object generated by the shared recognizer in response to emulated input has a value of `null` for its <xref:System.Speech.Recognition.RecognitionResult.Audio%2A> property.</span></span>  
  
 <span data-ttu-id="52bef-180">非同期認識をエミュレートするために使用して、<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>メソッド。</span><span class="sxs-lookup"><span data-stu-id="52bef-180">To emulate asynchronous recognition, use the <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> method.</span></span>  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="EmulateRecognize">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.RecognitionResult EmulateRecognize(string inputText) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Function EmulateRecognize (inputText As String) As RecognitionResult" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::RecognitionResult ^ EmulateRecognize(System::String ^ inputText);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognize : string -&gt; System.Speech.Recognition.RecognitionResult" Usage="speechRecognizer.EmulateRecognize inputText" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognitionResult</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="inputText" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="inputText"><span data-ttu-id="52bef-181">認識操作の入力。</span><span class="sxs-lookup"><span data-stu-id="52bef-181">The input for the recognition operation.</span></span></param>
        <summary><span data-ttu-id="52bef-182">同期音声認識に音声ではなくテキストを使用して、共有音声認識エンジンに対する語句の入力をエミュレートします。</span><span class="sxs-lookup"><span data-stu-id="52bef-182">Emulates input of a phrase to the shared speech recognizer, using text instead of audio for synchronous speech recognition.</span></span></summary>
        <returns><span data-ttu-id="52bef-183">認識操作の認識結果。操作に成功しなかった場合や、Windows の音声認識が**スリープ**状態である場合は <see langword="null" />。</span><span class="sxs-lookup"><span data-stu-id="52bef-183">The recognition result for the recognition operation, or <see langword="null" />, if the operation is not successful or Windows Speech Recognition is in the **Sleeping** state.</span></span></returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-184">Vista および Windows 7 に付属しているレコグナイザーは大文字小文字を区別し、入力語句に文法規則を適用する場合は、幅を文字します。</span><span class="sxs-lookup"><span data-stu-id="52bef-184">The recognizers that ship with Vista and Windows 7 ignore case and character width when applying grammar rules to the input phrase.</span></span> <span data-ttu-id="52bef-185">この種類の比較の詳細については、次を参照してください。、<xref:System.Globalization.CompareOptions>列挙値<xref:System.Globalization.CompareOptions.OrdinalIgnoreCase>と<xref:System.Globalization.CompareOptions.IgnoreWidth>します。</span><span class="sxs-lookup"><span data-stu-id="52bef-185">For more information about this type of comparison, see the <xref:System.Globalization.CompareOptions> enumeration values <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> and <xref:System.Globalization.CompareOptions.IgnoreWidth>.</span></span> <span data-ttu-id="52bef-186">認識対象も新しい行と余分な空白を無視し、区切り記号をリテラルの入力として扱います。</span><span class="sxs-lookup"><span data-stu-id="52bef-186">The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="52bef-187">次の例では、共有認識エンジンに対するサンプルの文法を読み込み、認識エンジンに対する入力をエミュレートします。</span><span class="sxs-lookup"><span data-stu-id="52bef-187">The following example loads a sample grammar to the shared recognizer and emulates input to the recognizer.</span></span> <span data-ttu-id="52bef-188">Windows 音声認識が実行されていない場合、このアプリケーションの開始と Windows 音声認識が開始もします。</span><span class="sxs-lookup"><span data-stu-id="52bef-188">If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</span></span> <span data-ttu-id="52bef-189">Windows 音声認識がある場合、**スリープ**し、状態<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>常に null を返します。</span><span class="sxs-lookup"><span data-stu-id="52bef-189">If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> always returns null.</span></span>  
  
```csharp  
  
using System;  
using System.Speech.Recognition;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
  
    static void Main(string[] args)  
    {  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
  
        recognizer.LoadGrammar(testGrammar);  
  
        RecognitionResult result;  
  
        // This EmulateRecognize call matches the grammar and returns a  
        // recognition result.  
        result = recognizer.EmulateRecognize("testing testing");  
        OutputResult(result);  
  
        // This EmulateRecognize call does not match the grammar and   
        // returns null.  
        result = recognizer.EmulateRecognize("testing one two three");  
        OutputResult(result);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Output information about a recognition result to the console.  
    private static void OutputResult(RecognitionResult result)  
    {  
      if (result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognize">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognitionResult EmulateRecognize (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.RecognitionResult EmulateRecognize(class System.Speech.Recognition.RecognizedWordUnit[] wordUnits, valuetype System.Globalization.CompareOptions compareOptions) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::RecognitionResult ^ EmulateRecognize(cli::array &lt;System::Speech::Recognition::RecognizedWordUnit ^&gt; ^ wordUnits, System::Globalization::CompareOptions compareOptions);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognize : System.Speech.Recognition.RecognizedWordUnit[] * System.Globalization.CompareOptions -&gt; System.Speech.Recognition.RecognitionResult" Usage="speechRecognizer.EmulateRecognize (wordUnits, compareOptions)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognitionResult</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="wordUnits" Type="System.Speech.Recognition.RecognizedWordUnit[]" />
        <Parameter Name="compareOptions" Type="System.Globalization.CompareOptions" />
      </Parameters>
      <Docs>
        <param name="wordUnits"><span data-ttu-id="52bef-190">認識操作のための必要を格納する単語単位の配列。</span><span class="sxs-lookup"><span data-stu-id="52bef-190">An array of word units that contains the input for the recognition operation.</span></span></param>
        <param name="compareOptions"><span data-ttu-id="52bef-191">エミュレートされた認識操作に使用する比較の種類を示す列挙値のビットごとの組み合わせ。</span><span class="sxs-lookup"><span data-stu-id="52bef-191">A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</span></span></param>
        <summary><span data-ttu-id="52bef-192">同期音声認識にオーディオではなくテキストを使用して、共有された音声認識エンジンに対する特定の語の入力をエミュレートし、語と読み込まれている音声認識文法との間で認識エンジンが Unicode 比較をどのように行うかを指定します。</span><span class="sxs-lookup"><span data-stu-id="52bef-192">Emulates input of specific words to the shared speech recognizer, using text instead of audio for synchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the words and the loaded speech recognition grammars.</span></span></summary>
        <returns><span data-ttu-id="52bef-193">認識操作の認識結果。操作に成功しなかった場合や、Windows の音声認識が**スリープ**状態である場合は <see langword="null" />。</span><span class="sxs-lookup"><span data-stu-id="52bef-193">The recognition result for the recognition operation, or <see langword="null" />, if the operation is not successful or Windows Speech Recognition is in the **Sleeping** state.</span></span></returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-194">このメソッドを作成、<xref:System.Speech.Recognition.RecognitionResult>オブジェクトで提供される情報を使用して、`wordUnits`パラメーター。</span><span class="sxs-lookup"><span data-stu-id="52bef-194">This method creates a <xref:System.Speech.Recognition.RecognitionResult> object using the information provided in the `wordUnits` parameter.</span></span>  
  
 <span data-ttu-id="52bef-195">認識エンジンを使用して、`compareOptions`入力語句に文法規則が適用するときにします。</span><span class="sxs-lookup"><span data-stu-id="52bef-195">The recognizer uses the `compareOptions` when it applies grammar rules to the input phrase.</span></span> <span data-ttu-id="52bef-196">Vista および Windows 7 に付属しているレコグナイザー場合大文字小文字は無視、<xref:System.Globalization.CompareOptions.OrdinalIgnoreCase>または<xref:System.Globalization.CompareOptions.IgnoreCase>値が存在します。</span><span class="sxs-lookup"><span data-stu-id="52bef-196">The recognizers that ship with Vista and Windows 7 ignore case if the <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> or <xref:System.Globalization.CompareOptions.IgnoreCase> value is present.</span></span> <span data-ttu-id="52bef-197">認識対象は、文字幅を常に無視して、カナ型を無視することはありません。</span><span class="sxs-lookup"><span data-stu-id="52bef-197">The recognizers always ignore the character width and never ignore the Kana type.</span></span> <span data-ttu-id="52bef-198">認識は、新しい行と余分な空白を無視して、区切り記号をリテラルの入力として扱います。</span><span class="sxs-lookup"><span data-stu-id="52bef-198">The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</span></span> <span data-ttu-id="52bef-199">詳細については、文字幅、ひらがなとカタカナは、次を参照してください。、<xref:System.Globalization.CompareOptions>列挙体。</span><span class="sxs-lookup"><span data-stu-id="52bef-199">For more information about character width and Kana type, see the <xref:System.Globalization.CompareOptions> enumeration.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognize">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText, System.Globalization.CompareOptions compareOptions);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.RecognitionResult EmulateRecognize(string inputText, valuetype System.Globalization.CompareOptions compareOptions) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::RecognitionResult ^ EmulateRecognize(System::String ^ inputText, System::Globalization::CompareOptions compareOptions);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognize : string * System.Globalization.CompareOptions -&gt; System.Speech.Recognition.RecognitionResult" Usage="speechRecognizer.EmulateRecognize (inputText, compareOptions)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognitionResult</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="inputText" Type="System.String" />
        <Parameter Name="compareOptions" Type="System.Globalization.CompareOptions" />
      </Parameters>
      <Docs>
        <param name="inputText"><span data-ttu-id="52bef-200">認識操作の入力語句。</span><span class="sxs-lookup"><span data-stu-id="52bef-200">The input phrase for the recognition operation.</span></span></param>
        <param name="compareOptions"><span data-ttu-id="52bef-201">エミュレートされた認識操作に使用する比較の種類を示す列挙値のビットごとの組み合わせ。</span><span class="sxs-lookup"><span data-stu-id="52bef-201">A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</span></span></param>
        <summary><span data-ttu-id="52bef-202">同期音声認識にオーディオではなくテキストを使用して、共有された音声認識エンジンに対するフレーズの入力をエミュレートし、フレーズと読み込まれている音声認識文法との間で認識エンジンが Unicode 比較をどのように行うかを指定します。</span><span class="sxs-lookup"><span data-stu-id="52bef-202">Emulates input of a phrase to the shared speech recognizer, using text instead of audio for synchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the phrase and the loaded speech recognition grammars.</span></span></summary>
        <returns><span data-ttu-id="52bef-203">認識操作の認識結果。操作に成功しなかった場合や、Windows の音声認識が**スリープ**状態である場合は <see langword="null" />。</span><span class="sxs-lookup"><span data-stu-id="52bef-203">The recognition result for the recognition operation, or <see langword="null" />, if the operation is not successful or Windows Speech Recognition is in the **Sleeping** state.</span></span></returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-204">認識エンジンを使用して、`compareOptions`入力語句に文法規則が適用するときにします。</span><span class="sxs-lookup"><span data-stu-id="52bef-204">The recognizer uses the `compareOptions` when it applies grammar rules to the input phrase.</span></span> <span data-ttu-id="52bef-205">Vista および Windows 7 に付属しているレコグナイザー場合大文字小文字は無視、<xref:System.Globalization.CompareOptions.OrdinalIgnoreCase>または<xref:System.Globalization.CompareOptions.IgnoreCase>値が存在します。</span><span class="sxs-lookup"><span data-stu-id="52bef-205">The recognizers that ship with Vista and Windows 7 ignore case if the <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> or <xref:System.Globalization.CompareOptions.IgnoreCase> value is present.</span></span> <span data-ttu-id="52bef-206">認識対象は、文字幅を常に無視して、カナ型を無視することはありません。</span><span class="sxs-lookup"><span data-stu-id="52bef-206">The recognizers always ignore the character width and never ignore the Kana type.</span></span> <span data-ttu-id="52bef-207">認識は、新しい行と余分な空白を無視して、区切り記号をリテラルの入力として扱います。</span><span class="sxs-lookup"><span data-stu-id="52bef-207">The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</span></span> <span data-ttu-id="52bef-208">詳細については、文字幅、ひらがなとカタカナは、次を参照してください。、<xref:System.Globalization.CompareOptions>列挙体。</span><span class="sxs-lookup"><span data-stu-id="52bef-208">For more information about character width and Kana type, see the <xref:System.Globalization.CompareOptions> enumeration.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <MemberGroup MemberName="EmulateRecognizeAsync">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary><span data-ttu-id="52bef-209">非同期音声認識に音声ではなくテキストを使用して、共有音声認識エンジンに対する入力をエミュレートします。</span><span class="sxs-lookup"><span data-stu-id="52bef-209">Emulates input to the shared speech recognizer, using text instead of audio for asynchronous speech recognition.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-210">これらのメソッドは、システム オーディオの入力をバイパスします。</span><span class="sxs-lookup"><span data-stu-id="52bef-210">These methods bypass the system audio input.</span></span> <span data-ttu-id="52bef-211">これは、アプリケーションまたは文法のデバッグまたはテストするときに役立ちます。</span><span class="sxs-lookup"><span data-stu-id="52bef-211">This can be helpful when you are testing or debugging an application or grammar.</span></span>  
  
 <span data-ttu-id="52bef-212">共有認識エンジンが発生、 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>、 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>、 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>、および<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>イベント認識操作がエミュレートされていない場合と同様です。</span><span class="sxs-lookup"><span data-stu-id="52bef-212">The shared recognizer raises the <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>, and <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> events as if the recognition operation is not emulated.</span></span> <span data-ttu-id="52bef-213">認識エンジンには、非同期認識操作が完了すると、生成、<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted>イベント。</span><span class="sxs-lookup"><span data-stu-id="52bef-213">When the recognizer completes the asynchronous recognition operation, it raises the <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted> event.</span></span> <span data-ttu-id="52bef-214">認識エンジンは、新しい行と余分な空白を無視し、区切り記号をリテラルの入力として扱います。</span><span class="sxs-lookup"><span data-stu-id="52bef-214">The recognizer ignores new lines and extra white space and treats punctuation as literal input.</span></span>  
  
> [!NOTE]
>  <span data-ttu-id="52bef-215">Windows 音声認識がある場合、**スリープ**状態では、共有認識エンジンが入力を処理しないは発生しませんし、<xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>関連のイベントと、発生させるものの、<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted>イベント。</span><span class="sxs-lookup"><span data-stu-id="52bef-215">If Windows Speech Recognition is in the **Sleeping** state, then the shared recognizer does not process input and does not raise the <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected> and related events, but still raises the <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted> event.</span></span>  
  
> [!NOTE]
>  <span data-ttu-id="52bef-216"><xref:System.Speech.Recognition.RecognitionResult>エミュレートされた入力に応答共有認識エンジンによって生成されたオブジェクトの値を持つ`null`の<xref:System.Speech.Recognition.RecognitionResult.Audio%2A>プロパティ。</span><span class="sxs-lookup"><span data-stu-id="52bef-216">The <xref:System.Speech.Recognition.RecognitionResult> object generated by the shared recognizer in response to emulated input has a value of `null` for its <xref:System.Speech.Recognition.RecognitionResult.Audio%2A> property.</span></span>  
  
 <span data-ttu-id="52bef-217">同期の認識をエミュレートするために使用して、<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>メソッド。</span><span class="sxs-lookup"><span data-stu-id="52bef-217">To emulate synchronous recognition, use the <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> method.</span></span>  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="EmulateRecognizeAsync">
      <MemberSignature Language="C#" Value="public void EmulateRecognizeAsync (string inputText);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EmulateRecognizeAsync(string inputText) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub EmulateRecognizeAsync (inputText As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EmulateRecognizeAsync(System::String ^ inputText);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognizeAsync : string -&gt; unit" Usage="speechRecognizer.EmulateRecognizeAsync inputText" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="inputText" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="inputText"><span data-ttu-id="52bef-218">認識操作の入力。</span><span class="sxs-lookup"><span data-stu-id="52bef-218">The input for the recognition operation.</span></span></param>
        <summary><span data-ttu-id="52bef-219">非同期音声認識に音声ではなくテキストを使用して、共有音声認識エンジンに対する語句の入力をエミュレートします。</span><span class="sxs-lookup"><span data-stu-id="52bef-219">Emulates input of a phrase to the shared speech recognizer, using text instead of audio for asynchronous speech recognition.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-220">Vista および Windows 7 に付属しているレコグナイザーは大文字小文字を区別し、入力語句に文法規則を適用する場合は、幅を文字します。</span><span class="sxs-lookup"><span data-stu-id="52bef-220">The recognizers that ship with Vista and Windows 7 ignore case and character width when applying grammar rules to the input phrase.</span></span> <span data-ttu-id="52bef-221">この種類の比較の詳細については、次を参照してください。、<xref:System.Globalization.CompareOptions>列挙値<xref:System.Globalization.CompareOptions.OrdinalIgnoreCase>と<xref:System.Globalization.CompareOptions.IgnoreWidth>します。</span><span class="sxs-lookup"><span data-stu-id="52bef-221">For more information about this type of comparison, see the <xref:System.Globalization.CompareOptions> enumeration values <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> and <xref:System.Globalization.CompareOptions.IgnoreWidth>.</span></span> <span data-ttu-id="52bef-222">認識対象も新しい行と余分な空白を無視し、区切り記号をリテラルの入力として扱います。</span><span class="sxs-lookup"><span data-stu-id="52bef-222">The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="52bef-223">次の例は、音声認識文法を読み込みますを非同期のエミュレートされた入力、関連付けられている認識結果、および音声認識エンジンによって生成される、関連するイベントを示すコンソール アプリケーションの一部です。</span><span class="sxs-lookup"><span data-stu-id="52bef-223">The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</span></span> <span data-ttu-id="52bef-224">Windows 音声認識が実行されていない場合、このアプリケーションの開始と Windows 音声認識が開始もします。</span><span class="sxs-lookup"><span data-stu-id="52bef-224">If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</span></span> <span data-ttu-id="52bef-225">Windows 音声認識がある場合、**スリープ**し、状態<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>常に null を返します。</span><span class="sxs-lookup"><span data-stu-id="52bef-225">If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.</span></span>  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=  
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call does not match the grammar   
        // or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  
    // Handle the EmulateRecognizeCompleted event.   
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognizeAsync">
      <MemberSignature Language="C#" Value="public void EmulateRecognizeAsync (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EmulateRecognizeAsync(class System.Speech.Recognition.RecognizedWordUnit[] wordUnits, valuetype System.Globalization.CompareOptions compareOptions) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EmulateRecognizeAsync(cli::array &lt;System::Speech::Recognition::RecognizedWordUnit ^&gt; ^ wordUnits, System::Globalization::CompareOptions compareOptions);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognizeAsync : System.Speech.Recognition.RecognizedWordUnit[] * System.Globalization.CompareOptions -&gt; unit" Usage="speechRecognizer.EmulateRecognizeAsync (wordUnits, compareOptions)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="wordUnits" Type="System.Speech.Recognition.RecognizedWordUnit[]" />
        <Parameter Name="compareOptions" Type="System.Globalization.CompareOptions" />
      </Parameters>
      <Docs>
        <param name="wordUnits"><span data-ttu-id="52bef-226">認識操作のための必要を格納する単語単位の配列。</span><span class="sxs-lookup"><span data-stu-id="52bef-226">An array of word units that contains the input for the recognition operation.</span></span></param>
        <param name="compareOptions"><span data-ttu-id="52bef-227">エミュレートされた認識操作に使用する比較の種類を示す列挙値のビットごとの組み合わせ。</span><span class="sxs-lookup"><span data-stu-id="52bef-227">A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</span></span></param>
        <summary><span data-ttu-id="52bef-228">非同期音声認識にオーディオではなくテキストを使用して、共有された音声認識エンジンに対する特定の語の入力をエミュレートし、語と読み込まれている音声認識文法との間で認識エンジンが Unicode 比較をどのように行うかを指定します。</span><span class="sxs-lookup"><span data-stu-id="52bef-228">Emulates input of specific words to the shared speech recognizer, using text instead of audio for asynchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the words and the loaded speech recognition grammars.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-229">このメソッドを作成、<xref:System.Speech.Recognition.RecognitionResult>オブジェクトで提供される情報を使用して、`wordUnits`パラメーター。</span><span class="sxs-lookup"><span data-stu-id="52bef-229">This method creates a <xref:System.Speech.Recognition.RecognitionResult> object using the information provided in the `wordUnits` parameter.</span></span>  
  
 <span data-ttu-id="52bef-230">認識エンジンを使用して、`compareOptions`入力語句に文法規則が適用するときにします。</span><span class="sxs-lookup"><span data-stu-id="52bef-230">The recognizer uses the `compareOptions` when it applies grammar rules to the input phrase.</span></span> <span data-ttu-id="52bef-231">Vista および Windows 7 に付属しているレコグナイザー場合大文字小文字は無視、<xref:System.Globalization.CompareOptions.OrdinalIgnoreCase>または<xref:System.Globalization.CompareOptions.IgnoreCase>値が存在します。</span><span class="sxs-lookup"><span data-stu-id="52bef-231">The recognizers that ship with Vista and Windows 7 ignore case if the <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> or <xref:System.Globalization.CompareOptions.IgnoreCase> value is present.</span></span> <span data-ttu-id="52bef-232">認識対象は、文字幅を常に無視して、カナ型を無視することはありません。</span><span class="sxs-lookup"><span data-stu-id="52bef-232">The recognizers always ignore the character width and never ignore the Kana type.</span></span> <span data-ttu-id="52bef-233">認識は、新しい行と余分な空白を無視して、区切り記号をリテラルの入力として扱います。</span><span class="sxs-lookup"><span data-stu-id="52bef-233">The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</span></span> <span data-ttu-id="52bef-234">詳細については、文字幅、ひらがなとカタカナは、次を参照してください。、<xref:System.Globalization.CompareOptions>列挙体。</span><span class="sxs-lookup"><span data-stu-id="52bef-234">For more information about character width and Kana type, see the <xref:System.Globalization.CompareOptions> enumeration.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognizeAsync">
      <MemberSignature Language="C#" Value="public void EmulateRecognizeAsync (string inputText, System.Globalization.CompareOptions compareOptions);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EmulateRecognizeAsync(string inputText, valuetype System.Globalization.CompareOptions compareOptions) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EmulateRecognizeAsync(System::String ^ inputText, System::Globalization::CompareOptions compareOptions);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognizeAsync : string * System.Globalization.CompareOptions -&gt; unit" Usage="speechRecognizer.EmulateRecognizeAsync (inputText, compareOptions)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="inputText" Type="System.String" />
        <Parameter Name="compareOptions" Type="System.Globalization.CompareOptions" />
      </Parameters>
      <Docs>
        <param name="inputText"><span data-ttu-id="52bef-235">認識操作の入力語句。</span><span class="sxs-lookup"><span data-stu-id="52bef-235">The input phrase for the recognition operation.</span></span></param>
        <param name="compareOptions"><span data-ttu-id="52bef-236">エミュレートされた認識操作に使用する比較の種類を示す列挙値のビットごとの組み合わせ。</span><span class="sxs-lookup"><span data-stu-id="52bef-236">A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</span></span></param>
        <summary><span data-ttu-id="52bef-237">非同期音声認識にオーディオではなくテキストを使用して、共有された音声認識エンジンに対するフレーズの入力をエミュレートし、フレーズと読み込まれている音声認識文法との間で認識エンジンが Unicode 比較をどのように行うかを指定します。</span><span class="sxs-lookup"><span data-stu-id="52bef-237">Emulates input of a phrase to the shared speech recognizer, using text instead of audio for asynchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the phrase and the loaded speech recognition grammars.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-238">認識エンジンを使用して、`compareOptions`入力語句に文法規則が適用するときにします。</span><span class="sxs-lookup"><span data-stu-id="52bef-238">The recognizer uses the `compareOptions` when it applies grammar rules to the input phrase.</span></span> <span data-ttu-id="52bef-239">Vista および Windows 7 に付属しているレコグナイザー場合大文字小文字は無視、<xref:System.Globalization.CompareOptions.OrdinalIgnoreCase>または<xref:System.Globalization.CompareOptions.IgnoreCase>値が存在します。</span><span class="sxs-lookup"><span data-stu-id="52bef-239">The recognizers that ship with Vista and Windows 7 ignore case if the <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> or <xref:System.Globalization.CompareOptions.IgnoreCase> value is present.</span></span> <span data-ttu-id="52bef-240">認識対象は、文字幅を常に無視して、カナ型を無視することはありません。</span><span class="sxs-lookup"><span data-stu-id="52bef-240">The recognizers always ignore the character width and never ignore the Kana type.</span></span> <span data-ttu-id="52bef-241">認識は、新しい行と余分な空白を無視して、区切り記号をリテラルの入力として扱います。</span><span class="sxs-lookup"><span data-stu-id="52bef-241">The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</span></span> <span data-ttu-id="52bef-242">詳細については、文字幅、ひらがなとカタカナは、次を参照してください。、<xref:System.Globalization.CompareOptions>列挙体。</span><span class="sxs-lookup"><span data-stu-id="52bef-242">For more information about character width and Kana type, see the <xref:System.Globalization.CompareOptions> enumeration.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognizeCompleted">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; EmulateRecognizeCompleted;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; EmulateRecognizeCompleted" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted" />
      <MemberSignature Language="VB.NET" Value="Public Event EmulateRecognizeCompleted As EventHandler(Of EmulateRecognizeCompletedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::EmulateRecognizeCompletedEventArgs ^&gt; ^ EmulateRecognizeCompleted;" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognizeCompleted : EventHandler&lt;System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; " Usage="member this.EmulateRecognizeCompleted : System.EventHandler&lt;System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="52bef-243">共有認識機能がエミュレートされた入力の非同期認識操作を終了すると発生します。</span><span class="sxs-lookup"><span data-stu-id="52bef-243">Occurs when the shared recognizer finalizes an asynchronous recognition operation for emulated input.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-244">各<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>メソッドが非同期認識操作を開始します。</span><span class="sxs-lookup"><span data-stu-id="52bef-244">Each <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> method begins an asynchronous recognition operation.</span></span> <span data-ttu-id="52bef-245">認識エンジンが発生、`EmulateRecognizeCompleted`非同期操作を終了したときにイベント。</span><span class="sxs-lookup"><span data-stu-id="52bef-245">The recognizer raises the `EmulateRecognizeCompleted` event when it finalizes the asynchronous operation.</span></span>  
  
 <span data-ttu-id="52bef-246">非同期認識操作を発生させることができます、 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>、 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>、 <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>、および<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>イベント。</span><span class="sxs-lookup"><span data-stu-id="52bef-246">The asynchronous recognition operation can raise the <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>, and <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> events.</span></span> <span data-ttu-id="52bef-247"><xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted>イベントが最後にこのようなイベントを認識エンジンが、特定の操作を発生させます。</span><span class="sxs-lookup"><span data-stu-id="52bef-247">The <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted> event is the last such event that the recognizer raises for a given operation.</span></span>  
  
 <span data-ttu-id="52bef-248">デリゲートを作成するとき、`EmulateRecognizeCompleted`イベント、イベントを処理するメソッドを識別します。</span><span class="sxs-lookup"><span data-stu-id="52bef-248">When you create a delegate for an `EmulateRecognizeCompleted` event, you identify the method that will handle the event.</span></span> <span data-ttu-id="52bef-249">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</span><span class="sxs-lookup"><span data-stu-id="52bef-249">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="52bef-250">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</span><span class="sxs-lookup"><span data-stu-id="52bef-250">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="52bef-251">イベント ハンドラー デリゲートの詳細については、次を参照してください。[イベントとデリゲート](https://go.microsoft.com/fwlink/?LinkId=162418)します。</span><span class="sxs-lookup"><span data-stu-id="52bef-251">For more information about event-handler delegates, see [Events and Delegates](https://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="52bef-252">次の例は、音声認識文法を読み込みますを非同期のエミュレートされた入力、関連付けられている認識結果、および音声認識エンジンによって生成される、関連するイベントを示すコンソール アプリケーションの一部です。</span><span class="sxs-lookup"><span data-stu-id="52bef-252">The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</span></span> <span data-ttu-id="52bef-253">Windows 音声認識が実行されていない場合、このアプリケーションの開始と Windows 音声認識が開始もします。</span><span class="sxs-lookup"><span data-stu-id="52bef-253">If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</span></span> <span data-ttu-id="52bef-254">Windows 音声認識がある場合、**スリープ**モード、<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>常に null を返します。</span><span class="sxs-lookup"><span data-stu-id="52bef-254">If Windows Speech Recognition is in the **Sleeping** mode, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.</span></span>  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    // Indicate whether the asynchronous emulate recognition  
    // operation has completed.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=   
          new EventHandler<SpeechRecognizedEventArgs>(SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=   
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call does not match the grammar  
        // or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  
    // Handle the EmulateRecognizeCompleted event.  
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      // Indicate the asynchronous operation is complete.  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="Enabled">
      <MemberSignature Language="C#" Value="public bool Enabled { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance bool Enabled" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.Enabled" />
      <MemberSignature Language="VB.NET" Value="Public Property Enabled As Boolean" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property bool Enabled { bool get(); void set(bool value); };" />
      <MemberSignature Language="F#" Value="member this.Enabled : bool with get, set" Usage="System.Speech.Recognition.SpeechRecognizer.Enabled" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Boolean</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="52bef-255">この <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> オブジェクトが音声を処理する準備ができたかどうかを示す値を取得または設定します。</span><span class="sxs-lookup"><span data-stu-id="52bef-255">Gets or sets a value that indicates whether this <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> object is ready to process speech.</span></span></summary>
        <value><span data-ttu-id="52bef-256">この <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> オブジェクトが音声認識を行っている場合は <see langword="true" />。それ以外の場合は <see langword="false" />。</span><span class="sxs-lookup"><span data-stu-id="52bef-256"><see langword="true" /> if this <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> object is performing speech recognition; otherwise, <see langword="false" />.</span></span></value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-257">このプロパティに対する変更の他のインスタンスの影響を与えるありません、<xref:System.Speech.Recognition.SpeechRecognizer>クラス。</span><span class="sxs-lookup"><span data-stu-id="52bef-257">Changes to this property do not affect other instances of the <xref:System.Speech.Recognition.SpeechRecognizer> class.</span></span>  
  
 <span data-ttu-id="52bef-258">既定の値で、<xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>プロパティは`true`の新しくインスタンス化されたインスタンスの<xref:System.Speech.Recognition.SpeechRecognizer>します。</span><span class="sxs-lookup"><span data-stu-id="52bef-258">By default, the value of the <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> property is `true` for a newly instantiated instance of <xref:System.Speech.Recognition.SpeechRecognizer>.</span></span> <span data-ttu-id="52bef-259">認識エンジンが無効になっていると、認識エンジンの音声認識文法のいずれもが認識操作に使用できます。</span><span class="sxs-lookup"><span data-stu-id="52bef-259">While the recognizer is disabled, none of the recognizer's speech recognition grammars are available for recognition operations.</span></span> <span data-ttu-id="52bef-260">認識エンジンの設定<xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>プロパティは、認識エンジンに影響を与えません<xref:System.Speech.Recognition.SpeechRecognizer.State%2A>プロパティ。</span><span class="sxs-lookup"><span data-stu-id="52bef-260">Setting the recognizer's <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> property has no effect on the recognizer's <xref:System.Speech.Recognition.SpeechRecognizer.State%2A> property.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition" />
      </Docs>
    </Member>
    <Member MemberName="Grammars">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.Grammar&gt; Grammars { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.ObjectModel.ReadOnlyCollection`1&lt;class System.Speech.Recognition.Grammar&gt; Grammars" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.Grammars" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Grammars As ReadOnlyCollection(Of Grammar)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::Grammar ^&gt; ^ Grammars { System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::Grammar ^&gt; ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Grammars : System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.Grammar&gt;" Usage="System.Speech.Recognition.SpeechRecognizer.Grammars" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.Grammar&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="52bef-261">この <see cref="T:System.Speech.Recognition.Grammar" /> インスタンスに読み込まれる <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> オブジェクトのコレクションを取得します。</span><span class="sxs-lookup"><span data-stu-id="52bef-261">Gets a collection of the <see cref="T:System.Speech.Recognition.Grammar" /> objects that are loaded in this <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> instance.</span></span></summary>
        <value><span data-ttu-id="52bef-262">アプリケーションが共有認識エンジンの現在のインスタンスに読み込んだ <see cref="T:System.Speech.Recognition.Grammar" /> オブジェクトのコレクション。</span><span class="sxs-lookup"><span data-stu-id="52bef-262">A collection of the <see cref="T:System.Speech.Recognition.Grammar" /> objects that the application loaded into the current instance of the shared recognizer.</span></span></value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-263">このプロパティは返されません、音声認識文法が別のアプリケーションによって読み込まれます。</span><span class="sxs-lookup"><span data-stu-id="52bef-263">This property does not return any speech recognition grammars loaded by another application.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="52bef-264">次の例では、共有音声認識エンジンに読み込まれる各音声認識文法のコンソールに情報を出力します。</span><span class="sxs-lookup"><span data-stu-id="52bef-264">The following example outputs information to the console for each speech recognition grammar loaded into the shared speech recognizer.</span></span>  
  
```csharp  
  
using System;  
using System.Collections.Generic;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        Grammar sampleGrammar = new Grammar(new GrammarBuilder("sample phrase"));  
        sampleGrammar.Name = "Sample Grammar";  
        recognizer.LoadGrammar(sampleGrammar);  
  
        OutputGrammarList(recognizer);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    private static void OutputGrammarList(SpeechRecognizer recognizer)  
    {  
      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  
      if (grammars.Count > 0)  
      {  
        Console.WriteLine("Loaded grammars:");  
        foreach (Grammar g in grammars)  
        {  
          Console.WriteLine("  Grammar: {0}",  
            (g.Name != null) ? g.Name : "<no name>");  
        }  
      }  
      else  
      {  
        Console.WriteLine("No grammars loaded.");  
      }  
    }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
      </Docs>
    </Member>
    <Member MemberName="LoadGrammar">
      <MemberSignature Language="C#" Value="public void LoadGrammar (System.Speech.Recognition.Grammar grammar);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void LoadGrammar(class System.Speech.Recognition.Grammar grammar) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void LoadGrammar(System::Speech::Recognition::Grammar ^ grammar);" />
      <MemberSignature Language="F#" Value="member this.LoadGrammar : System.Speech.Recognition.Grammar -&gt; unit" Usage="speechRecognizer.LoadGrammar grammar" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="grammar" Type="System.Speech.Recognition.Grammar" />
      </Parameters>
      <Docs>
        <param name="grammar"><span data-ttu-id="52bef-265">読み込む音声認識文法。</span><span class="sxs-lookup"><span data-stu-id="52bef-265">The speech recognition grammar to load.</span></span></param>
        <summary><span data-ttu-id="52bef-266">音声認識文法を読み込みます。</span><span class="sxs-lookup"><span data-stu-id="52bef-266">Loads a speech recognition grammar.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-267">共有認識エンジンは、音声認識文法が既に読み込まれて、非同期的にロードされてまたは任意の認識エンジンに読み込みに失敗しましたが、例外をスローします。</span><span class="sxs-lookup"><span data-stu-id="52bef-267">The shared recognizer throws an exception if the speech recognition grammar is already loaded, is being asynchronously loaded, or has failed to load into any recognizer.</span></span> <span data-ttu-id="52bef-268">認識エンジンが実行されている場合、アプリケーションが使用する必要があります<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>を読み込み、アンロードが有効にすると、または文法を無効にする前に、音声認識エンジンを一時停止します。</span><span class="sxs-lookup"><span data-stu-id="52bef-268">If the recognizer is running, applications must use <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</span></span>  
  
 <span data-ttu-id="52bef-269">音声認識文法を非同期で読み込むには、使用、<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>メソッド。</span><span class="sxs-lookup"><span data-stu-id="52bef-269">To load a speech recognition grammar asynchronously, use the <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A> method.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="52bef-270">次の例は、音声認識文法を読み込みますを非同期のエミュレートされた入力、関連付けられている認識結果、および音声認識エンジンによって生成される、関連するイベントを示すコンソール アプリケーションの一部です。</span><span class="sxs-lookup"><span data-stu-id="52bef-270">The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.</span></span> <span data-ttu-id="52bef-271">Windows 音声認識が実行されていない場合、このアプリケーションの開始と Windows 音声認識が開始もします。</span><span class="sxs-lookup"><span data-stu-id="52bef-271">If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</span></span> <span data-ttu-id="52bef-272">Windows 音声認識がある場合、**スリープ**し、状態<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>常に null を返します。</span><span class="sxs-lookup"><span data-stu-id="52bef-272">If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.</span></span>  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    // Indicate whether the asynchronous emulate recognition  
    // operation has completed.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=  
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call does not match the grammar   
        // or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }   
  
    // Handle the EmulateRecognizeCompleted event.   
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
      </Docs>
    </Member>
    <Member MemberName="LoadGrammarAsync">
      <MemberSignature Language="C#" Value="public void LoadGrammarAsync (System.Speech.Recognition.Grammar grammar);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void LoadGrammarAsync(class System.Speech.Recognition.Grammar grammar) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void LoadGrammarAsync(System::Speech::Recognition::Grammar ^ grammar);" />
      <MemberSignature Language="F#" Value="member this.LoadGrammarAsync : System.Speech.Recognition.Grammar -&gt; unit" Usage="speechRecognizer.LoadGrammarAsync grammar" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="grammar" Type="System.Speech.Recognition.Grammar" />
      </Parameters>
      <Docs>
        <param name="grammar"><span data-ttu-id="52bef-273">読み込む音声認識文法。</span><span class="sxs-lookup"><span data-stu-id="52bef-273">The speech recognition grammar to load.</span></span></param>
        <summary><span data-ttu-id="52bef-274">非同期的に音声認識文法を読み込みます。</span><span class="sxs-lookup"><span data-stu-id="52bef-274">Asynchronously loads a speech recognition grammar.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-275">認識エンジンには、この非同期操作が完了すると、生成、<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted>イベント。</span><span class="sxs-lookup"><span data-stu-id="52bef-275">When the recognizer completes this asynchronous operation, it raises a <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted> event.</span></span> <span data-ttu-id="52bef-276">音声認識文法が既に読み込まれて、非同期的にロードされてまたは任意の認識エンジンに読み込みに失敗しましたが、認識エンジンは例外をスローします。</span><span class="sxs-lookup"><span data-stu-id="52bef-276">The recognizer throws an exception if the speech recognition grammar is already loaded, is being asynchronously loaded, or has failed to load into any recognizer.</span></span> <span data-ttu-id="52bef-277">認識エンジンが実行されている場合、アプリケーションが使用する必要があります<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>を読み込み、アンロードが有効にすると、または文法を無効にする前に、音声認識エンジンを一時停止します。</span><span class="sxs-lookup"><span data-stu-id="52bef-277">If the recognizer is running, applications must use <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</span></span>  
  
 <span data-ttu-id="52bef-278">音声認識文法を同期的に読み込むには使用、<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A>メソッド。</span><span class="sxs-lookup"><span data-stu-id="52bef-278">To load a speech recognition grammar synchronously, use the <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A> method.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted" />
      </Docs>
    </Member>
    <Member MemberName="LoadGrammarCompleted">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt; LoadGrammarCompleted;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt; LoadGrammarCompleted" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted" />
      <MemberSignature Language="VB.NET" Value="Public Event LoadGrammarCompleted As EventHandler(Of LoadGrammarCompletedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::LoadGrammarCompletedEventArgs ^&gt; ^ LoadGrammarCompleted;" />
      <MemberSignature Language="F#" Value="member this.LoadGrammarCompleted : EventHandler&lt;System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt; " Usage="member this.LoadGrammarCompleted : System.EventHandler&lt;System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="52bef-279">認識機能が音声認識文法の非同期読み込みを終了すると発生します。</span><span class="sxs-lookup"><span data-stu-id="52bef-279">Occurs when the recognizer finishes the asynchronous loading of a speech recognition grammar.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-280">認識エンジンの<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>メソッドが非同期操作を開始します。</span><span class="sxs-lookup"><span data-stu-id="52bef-280">The recognizer's <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A> method initiates an asynchronous operation.</span></span> <span data-ttu-id="52bef-281">認識エンジンが発生、`LoadGrammarCompleted`イベント、操作が完了するとします。</span><span class="sxs-lookup"><span data-stu-id="52bef-281">The recognizer raises the `LoadGrammarCompleted` event when it completes the operation.</span></span> <span data-ttu-id="52bef-282">取得する、<xref:System.Speech.Recognition.Grammar>認識エンジンが読み込まれているオブジェクト、 <xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A> 、関連付けられているプロパティ<xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs>します。</span><span class="sxs-lookup"><span data-stu-id="52bef-282">To get the <xref:System.Speech.Recognition.Grammar> object that the recognizer loaded, use the <xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A> property of the associated <xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs>.</span></span> <span data-ttu-id="52bef-283">現在の取得に<xref:System.Speech.Recognition.Grammar>認識エンジンが読み込まれて、オブジェクトを使用して、認識エンジンの<xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A>プロパティ。</span><span class="sxs-lookup"><span data-stu-id="52bef-283">To get the current <xref:System.Speech.Recognition.Grammar> objects the recognizer has loaded, use the recognizer's <xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A> property.</span></span>  
  
 <span data-ttu-id="52bef-284">デリゲートを作成するとき、`LoadGrammarCompleted`イベント、イベントを処理するメソッドを識別します。</span><span class="sxs-lookup"><span data-stu-id="52bef-284">When you create a delegate for a `LoadGrammarCompleted` event, you identify the method that will handle the event.</span></span> <span data-ttu-id="52bef-285">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</span><span class="sxs-lookup"><span data-stu-id="52bef-285">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="52bef-286">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</span><span class="sxs-lookup"><span data-stu-id="52bef-286">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="52bef-287">イベント ハンドラー デリゲートの詳細については、次を参照してください。[イベントとデリゲート](https://go.microsoft.com/fwlink/?LinkId=162418)します。</span><span class="sxs-lookup"><span data-stu-id="52bef-287">For more information about event-handler delegates, see [Events and Delegates](https://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="52bef-288">次の例では、共有音声認識エンジンを作成し、文法および自由発話のディクテーションを受け入れるための特定の単語を認識するための 2 種類が作成されます。</span><span class="sxs-lookup"><span data-stu-id="52bef-288">The following example creates a shared speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation.</span></span> <span data-ttu-id="52bef-289">例は、認識エンジンに作成されたすべての文法を非同期で読み込みます。</span><span class="sxs-lookup"><span data-stu-id="52bef-289">The example asynchronously loads all the created grammars to the recognizer.</span></span> <span data-ttu-id="52bef-290">ハンドラーを認識エンジンの<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted>と<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>イベントでは、認識および認識結果のテキストをそれぞれ実行に使用された文法の名前をコンソールに出力します。</span><span class="sxs-lookup"><span data-stu-id="52bef-290">Handlers for the recognizer's <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted> and <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> events write to the console the name of the grammar that was used to perform the recognition and the text of the recognition result, respectively.</span></span>  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
        // Add a handler for the LoadGrammarCompleted event.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
        // Add a handler for the SpeechRecognized event.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
        // Add a handler for the StateChanged event.  
        recognizer.StateChanged +=  
          new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
  
        // Create "yesno" grammar.  
        Choices yesChoices = new Choices(new string[] { "yes", "yup", "yeah}" });  
        SemanticResultValue yesValue =  
            new SemanticResultValue(yesChoices, (bool)true);  
        Choices noChoices = new Choices(new string[] { "no", "nope", "neah" });  
        SemanticResultValue noValue =  
            new SemanticResultValue(noChoices, (bool)false);  
        SemanticResultKey yesNoKey =  
            new SemanticResultKey("yesno", new Choices(new GrammarBuilder[] { yesValue, noValue }));  
        Grammar yesnoGrammar = new Grammar(yesNoKey);  
        yesnoGrammar.Name = "yesNo";  
  
        // Create "done" grammar.  
        Grammar doneGrammar =  
          new Grammar(new Choices(new string[] { "done", "exit", "quit", "stop" }));  
        doneGrammar.Name = "Done";  
  
        // Create dictation grammar.  
        Grammar dictation = new DictationGrammar();  
        dictation.Name = "Dictation";  
  
        // Load grammars to the recognizer.  
        recognizer.LoadGrammarAsync(yesnoGrammar);  
        recognizer.LoadGrammarAsync(doneGrammar);  
        recognizer.LoadGrammarAsync(dictation);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Grammar({0}): {1}", e.Result.Grammar.Name, e.Result.Text);  
  
      // Add event handler code here.  
    }  
  
    // Handle the LoadGrammarCompleted event.   
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      string grammarName = e.Grammar.Name;  
      bool grammarLoaded = e.Grammar.Loaded;  
  
      if (e.Error != null)  
      {  
        Console.WriteLine("LoadGrammar for {0} failed with a {1}.",  
        grammarName, e.Error.GetType().Name);  
  
        // Add exception handling code here.  
      }  
  
      Console.WriteLine("Grammar {0} {1} loaded.",  
      grammarName, (grammarLoaded) ? "is" : "is not");  
    }  
  
    // Put the shared speech recognizer into "listening" mode.   
    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
      if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
        <altmember cref="T:System.Speech.Recognition.LoadGrammarCompletedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Grammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
      </Docs>
    </Member>
    <Member MemberName="MaxAlternates">
      <MemberSignature Language="C#" Value="public int MaxAlternates { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance int32 MaxAlternates" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.MaxAlternates" />
      <MemberSignature Language="VB.NET" Value="Public Property MaxAlternates As Integer" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property int MaxAlternates { int get(); void set(int value); };" />
      <MemberSignature Language="F#" Value="member this.MaxAlternates : int with get, set" Usage="System.Speech.Recognition.SpeechRecognizer.MaxAlternates" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Int32</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="52bef-291">共有認識エンジンが各認識操作に対して返す代替認識結果の最大数を取得または設定します。</span><span class="sxs-lookup"><span data-stu-id="52bef-291">Gets or sets the maximum number of alternate recognition results that the shared recognizer returns for each recognition operation.</span></span></summary>
        <value><span data-ttu-id="52bef-292">各認識操作に対して音声認識エンジンが返す代替結果の最大数。</span><span class="sxs-lookup"><span data-stu-id="52bef-292">The maximum number of alternate results that the speech recognizer returns for each recognition operation.</span></span></value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-293"><xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>のプロパティ、<xref:System.Speech.Recognition.RecognitionResult>クラスのコレクションを格納する<xref:System.Speech.Recognition.RecognizedPhrase>入力の他の候補の解釈を表すオブジェクト。</span><span class="sxs-lookup"><span data-stu-id="52bef-293">The <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> property of the <xref:System.Speech.Recognition.RecognitionResult> class contains the collection of <xref:System.Speech.Recognition.RecognizedPhrase> objects that represent other candidate interpretations of the input.</span></span>  
  
 <span data-ttu-id="52bef-294">既定値<xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A>10。</span><span class="sxs-lookup"><span data-stu-id="52bef-294">The default value for <xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A> is 10.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.RecognitionResult.Alternates" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="PauseRecognizerOnRecognition">
      <MemberSignature Language="C#" Value="public bool PauseRecognizerOnRecognition { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance bool PauseRecognizerOnRecognition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition" />
      <MemberSignature Language="VB.NET" Value="Public Property PauseRecognizerOnRecognition As Boolean" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property bool PauseRecognizerOnRecognition { bool get(); void set(bool value); };" />
      <MemberSignature Language="F#" Value="member this.PauseRecognizerOnRecognition : bool with get, set" Usage="System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Boolean</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="52bef-295">アプリケーションが <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /> イベントを処理している間、共有認識エンジンが認識操作を一時停止するかどうかを示す値を取得または設定します。</span><span class="sxs-lookup"><span data-stu-id="52bef-295">Gets or sets a value that indicates whether the shared recognizer pauses recognition operations while an application is handling a <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /> event.</span></span></summary>
        <value><span data-ttu-id="52bef-296">いずれかのアプリケーションが <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /> イベントを処理している間、共有レコグナイザーが入力の処理を待機している場合は <see langword="true" />。それ以外の場合は <see langword="false" />。</span><span class="sxs-lookup"><span data-stu-id="52bef-296"><see langword="true" /> if the shared recognizer waits to process input while any application is handling the <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /> event; otherwise, <see langword="false" />.</span></span></value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-297">このプロパティを設定`true`場合は、内で、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>イベント ハンドラーが、アプリケーションは、音声認識サービスの状態を変更または音声認識サービスの前に読み込まれたまたは有効化の音声認識文法を変更する必要がありますプロセスの入力します。</span><span class="sxs-lookup"><span data-stu-id="52bef-297">Set this property to `true`, if within the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> event handler your application needs to change the state of the speech recognition service or change the loaded or enabled speech recognition grammars before the speech recognition service processes more input.</span></span>  
  
> [!NOTE]
>  <span data-ttu-id="52bef-298">設定、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>プロパティを`true`と、 <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> Windows 音声認識サービスをブロックするすべてのアプリケーション内のイベント ハンドラー。</span><span class="sxs-lookup"><span data-stu-id="52bef-298">Setting the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> property to `true` causes each <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> event handler in every application to block the Windows speech recognition service.</span></span>  
  
 <span data-ttu-id="52bef-299">アプリケーションの状態で、共有認識エンジンに対する変更を同期するを使用して、<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>メソッド。</span><span class="sxs-lookup"><span data-stu-id="52bef-299">To synchronize the changes to the shared recognizer with your application state, use the <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> method.</span></span>  
  
 <span data-ttu-id="52bef-300">ときに<xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A>は`true`の実行中に、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>ハンドラー、音声認識サービスが一時停止し、バッファーの新しいオーディオ入力が到着するとします。</span><span class="sxs-lookup"><span data-stu-id="52bef-300">When <xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A> is `true`, during the execution of the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> handler the speech recognition service pauses and buffers new audio input as it arrives.</span></span> <span data-ttu-id="52bef-301">1 回、<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>イベント ハンドラーの終了、音声認識サービス再開の認識と、入力バッファーからの情報の処理を開始します。</span><span class="sxs-lookup"><span data-stu-id="52bef-301">Once the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> event handler exits, the speech recognition service resumes recognition and starts processing information from its input buffer.</span></span>  
  
 <span data-ttu-id="52bef-302">有効または音声認識サービスを無効にする、使用、<xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>プロパティ。</span><span class="sxs-lookup"><span data-stu-id="52bef-302">To enable or disable the speech recognition service, use the <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> property.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Enabled" />
      </Docs>
    </Member>
    <Member MemberName="RecognizerAudioPosition">
      <MemberSignature Language="C#" Value="public TimeSpan RecognizerAudioPosition { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.TimeSpan RecognizerAudioPosition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property RecognizerAudioPosition As TimeSpan" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property TimeSpan RecognizerAudioPosition { TimeSpan get(); };" />
      <MemberSignature Language="F#" Value="member this.RecognizerAudioPosition : TimeSpan" Usage="System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.TimeSpan</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="52bef-303">処理中のオーディオ入力内の認識エンジンの現在の位置を取得します。</span><span class="sxs-lookup"><span data-stu-id="52bef-303">Gets the current location of the recognizer in the audio input that it is processing.</span></span></summary>
        <value><span data-ttu-id="52bef-304">処理中のオーディオ入力の認識エンジンの位置。</span><span class="sxs-lookup"><span data-stu-id="52bef-304">The position of the recognizer in the audio input that it is processing.</span></span></value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-305">`RecognizerAudioPosition`プロパティは、そのオーディオ入力の処理で認識エンジンの位置を参照します。</span><span class="sxs-lookup"><span data-stu-id="52bef-305">The `RecognizerAudioPosition` property references the recognizer's position in processing its audio input.</span></span> <span data-ttu-id="52bef-306">これに対し、<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>プロパティは、生成されたオーディオ ストリーム内の入力デバイスの位置を参照します。</span><span class="sxs-lookup"><span data-stu-id="52bef-306">By contrast, the <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> property references the input device's position in its generated audio stream.</span></span> <span data-ttu-id="52bef-307">これらの位置は、さまざまなであることができます。</span><span class="sxs-lookup"><span data-stu-id="52bef-307">These positions can be different.</span></span> <span data-ttu-id="52bef-308">たとえば、認識エンジンが受け取った場合どの it されていない入力が、認識結果が次の値を生成、<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>プロパティは、の値より小さい、<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>プロパティ。</span><span class="sxs-lookup"><span data-stu-id="52bef-308">For example, if the recognizer has received input for which it has not yet generated a recognition result then the value of the <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> property is less than the value of the <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> property.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="RecognizerInfo">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognizerInfo RecognizerInfo { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.Recognition.RecognizerInfo RecognizerInfo" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.RecognizerInfo" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property RecognizerInfo As RecognizerInfo" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::RecognizerInfo ^ RecognizerInfo { System::Speech::Recognition::RecognizerInfo ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.RecognizerInfo : System.Speech.Recognition.RecognizerInfo" Usage="System.Speech.Recognition.SpeechRecognizer.RecognizerInfo" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizerInfo</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="52bef-309">共有音声認識エンジンに関する情報を取得します。</span><span class="sxs-lookup"><span data-stu-id="52bef-309">Gets information about the shared speech recognizer.</span></span></summary>
        <value><span data-ttu-id="52bef-310">共有音声認識エンジンに関する情報です。</span><span class="sxs-lookup"><span data-stu-id="52bef-310">Information about the shared speech recognizer.</span></span></value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-311">このプロパティは、Windows 音声認識で使用中の音声認識エンジンに関する情報を返します。</span><span class="sxs-lookup"><span data-stu-id="52bef-311">This property returns information about the speech recognizer in use by Windows Speech Recognition.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="52bef-312">次の例では、コンソールに共有認識エンジンに関する情報を送信します。</span><span class="sxs-lookup"><span data-stu-id="52bef-312">The following example sends information about the shared recognizer to the console.</span></span>  
  
```csharp  
  
using System;  
using System.Speech.Recognition;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        Console.WriteLine("Recognizer information for the shared recognizer:");  
        Console.WriteLine("  Name: {0}", recognizer.RecognizerInfo.Name);  
        Console.WriteLine("  Culture: {0}", recognizer.RecognizerInfo.Culture.ToString());  
        Console.WriteLine("  Description: {0}", recognizer.RecognizerInfo.Description);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizerInfo" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.State" />
      </Docs>
    </Member>
    <Member MemberName="RecognizerUpdateReached">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; RecognizerUpdateReached;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; RecognizerUpdateReached" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
      <MemberSignature Language="VB.NET" Value="Public Event RecognizerUpdateReached As EventHandler(Of RecognizerUpdateReachedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::RecognizerUpdateReachedEventArgs ^&gt; ^ RecognizerUpdateReached;" />
      <MemberSignature Language="F#" Value="member this.RecognizerUpdateReached : EventHandler&lt;System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; " Usage="member this.RecognizerUpdateReached : System.EventHandler&lt;System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="52bef-313">認識機能が認識と他の操作を同期するために一時停止すると発生します。</span><span class="sxs-lookup"><span data-stu-id="52bef-313">Occurs when the recognizer pauses to synchronize recognition and other operations.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-314">アプリケーションを使用する必要があります<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>のインスタンスが実行を一時停止する<xref:System.Speech.Recognition.SpeechRecognizer>変更する前にその<xref:System.Speech.Recognition.Grammar>オブジェクト。</span><span class="sxs-lookup"><span data-stu-id="52bef-314">Applications must use <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> to pause a running instance of <xref:System.Speech.Recognition.SpeechRecognizer> before modifying its <xref:System.Speech.Recognition.Grammar> objects.</span></span> <span data-ttu-id="52bef-315">たとえば、while、<xref:System.Speech.Recognition.SpeechRecognizer>は、一時停止できます読み込み、アンロードを有効にして無効にした<xref:System.Speech.Recognition.Grammar>オブジェクト。</span><span class="sxs-lookup"><span data-stu-id="52bef-315">For example, while the <xref:System.Speech.Recognition.SpeechRecognizer> is paused, you can load, unload, enable, and disable <xref:System.Speech.Recognition.Grammar> objects.</span></span> <span data-ttu-id="52bef-316"><xref:System.Speech.Recognition.SpeechRecognizer>変更を受け入れる準備ができた場合は、このイベントを発生させます。</span><span class="sxs-lookup"><span data-stu-id="52bef-316">The <xref:System.Speech.Recognition.SpeechRecognizer> raises this event when it is ready to accept modifications.</span></span>  
  
 <span data-ttu-id="52bef-317">デリゲートを作成するとき、<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>イベント、イベントを処理するメソッドを識別します。</span><span class="sxs-lookup"><span data-stu-id="52bef-317">When you create a delegate for a <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> event, you identify the method that will handle the event.</span></span> <span data-ttu-id="52bef-318">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</span><span class="sxs-lookup"><span data-stu-id="52bef-318">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="52bef-319">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</span><span class="sxs-lookup"><span data-stu-id="52bef-319">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="52bef-320">イベント ハンドラー デリゲートの詳細については、次を参照してください。[イベントとデリゲート](https://go.microsoft.com/fwlink/?LinkId=162418)します。</span><span class="sxs-lookup"><span data-stu-id="52bef-320">For more information about event-handler delegates, see [Events and Delegates](https://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="52bef-321">次の例では、コンソール アプリケーションをロードおよびアンロード<xref:System.Speech.Recognition.Grammar>オブジェクト。</span><span class="sxs-lookup"><span data-stu-id="52bef-321">The following example shows a console application that loads and unloads <xref:System.Speech.Recognition.Grammar> objects.</span></span> <span data-ttu-id="52bef-322">アプリケーションを使用して、<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>音声認識エンジンの更新プログラムを受信できるようにを一時停止を要求するメソッド。</span><span class="sxs-lookup"><span data-stu-id="52bef-322">The application uses the <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> method to request the speech recognition engine to pause so it can receive an update.</span></span> <span data-ttu-id="52bef-323">アプリケーション、ロードまたはアンロード、<xref:System.Speech.Recognition.Grammar>オブジェクト。</span><span class="sxs-lookup"><span data-stu-id="52bef-323">The application then loads or unloads a <xref:System.Speech.Recognition.Grammar> object.</span></span>  
  
 <span data-ttu-id="52bef-324">各更新プログラムのハンドラーで<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>イベントの名前と読み込まれた現在の状態の書き込み<xref:System.Speech.Recognition.Grammar>コンソールへのオブジェクト。</span><span class="sxs-lookup"><span data-stu-id="52bef-324">At each update, a handler for <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> event writes the name and status of the currently loaded <xref:System.Speech.Recognition.Grammar> objects to the console.</span></span> <span data-ttu-id="52bef-325">文法が読み込まれ、アンロード、として、アプリケーションは、ファームの動物の名前、ファームの動物の名前と、果物の名前、果物の名前のみに最初に認識します。</span><span class="sxs-lookup"><span data-stu-id="52bef-325">As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.</span></span>  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Collections.Generic;  
using System.Threading;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
      // Create the first grammar - Farm.  
      Choices animals = new Choices(new string[] { "cow", "pig", "goat" });  
      GrammarBuilder farm = new GrammarBuilder(animals);  
      Grammar farmAnimals = new Grammar(farm);  
      farmAnimals.Name = "Farm";  
  
      // Create the second grammar - Fruit.  
      Choices fruit = new Choices(new string[] { "apples", "peaches", "oranges" });  
      GrammarBuilder favorite = new GrammarBuilder(fruit);  
      Grammar favoriteFruit = new Grammar(favorite);  
      favoriteFruit.Name = "Fruit";  
  
      // Attach event handlers.  
      recognizer.SpeechRecognized +=  
        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
      recognizer.RecognizerUpdateReached +=  
        new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  
      recognizer.StateChanged +=   
        new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
  
      // Load the Farm grammar.  
      recognizer.LoadGrammar(farmAnimals);  
      Console.WriteLine("Grammar Farm is loaded");  
  
      // Pause to recognize farm animals.  
      Thread.Sleep(7000);  
      Console.WriteLine();  
  
      // Request an update and load the Fruit grammar.  
      recognizer.RequestRecognizerUpdate();  
      recognizer.LoadGrammarAsync(favoriteFruit);  
      Thread.Sleep(5000);  
  
      // Request an update and unload the Farm grammar.  
      recognizer.RequestRecognizerUpdate();  
      recognizer.UnloadGrammar(farmAnimals);  
      Thread.Sleep(5000);  
  
      // Keep the console window open.  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Put the shared speech recognizer into "listening" mode.  
    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
      if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  
    // At the update, get the names and enabled status of the currently loaded grammars.  
    public static void recognizer_RecognizerUpdateReached(  
      object sender, RecognizerUpdateReachedEventArgs e)  
    {  
      Console.WriteLine();  
      Console.WriteLine("Update reached:");  
      Thread.Sleep(1000);  
  
      string qualifier;  
      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  
      foreach (Grammar g in grammars)  
      {  
        qualifier = (g.Enabled) ? "enabled" : "disabled";  
        Console.WriteLine("  Grammar {0} is loaded and is {1}.",  
        g.Name, qualifier);  
      }  
    }  
  
    // Write the text of the recognized phrase to the console.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("  Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
        <altmember cref="T:System.Speech.Recognition.RecognizerUpdateReachedEventArgs" />
      </Docs>
    </Member>
    <MemberGroup MemberName="RequestRecognizerUpdate">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary><span data-ttu-id="52bef-326">共有認識エンジンがその状態を更新および停止するように要求します。</span><span class="sxs-lookup"><span data-stu-id="52bef-326">Requests that the shared recognizer pause and update its state.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-327">共有認識エンジンに対する変更を同期するのにには、このメソッドを使用します。</span><span class="sxs-lookup"><span data-stu-id="52bef-327">Use this method to synchronize changes to the shared recognizer.</span></span> <span data-ttu-id="52bef-328">たとえば、読み込み、認識エンジンが入力を処理する際に、音声認識文法をアンロードするか、このメソッドを使用し、<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>認識エンジンの状態と、アプリケーションの動作を同期するイベントです。</span><span class="sxs-lookup"><span data-stu-id="52bef-328">For example, if you load or unload a speech recognition grammar while the recognizer is processing input, use this method and the <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> event to synchronize your application behavior with the state of the recognizer.</span></span>  
  
 <span data-ttu-id="52bef-329">認識エンジンについて、一時停止または非同期操作が完了するし、が生成されますでこのメソッドが呼び出されたときに、<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>イベント。</span><span class="sxs-lookup"><span data-stu-id="52bef-329">When this method is called, the recognizer pauses or completes asynchronous operations and generates a <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> event.</span></span> <span data-ttu-id="52bef-330">A<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>イベント ハンドラーは、認識エンジンに対する認識操作の間の状態を変更できます。</span><span class="sxs-lookup"><span data-stu-id="52bef-330">A <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> event handler can then modify the state of the recognizer in between recognition operations.</span></span>  
  
 <span data-ttu-id="52bef-331">このメソッドが呼び出されたとき。</span><span class="sxs-lookup"><span data-stu-id="52bef-331">When this method is called:</span></span>  
  
-   <span data-ttu-id="52bef-332">認識エンジンをすぐに生成、認識エンジンが入力を処理されていない場合、<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>イベント。</span><span class="sxs-lookup"><span data-stu-id="52bef-332">If the recognizer is not processing input, the recognizer immediately generates the <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> event.</span></span>  
  
-   <span data-ttu-id="52bef-333">認識エンジンが認識操作を一時停止し、生成、認識エンジンがサイレント状態のバック グラウンド ノイズで構成される入力を処理する場合、<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>イベント。</span><span class="sxs-lookup"><span data-stu-id="52bef-333">If the recognizer is processing input that consists of silence or background noise, the recognizer pauses the recognition operation and generates the <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> event.</span></span>  
  
-   <span data-ttu-id="52bef-334">認識エンジンが認識操作を完了し、生成、認識エンジンがサイレント状態またはバック グラウンド ノイズの構成がない入力を処理する場合、<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>イベント。</span><span class="sxs-lookup"><span data-stu-id="52bef-334">If the recognizer is processing input that does not consist of silence or background noise, the recognizer completes the recognition operation and then generates the <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> event.</span></span>  
  
 <span data-ttu-id="52bef-335">認識エンジンが処理している間、<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>イベント。</span><span class="sxs-lookup"><span data-stu-id="52bef-335">While the recognizer is handling the <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> event:</span></span>  
  
-   <span data-ttu-id="52bef-336">認識エンジンは、入力との値を処理しません、<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>プロパティは変わりません。</span><span class="sxs-lookup"><span data-stu-id="52bef-336">The recognizer does not process input, and the value of the <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> property remains the same.</span></span>  
  
-   <span data-ttu-id="52bef-337">認識エンジンの入力を収集しの値は引き続き、<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>プロパティを変更することができます。</span><span class="sxs-lookup"><span data-stu-id="52bef-337">The recognizer continues to collect input, and the value of the <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> property can change.</span></span>  
  
 <span data-ttu-id="52bef-338">アプリケーションが処理している間、共有認識エンジンが認識操作を一時停止かどうかを変更する、<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>イベントを使用して、<xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A>プロパティ。</span><span class="sxs-lookup"><span data-stu-id="52bef-338">To change whether the shared recognizer pauses recognition operations while an application is handling a <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> event, use the <xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A> property.</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="52bef-339">次の例では、コンソール アプリケーションをロードおよびアンロード<xref:System.Speech.Recognition.Grammar>オブジェクト。</span><span class="sxs-lookup"><span data-stu-id="52bef-339">The following example shows a console application that loads and unloads <xref:System.Speech.Recognition.Grammar> objects.</span></span> <span data-ttu-id="52bef-340">アプリケーションを使用して、<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>音声認識エンジンの更新プログラムを受信できるようにを一時停止を要求するメソッド。</span><span class="sxs-lookup"><span data-stu-id="52bef-340">The application uses the <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> method to request the speech recognition engine to pause so it can receive an update.</span></span> <span data-ttu-id="52bef-341">アプリケーション、ロードまたはアンロード、<xref:System.Speech.Recognition.Grammar>オブジェクト。</span><span class="sxs-lookup"><span data-stu-id="52bef-341">The application then loads or unloads a <xref:System.Speech.Recognition.Grammar> object.</span></span>  
  
 <span data-ttu-id="52bef-342">各更新プログラムのハンドラーで<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>イベントの名前と読み込まれた現在の状態の書き込み<xref:System.Speech.Recognition.Grammar>コンソールへのオブジェクト。</span><span class="sxs-lookup"><span data-stu-id="52bef-342">At each update, a handler for <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> event writes the name and status of the currently loaded <xref:System.Speech.Recognition.Grammar> objects to the console.</span></span> <span data-ttu-id="52bef-343">文法が読み込まれ、アンロード、として、アプリケーションは、ファームの動物の名前、ファームの動物の名前と、果物の名前、果物の名前のみに最初に認識します。</span><span class="sxs-lookup"><span data-stu-id="52bef-343">As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.</span></span>  
  
```csharp  
  
using System;  
using System.Speech.Recognition;  
using System.Collections.Generic;  
using System.Threading;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize an in-process speech recognition engine and configure its input.  
      recognizer = new SpeechRecognizer();  
  
      // Create the first grammar - Farm.  
      Choices animals = new Choices(new string[] { "cow", "pig", "goat" });  
      GrammarBuilder farm = new GrammarBuilder(animals);  
      Grammar farmAnimals = new Grammar(farm);  
      farmAnimals.Name = "Farm";  
  
      // Create the second grammar - Fruit.  
      Choices fruit = new Choices(new string[] { "apples", "peaches", "oranges" });  
      GrammarBuilder favorite = new GrammarBuilder(fruit);  
      Grammar favoriteFruit = new Grammar(favorite);  
      favoriteFruit.Name = "Fruit";  
  
      // Attach event handlers.  
      recognizer.SpeechRecognized +=  
        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
      recognizer.RecognizerUpdateReached +=  
        new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  
  
      // Check to see if recognizer is loaded, wait if it is not loaded.  
      if (recognizer.State != RecognizerState.Listening)  
      {  
        Thread.Sleep(5000);  
  
        // Put recognizer in listening state.  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
  
      // Load the Farm grammar.  
      recognizer.LoadGrammar(farmAnimals);  
      Console.WriteLine("Grammar Farm is loaded");  
  
      // Pause to recognize farm animals.  
      Thread.Sleep(7000);  
      Console.WriteLine();  
  
      // Request an update and load the Fruit grammar.  
      recognizer.RequestRecognizerUpdate();  
      recognizer.LoadGrammarAsync(favoriteFruit);  
      Thread.Sleep(5000);  
  
      // Request an update and unload the Farm grammar.  
      recognizer.RequestRecognizerUpdate();  
      recognizer.UnloadGrammar(farmAnimals);  
      Thread.Sleep(5000);  
  
      // Keep the console window open.  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    public static void recognizer_RecognizerUpdateReached(object sender, RecognizerUpdateReachedEventArgs e)  
    {  
      // At the update, get the names and enabled status of the currently loaded grammars.  
      Console.WriteLine();  
      Console.WriteLine("Update reached:");  
      Thread.Sleep(1000);  
      string qualifier;  
      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  
      foreach (Grammar g in grammars)  
      {  
        qualifier = (g.Enabled) ? "enabled" : "disabled";  
        Console.WriteLine("  Grammar {0} is loaded and is {1}.",  
        g.Name, qualifier);  
      }  
    }  
  
    // Write the text of the recognized phrase to the console.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("  Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
      </Docs>
    </MemberGroup>
    <Member MemberName="RequestRecognizerUpdate">
      <MemberSignature Language="C#" Value="public void RequestRecognizerUpdate ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void RequestRecognizerUpdate() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
      <MemberSignature Language="VB.NET" Value="Public Sub RequestRecognizerUpdate ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void RequestRecognizerUpdate();" />
      <MemberSignature Language="F#" Value="member this.RequestRecognizerUpdate : unit -&gt; unit" Usage="speechRecognizer.RequestRecognizerUpdate " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary><span data-ttu-id="52bef-344">共有認識エンジンがその状態を更新および停止するように要求します。</span><span class="sxs-lookup"><span data-stu-id="52bef-344">Requests that the shared recognizer pause and update its state.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-345">認識エンジンが生成するとき、<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>イベント、<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>のプロパティ、<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>は`null`します。</span><span class="sxs-lookup"><span data-stu-id="52bef-345">When the recognizer generates the <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> event, the <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> property of the <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> is `null`.</span></span>  
  
 <span data-ttu-id="52bef-346">ユーザー トークンを提供するには、使用、<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>または<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>メソッド。</span><span class="sxs-lookup"><span data-stu-id="52bef-346">To provide a user token, use the <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> or <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> method.</span></span> <span data-ttu-id="52bef-347">オーディオの位置のオフセットを指定するには、使用、<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>メソッド。</span><span class="sxs-lookup"><span data-stu-id="52bef-347">To specify an audio position offset, use the <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> method.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="RequestRecognizerUpdate">
      <MemberSignature Language="C#" Value="public void RequestRecognizerUpdate (object userToken);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void RequestRecognizerUpdate(object userToken) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)" />
      <MemberSignature Language="VB.NET" Value="Public Sub RequestRecognizerUpdate (userToken As Object)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void RequestRecognizerUpdate(System::Object ^ userToken);" />
      <MemberSignature Language="F#" Value="member this.RequestRecognizerUpdate : obj -&gt; unit" Usage="speechRecognizer.RequestRecognizerUpdate userToken" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="userToken" Type="System.Object" />
      </Parameters>
      <Docs>
        <param name="userToken"><span data-ttu-id="52bef-348">操作に関する情報を含むユーザー定義情報。</span><span class="sxs-lookup"><span data-stu-id="52bef-348">User-defined information that contains information for the operation.</span></span></param>
        <summary><span data-ttu-id="52bef-349">共有認識エンジンがその状態を停止および更新し、関連イベントのユーザー トークンを提供するように要求します。</span><span class="sxs-lookup"><span data-stu-id="52bef-349">Requests that the shared recognizer pause and update its state and provides a user token for the associated event.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-350">認識エンジンが生成するとき、 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> 、イベント、<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>のプロパティ、<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>の値を格納、`userToken`パラメーター。</span><span class="sxs-lookup"><span data-stu-id="52bef-350">When the recognizer generates the <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> event, the <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> property of the <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> contains the value of the `userToken` parameter.</span></span>  
  
 <span data-ttu-id="52bef-351">オーディオの位置のオフセットを指定するには、使用、<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>メソッド。</span><span class="sxs-lookup"><span data-stu-id="52bef-351">To specify an audio position offset, use the <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> method.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="RequestRecognizerUpdate">
      <MemberSignature Language="C#" Value="public void RequestRecognizerUpdate (object userToken, TimeSpan audioPositionAheadToRaiseUpdate);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void RequestRecognizerUpdate(object userToken, valuetype System.TimeSpan audioPositionAheadToRaiseUpdate) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)" />
      <MemberSignature Language="VB.NET" Value="Public Sub RequestRecognizerUpdate (userToken As Object, audioPositionAheadToRaiseUpdate As TimeSpan)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void RequestRecognizerUpdate(System::Object ^ userToken, TimeSpan audioPositionAheadToRaiseUpdate);" />
      <MemberSignature Language="F#" Value="member this.RequestRecognizerUpdate : obj * TimeSpan -&gt; unit" Usage="speechRecognizer.RequestRecognizerUpdate (userToken, audioPositionAheadToRaiseUpdate)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="userToken" Type="System.Object" />
        <Parameter Name="audioPositionAheadToRaiseUpdate" Type="System.TimeSpan" />
      </Parameters>
      <Docs>
        <param name="userToken"><span data-ttu-id="52bef-352">操作に関する情報を含むユーザー定義情報。</span><span class="sxs-lookup"><span data-stu-id="52bef-352">User-defined information that contains information for the operation.</span></span></param>
        <param name="audioPositionAheadToRaiseUpdate"><span data-ttu-id="52bef-353">要求を遅延するための、現在の <see cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" /> からのオフセット。</span><span class="sxs-lookup"><span data-stu-id="52bef-353">The offset from the current <see cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" /> to delay the request.</span></span></param>
        <summary><span data-ttu-id="52bef-354">共有認識エンジンがその状態を停止および更新し、関連イベントのオフセットとユーザー トークンを提供するように要求します。</span><span class="sxs-lookup"><span data-stu-id="52bef-354">Requests that the shared recognizer pause and update its state and provides an offset and a user token for the associated event.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-355">認識エンジンが認識エンジンのまで認識エンジンの更新要求を開始できません<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>現在に等しい<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>の値、`audioPositionAheadToRaiseUpdate`パラメーター。</span><span class="sxs-lookup"><span data-stu-id="52bef-355">The recognizer does not initiate the recognizer update request until the recognizer's <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> equals the current <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> plus the value of the `audioPositionAheadToRaiseUpdate` parameter.</span></span>  
  
 <span data-ttu-id="52bef-356">認識エンジンが生成するとき、 <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> 、イベント、<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>のプロパティ、<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>の値を格納、`userToken`パラメーター。</span><span class="sxs-lookup"><span data-stu-id="52bef-356">When the recognizer generates the <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> event, the <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> property of the <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> contains the value of the `userToken` parameter.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="SpeechDetected">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.SpeechDetectedEventArgs&gt; SpeechDetected;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.SpeechDetectedEventArgs&gt; SpeechDetected" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
      <MemberSignature Language="VB.NET" Value="Public Event SpeechDetected As EventHandler(Of SpeechDetectedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::SpeechDetectedEventArgs ^&gt; ^ SpeechDetected;" />
      <MemberSignature Language="F#" Value="member this.SpeechDetected : EventHandler&lt;System.Speech.Recognition.SpeechDetectedEventArgs&gt; " Usage="member this.SpeechDetected : System.EventHandler&lt;System.Speech.Recognition.SpeechDetectedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.SpeechDetectedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="52bef-357">認識機能が音声として識別できる入力を検出すると発生します。</span><span class="sxs-lookup"><span data-stu-id="52bef-357">Occurs when the recognizer detects input that it can identify as speech.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-358">共有認識エンジンには、入力への応答には、このイベントを生成できます。</span><span class="sxs-lookup"><span data-stu-id="52bef-358">The shared recognizer can raise this event in response to input.</span></span> <span data-ttu-id="52bef-359"><xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A>プロパティ、関連付けられている<xref:System.Speech.Recognition.SpeechDetectedEventArgs>オブジェクトが、認識エンジンが音声を認識する場合、入力ストリーム内の場所を示します。</span><span class="sxs-lookup"><span data-stu-id="52bef-359">The <xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A> property of the associated <xref:System.Speech.Recognition.SpeechDetectedEventArgs> object indicates location in the input stream where the recognizer detected speech.</span></span> <span data-ttu-id="52bef-360">詳細については、次を参照してください。、<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>と<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>プロパティおよび<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>と<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>メソッド。</span><span class="sxs-lookup"><span data-stu-id="52bef-360">For more information see the <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> and <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> properties and the <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> and <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> methods.</span></span>  
  
 <span data-ttu-id="52bef-361">デリゲートを作成するとき、<xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>イベント、イベントを処理するメソッドを識別します。</span><span class="sxs-lookup"><span data-stu-id="52bef-361">When you create a delegate for a <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected> event, you identify the method that will handle the event.</span></span> <span data-ttu-id="52bef-362">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</span><span class="sxs-lookup"><span data-stu-id="52bef-362">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="52bef-363">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</span><span class="sxs-lookup"><span data-stu-id="52bef-363">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="52bef-364">イベント ハンドラー デリゲートの詳細については、次を参照してください。[イベントとデリゲート](https://go.microsoft.com/fwlink/?LinkId=162418)します。</span><span class="sxs-lookup"><span data-stu-id="52bef-364">For more information about event-handler delegates, see [Events and Delegates](https://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="52bef-365">次の例は、送信元と送信先の都市でフライトを選択するためのコンソール アプリケーションの一部です。</span><span class="sxs-lookup"><span data-stu-id="52bef-365">The following example is part of a console application for choosing origin and destination cities for a flight.</span></span> <span data-ttu-id="52bef-366">アプリケーション「たいシカゴにマイアミから飛行」など、語句が認識します。</span><span class="sxs-lookup"><span data-stu-id="52bef-366">The application recognizes phrases such as "I want to fly from Miami to Chicago."</span></span>  <span data-ttu-id="52bef-367">この例では、<xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>イベント レポートを<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>各時間の音声が検出されました。</span><span class="sxs-lookup"><span data-stu-id="52bef-367">The example uses the <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected> event to report the <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> each time speech is detected.</span></span>  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize a shared speech recognition engine.  
    {  
      using (SpeechRecognizer recognizer =  
         new SpeechRecognizer())  
      {  
  
        // Create a grammar.  
        Choices cities = new Choices(new string[] {   
          "Los Angeles", "New York", "Chicago", "San Francisco", "Miami", "Dallas" });  
  
        GrammarBuilder gb = new GrammarBuilder();  
        gb.Append("I would like to fly from");  
        gb.Append(cities);  
        gb.Append("to");  
        gb.Append(cities);  
  
        // Create a Grammar object and load it to the recognizer.  
        Grammar g = new Grammar(gb);  
        g.Name = ("City Chooser");  
        recognizer.LoadGrammarAsync(g);  
  
        // Attach event handlers.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
        recognizer.SpeechDetected +=   
          new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the SpeechDetected event.  
    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  
    {  
      Console.WriteLine("Speech detected at AudioPosition = {0}", e.AudioPosition);  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechDetectedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="SpeechHypothesized">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; SpeechHypothesized;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; SpeechHypothesized" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event SpeechHypothesized As EventHandler(Of SpeechHypothesizedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::SpeechHypothesizedEventArgs ^&gt; ^ SpeechHypothesized;" />
      <MemberSignature Language="F#" Value="member this.SpeechHypothesized : EventHandler&lt;System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; " Usage="member this.SpeechHypothesized : System.EventHandler&lt;System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.SpeechHypothesizedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="52bef-368">認識機能が文法の複数の完全な語句のコンポーネントである可能性がある単語を認識した場合に発生します。</span><span class="sxs-lookup"><span data-stu-id="52bef-368">Occurs when the recognizer has recognized a word or words that may be a component of multiple complete phrases in a grammar.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-369">共有認識エンジンは、入力があいまいな場合、このイベントを発生させることができます。</span><span class="sxs-lookup"><span data-stu-id="52bef-369">The shared recognizer can raise this event when the input is ambiguous.</span></span> <span data-ttu-id="52bef-370">たとえば、いずれかの認識をサポートする音声認識文法を"新しいゲームをしてください"または「新しいゲーム」、"新しいゲームをしてください"、明確な入力は、「新しいゲーム」はあいまいな入力です。</span><span class="sxs-lookup"><span data-stu-id="52bef-370">For example, for a speech recognition grammar that supports recognition of either "new game please" or "new game", "new game please" is an unambiguous input, and "new game" is an ambiguous input.</span></span>  
  
 <span data-ttu-id="52bef-371">デリゲートを作成するとき、<xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>イベント、イベントを処理するメソッドを識別します。</span><span class="sxs-lookup"><span data-stu-id="52bef-371">When you create a delegate for a <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized> event, you identify the method that will handle the event.</span></span> <span data-ttu-id="52bef-372">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</span><span class="sxs-lookup"><span data-stu-id="52bef-372">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="52bef-373">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</span><span class="sxs-lookup"><span data-stu-id="52bef-373">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="52bef-374">イベント ハンドラー デリゲートの詳細については、次を参照してください。[イベントとデリゲート](https://go.microsoft.com/fwlink/?LinkId=162418)します。</span><span class="sxs-lookup"><span data-stu-id="52bef-374">For more information about event-handler delegates, see [Events and Delegates](https://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="52bef-375">次の例では、「アーティスト ジャズのカテゴリの一覧を表示する」などの語句を認識します。</span><span class="sxs-lookup"><span data-stu-id="52bef-375">The following example recognizes phrases such as "Display the list of artists in the jazz category".</span></span> <span data-ttu-id="52bef-376">この例では、<xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>コンソールで、認識が不完全な語句のフラグメントを表示するイベントです。</span><span class="sxs-lookup"><span data-stu-id="52bef-376">The example uses the <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized> event to display incomplete phrase fragments in the console as they are recognized.</span></span>  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize a shared speech recognition engine.  
    {  
      using (SpeechRecognizer recognizer =  
         new SpeechRecognizer())  
      {  
  
        // Create a grammar.  
        //  Create lists of alternative choices.  
        Choices listTypes = new Choices(new string[] { "albums", "artists" });  
        Choices genres = new Choices(new string[] {   
          "blues", "classical", "gospel", "jazz", "rock" });  
  
        //  Create a GrammarBuilder object and assemble the grammar components.  
        GrammarBuilder mediaMenu = new GrammarBuilder("Display the list of");  
        mediaMenu.Append(listTypes);  
        mediaMenu.Append("in the");  
        mediaMenu.Append(genres);  
        mediaMenu.Append("category.");  
  
        //  Build a Grammar object from the GrammarBuilder.  
        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  
        mediaMenuGrammar.Name = "Media Chooser";  
  
        // Attach event handlers.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.SpeechHypothesized +=   
          new EventHandler<SpeechHypothesizedEventArgs>(recognizer_SpeechHypothesized);  
  
        // Load the grammar object to the recognizer.  
        recognizer.LoadGrammarAsync(mediaMenuGrammar);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the SpeechHypothesized event.  
    static void recognizer_SpeechHypothesized(object sender, SpeechHypothesizedEventArgs e)  
    {  
      Console.WriteLine("Speech hypothesized: " + e.Result.Text);  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechHypothesizedEventArgs" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="SpeechRecognitionRejected">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; SpeechRecognitionRejected;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; SpeechRecognitionRejected" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
      <MemberSignature Language="VB.NET" Value="Public Event SpeechRecognitionRejected As EventHandler(Of SpeechRecognitionRejectedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::SpeechRecognitionRejectedEventArgs ^&gt; ^ SpeechRecognitionRejected;" />
      <MemberSignature Language="F#" Value="member this.SpeechRecognitionRejected : EventHandler&lt;System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; " Usage="member this.SpeechRecognitionRejected : System.EventHandler&lt;System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="52bef-377">認識機能が読み込んだ音声認識文法のいずれにも一致しない入力を受け取ると発生します。</span><span class="sxs-lookup"><span data-stu-id="52bef-377">Occurs when the recognizer receives input that does not match any of the speech recognition grammars it has loaded.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-378">共有認識エンジンは、入力が一致しないことに十分な確実性、読み込まれている音声認識文法のいずれかを判断した場合、このイベントを発生させます。</span><span class="sxs-lookup"><span data-stu-id="52bef-378">The shared recognizer raises this event if it determines that input does not match with sufficient confidence any of the loaded speech recognition grammars.</span></span> <span data-ttu-id="52bef-379"><xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>のプロパティ、 <xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> 、拒否されたを含む<xref:System.Speech.Recognition.RecognitionResult>オブジェクト。</span><span class="sxs-lookup"><span data-stu-id="52bef-379">The <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> property of the <xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> contains the rejected <xref:System.Speech.Recognition.RecognitionResult> object.</span></span>  
  
 <span data-ttu-id="52bef-380">信頼度のしきい値によって管理される共有認識エンジンを<xref:System.Speech.Recognition.SpeechRecognizer>がユーザー プロファイルと関連付けられ、Windows レジストリに格納されています。</span><span class="sxs-lookup"><span data-stu-id="52bef-380">Confidence thresholds for the shared recognizer, managed by <xref:System.Speech.Recognition.SpeechRecognizer>, are associated with a user profile and stored in the Windows registry.</span></span> <span data-ttu-id="52bef-381">アプリケーションでは、共有認識エンジンのプロパティのレジストリに変更を記述しないでください。</span><span class="sxs-lookup"><span data-stu-id="52bef-381">Applications should not write changes to the registry for the properties of the shared recognizer.</span></span>  
  
 <span data-ttu-id="52bef-382">デリゲートを作成するとき、<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>イベント、イベントを処理するメソッドを識別します。</span><span class="sxs-lookup"><span data-stu-id="52bef-382">When you create a delegate for a <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected> event, you identify the method that will handle the event.</span></span> <span data-ttu-id="52bef-383">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</span><span class="sxs-lookup"><span data-stu-id="52bef-383">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="52bef-384">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</span><span class="sxs-lookup"><span data-stu-id="52bef-384">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="52bef-385">イベント ハンドラー デリゲートの詳細については、次を参照してください。[イベントとデリゲート](https://go.microsoft.com/fwlink/?LinkId=162418)します。</span><span class="sxs-lookup"><span data-stu-id="52bef-385">For more information about event-handler delegates, see [Events and Delegates](https://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="52bef-386">次の例では、「ジャズ カテゴリ アーティストの一覧の表示」や「絶対的のアルバムを表示する」などの語句を認識します。</span><span class="sxs-lookup"><span data-stu-id="52bef-386">The following example recognizes phrases such as "Display the list of artists in the jazz category" or "Display albums gospel".</span></span> <span data-ttu-id="52bef-387">この例のハンドラーを使用して、<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>の音声入力の認識を生成するために十分な確実性と、文法の内容に一致することはできません、コンソールの通知を表示するイベントです。</span><span class="sxs-lookup"><span data-stu-id="52bef-387">The example uses a handler for the <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected> event to display a notification in the console when the speech input cannot be matched to the contents of the grammar with sufficient confidence to produce a successful recognition.</span></span>  
  
```csharp  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize a shared speech recognition engine.  
    {  
      using (SpeechRecognizer recognizer =  
         new SpeechRecognizer())  
      {  
  
        // Create a grammar.  
        //  Create lists of alternative choices.  
        Choices listTypes = new Choices(new string[] { "albums", "artists" });  
        Choices genres = new Choices(new string[] {   
          "blues", "classical", "gospel", "jazz", "rock" });  
  
        //  Create a GrammarBuilder object and assemble the grammar components.  
        GrammarBuilder mediaMenu = new GrammarBuilder("Display");  
        mediaMenu.Append("the list of", 0, 1);  
        mediaMenu.Append(listTypes);  
        mediaMenu.Append("in the", 0, 1);  
        mediaMenu.Append(genres);  
        mediaMenu.Append("category", 0, 1);  
  
        //  Build a Grammar object from the GrammarBuilder.  
        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  
        mediaMenuGrammar.Name = "Media Chooser";  
  
        // Attach event handlers.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.SpeechRecognitionRejected +=   
          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  
  
        // Load the grammar object to the recognizer.  
        recognizer.LoadGrammarAsync(mediaMenuGrammar);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the SpeechRecognitionRejected event.  
    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  
    {  
      Console.WriteLine("Speech input was rejected.");  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="SpeechRecognized">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.SpeechRecognizedEventArgs&gt; SpeechRecognized;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.SpeechRecognizedEventArgs&gt; SpeechRecognized" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      <MemberSignature Language="VB.NET" Value="Public Event SpeechRecognized As EventHandler(Of SpeechRecognizedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::SpeechRecognizedEventArgs ^&gt; ^ SpeechRecognized;" />
      <MemberSignature Language="F#" Value="member this.SpeechRecognized : EventHandler&lt;System.Speech.Recognition.SpeechRecognizedEventArgs&gt; " Usage="member this.SpeechRecognized : System.EventHandler&lt;System.Speech.Recognition.SpeechRecognizedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.SpeechRecognizedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="52bef-388">認識機能が読み込んだ音声認識文法のいずれかに一致する入力を受け取ると発生します。</span><span class="sxs-lookup"><span data-stu-id="52bef-388">Occurs when the recognizer receives input that matches one of its speech recognition grammars.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-389">認識エンジンが発生、`SpeechRecognized`イベントの入力が読み込まれ、有効になっている音声認識文法のいずれかに一致するための十分な自信と判断した場合。</span><span class="sxs-lookup"><span data-stu-id="52bef-389">The recognizer raises the `SpeechRecognized` event if it determines with sufficient confidence that input matches one of the loaded and enabled speech recognition grammars.</span></span> <span data-ttu-id="52bef-390"><xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>のプロパティ、<xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>承諾を含む<xref:System.Speech.Recognition.RecognitionResult>オブジェクト。</span><span class="sxs-lookup"><span data-stu-id="52bef-390">The <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> property of the <xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> contains the accepted <xref:System.Speech.Recognition.RecognitionResult> object.</span></span>  
  
 <span data-ttu-id="52bef-391">信頼度のしきい値によって管理される共有認識エンジンを<xref:System.Speech.Recognition.SpeechRecognizer>がユーザー プロファイルと関連付けられ、Windows レジストリに格納されています。</span><span class="sxs-lookup"><span data-stu-id="52bef-391">Confidence thresholds for the shared recognizer, managed by <xref:System.Speech.Recognition.SpeechRecognizer>, are associated with a user profile and stored in the Windows registry.</span></span> <span data-ttu-id="52bef-392">アプリケーションでは、共有認識エンジンのプロパティのレジストリに変更を記述しないでください。</span><span class="sxs-lookup"><span data-stu-id="52bef-392">Applications should not write changes to the registry for the properties of the shared recognizer.</span></span>  
  
 <span data-ttu-id="52bef-393">認識エンジンは、文法に一致する入力を受け取るときに、<xref:System.Speech.Recognition.Grammar>オブジェクトを発生させることができます、<xref:System.Speech.Recognition.Grammar.SpeechRecognized>イベント。</span><span class="sxs-lookup"><span data-stu-id="52bef-393">When the recognizer receives input that matches a grammar, the <xref:System.Speech.Recognition.Grammar> object can raise the <xref:System.Speech.Recognition.Grammar.SpeechRecognized> event.</span></span> <span data-ttu-id="52bef-394"><xref:System.Speech.Recognition.Grammar>オブジェクトの<xref:System.Speech.Recognition.Grammar.SpeechRecognized>音声認識エンジンの前にイベントが発生した<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>イベント。</span><span class="sxs-lookup"><span data-stu-id="52bef-394">The <xref:System.Speech.Recognition.Grammar> object's <xref:System.Speech.Recognition.Grammar.SpeechRecognized> event is raised prior to the speech recognizer's <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> event.</span></span>  
  
 <span data-ttu-id="52bef-395">デリゲートを作成するとき、<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>イベント、イベントを処理するメソッドを識別します。</span><span class="sxs-lookup"><span data-stu-id="52bef-395">When you create a delegate for a <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> event, you identify the method that will handle the event.</span></span> <span data-ttu-id="52bef-396">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</span><span class="sxs-lookup"><span data-stu-id="52bef-396">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="52bef-397">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</span><span class="sxs-lookup"><span data-stu-id="52bef-397">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="52bef-398">イベント ハンドラー デリゲートの詳細については、次を参照してください。[イベントとデリゲート](https://go.microsoft.com/fwlink/?LinkId=162418)します。</span><span class="sxs-lookup"><span data-stu-id="52bef-398">For more information about event-handler delegates, see [Events and Delegates](https://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="52bef-399">次の例は、音声認識文法を読み込みますを音声入力が共有認識エンジン、関連付けられている認識結果、および音声認識エンジンによって生成される、関連するイベントを示すコンソール アプリケーションの一部です。</span><span class="sxs-lookup"><span data-stu-id="52bef-399">The following example is part of a console application that loads a speech recognition grammar and demonstrates speech input to the shared recognizer, the associated recognition results, and the associated events raised by the speech recognizer.</span></span> <span data-ttu-id="52bef-400">Windows 音声認識が実行されていない場合、このアプリケーションの開始と Windows 音声認識が開始もします。</span><span class="sxs-lookup"><span data-stu-id="52bef-400">If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.</span></span>  
  
 <span data-ttu-id="52bef-401">トリガーは「miami シカゴから飛行する」などの入力を読み上げ、<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>イベント。</span><span class="sxs-lookup"><span data-stu-id="52bef-401">Spoken input such as "I want to fly from Chicago to Miami" will trigger a <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> event.</span></span> <span data-ttu-id="52bef-402">"飛行 me ヒューストンからシカゴに"というフレーズを話すはトリガーされません、<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>イベント。</span><span class="sxs-lookup"><span data-stu-id="52bef-402">Speaking the phrase "Fly me from Houston to Chicago " will not trigger a <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> event.</span></span>  
  
 <span data-ttu-id="52bef-403">例では、ハンドラーを使用して、<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>正常に表示するイベントが語句と、コンソールが含まれているセマンティクスを認識します。</span><span class="sxs-lookup"><span data-stu-id="52bef-403">The example uses a handler for the <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> event to display successfully recognized phrases and the semantics they contain in the console.</span></span>  
  
```csharp  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize a shared speech recognition engine.  
    {  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
  
        // Create SemanticResultValue objects that contain cities and airport codes.  
        SemanticResultValue chicago = new SemanticResultValue("Chicago", "ORD");  
        SemanticResultValue boston = new SemanticResultValue("Boston", "BOS");  
        SemanticResultValue miami = new SemanticResultValue("Miami", "MIA");  
        SemanticResultValue dallas = new SemanticResultValue("Dallas", "DFW");  
  
        // Create a Choices object and add the SemanticResultValue objects, using  
        // implicit conversion from SemanticResultValue to GrammarBuilder  
        Choices cities = new Choices();  
        cities.Add(new Choices(new GrammarBuilder[] { chicago, boston, miami, dallas }));  
  
        // Build the phrase and add SemanticResultKeys.  
        GrammarBuilder chooseCities = new GrammarBuilder();  
        chooseCities.Append("I want to fly from");  
        chooseCities.Append(new SemanticResultKey("origin", cities));  
        chooseCities.Append("to");  
        chooseCities.Append(new SemanticResultKey("destination", cities));  
  
        // Build a Grammar object from the GrammarBuilder.  
        Grammar bookFlight = new Grammar(chooseCities);  
        bookFlight.Name = "Book Flight";  
  
        // Add a handler for the LoadGrammarCompleted event.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
        // Add a handler for the SpeechRecognized event.  
        recognizer.SpeechRecognized +=   
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
        // Load the grammar object to the recognizer.  
        recognizer.LoadGrammarAsync(bookFlight);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
      Console.WriteLine();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized:  " + e.Result.Text);  
      Console.WriteLine();  
      Console.WriteLine("Semantic results:");  
      Console.WriteLine("  The flight origin is " + e.Result.Semantics["origin"].Value);  
      Console.WriteLine("  The flight destination is " + e.Result.Semantics["destination"].Value);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="T:System.Speech.Recognition.SpeechRecognizedEventArgs" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
      </Docs>
    </Member>
    <Member MemberName="State">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognizerState State { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.Speech.Recognition.RecognizerState State" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.State" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property State As RecognizerState" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::RecognizerState State { System::Speech::Recognition::RecognizerState get(); };" />
      <MemberSignature Language="F#" Value="member this.State : System.Speech.Recognition.RecognizerState" Usage="System.Speech.Recognition.SpeechRecognizer.State" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizerState</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="52bef-404"><see cref="T:System.Speech.Recognition.SpeechRecognizer" /> オブジェクトの状態を取得します。</span><span class="sxs-lookup"><span data-stu-id="52bef-404">Gets the state of a <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> object.</span></span></summary>
        <value><span data-ttu-id="52bef-405"><see langword="SpeechRecognizer" /> オブジェクトの状態。</span><span class="sxs-lookup"><span data-stu-id="52bef-405">The state of the <see langword="SpeechRecognizer" /> object.</span></span></value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-406">この読み取り専用プロパティでは、Windows に常駐している共有認識エンジンがかどうかを示す、`Stopped`または`Listening`状態。</span><span class="sxs-lookup"><span data-stu-id="52bef-406">This read-only property indicates whether the shared recognizer resident in Windows is in the `Stopped` or the `Listening` state.</span></span> <span data-ttu-id="52bef-407">詳細については、<xref:System.Speech.Recognition.RecognizerState> 列挙型のページをご覧ください。</span><span class="sxs-lookup"><span data-stu-id="52bef-407">For more information, see the <xref:System.Speech.Recognition.RecognizerState> enumeration.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizerState" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.StateChanged" />
      </Docs>
    </Member>
    <Member MemberName="StateChanged">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.StateChangedEventArgs&gt; StateChanged;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.StateChangedEventArgs&gt; StateChanged" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.StateChanged" />
      <MemberSignature Language="VB.NET" Value="Public Event StateChanged As EventHandler(Of StateChangedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::StateChangedEventArgs ^&gt; ^ StateChanged;" />
      <MemberSignature Language="F#" Value="member this.StateChanged : EventHandler&lt;System.Speech.Recognition.StateChangedEventArgs&gt; " Usage="member this.StateChanged : System.EventHandler&lt;System.Speech.Recognition.StateChangedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.StateChangedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary><span data-ttu-id="52bef-408">Windows Desktop Speech テクノロジ音声認識エンジンの実行状態が変更されると発生します。</span><span class="sxs-lookup"><span data-stu-id="52bef-408">Occurs when the running state of the Windows Desktop Speech Technology recognition engine changes.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-409">共有認識エンジンに Windows 音声認識の状態が変更されたときに、このイベントを発生させる、<xref:System.Speech.Recognition.RecognizerState.Listening>または<xref:System.Speech.Recognition.RecognizerState.Stopped>状態。</span><span class="sxs-lookup"><span data-stu-id="52bef-409">The shared recognizer raises this event when the state of Windows Speech Recognition changes to the <xref:System.Speech.Recognition.RecognizerState.Listening> or <xref:System.Speech.Recognition.RecognizerState.Stopped> state.</span></span>  
  
 <span data-ttu-id="52bef-410">イベントの時点で、共有認識エンジンの状態を取得する、<xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A>プロパティ、関連付けられている<xref:System.Speech.Recognition.StateChangedEventArgs>します。</span><span class="sxs-lookup"><span data-stu-id="52bef-410">To get the state of the shared recognizer at the time of the event, use the <xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A> property of the associated <xref:System.Speech.Recognition.StateChangedEventArgs>.</span></span> <span data-ttu-id="52bef-411">共有認識エンジンの現在の状態を取得するには、使用、認識エンジンの<xref:System.Speech.Recognition.SpeechRecognizer.State%2A>プロパティ。</span><span class="sxs-lookup"><span data-stu-id="52bef-411">To get the current state of the shared recognizer, use the recognizer's <xref:System.Speech.Recognition.SpeechRecognizer.State%2A> property.</span></span>  
  
 <span data-ttu-id="52bef-412">デリゲートを作成するとき、<xref:System.Speech.Recognition.SpeechRecognizer.StateChanged>イベント、イベントを処理するメソッドを識別します。</span><span class="sxs-lookup"><span data-stu-id="52bef-412">When you create a delegate for a <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> event, you identify the method that will handle the event.</span></span> <span data-ttu-id="52bef-413">イベントをイベント ハンドラーに関連付けるには、デリゲートのインスタンスをイベントに追加します。</span><span class="sxs-lookup"><span data-stu-id="52bef-413">To associate the event with your event handler, add an instance of the delegate to the event.</span></span> <span data-ttu-id="52bef-414">デリゲートを削除しない限り、そのイベントが発生すると常にイベント ハンドラーが呼び出されます。</span><span class="sxs-lookup"><span data-stu-id="52bef-414">The event handler is called whenever the event occurs, unless you remove the delegate.</span></span> <span data-ttu-id="52bef-415">イベント ハンドラー デリゲートの詳細については、次を参照してください。[イベントとデリゲート](https://go.microsoft.com/fwlink/?LinkId=162418)します。</span><span class="sxs-lookup"><span data-stu-id="52bef-415">For more information about event-handler delegates, see [Events and Delegates](https://go.microsoft.com/fwlink/?LinkId=162418).</span></span>  
  
   
  
## Examples  
 <span data-ttu-id="52bef-416">次の例では、共有音声認識エンジンを作成し、文法および自由発話のディクテーションを受け入れるための特定の単語を認識するための 2 種類が作成されます。</span><span class="sxs-lookup"><span data-stu-id="52bef-416">The following example creates a shared speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation.</span></span> <span data-ttu-id="52bef-417">例は、認識エンジンに作成されたすべての文法を非同期で読み込みます。</span><span class="sxs-lookup"><span data-stu-id="52bef-417">The example asynchronously loads all the created grammars to the recognizer.</span></span>  <span data-ttu-id="52bef-418">ハンドラーを<xref:System.Speech.Recognition.SpeechRecognizer.StateChanged>イベントを使用して、 <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> 「リッスン」モードで Windows の認識を配置するメソッド。</span><span class="sxs-lookup"><span data-stu-id="52bef-418">A handler for the <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> event uses the <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> method to put Windows Recognition in "listening" mode.</span></span>  
  
```csharp  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
      // Add a handler for the LoadGrammarCompleted event.  
      recognizer.LoadGrammarCompleted += new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
      // Add a handler for the SpeechRecognized event.  
      recognizer.SpeechRecognized += new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
      // Add a handler for the StateChanged event.  
      recognizer.StateChanged += new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
  
      // Create "yesno" grammar.  
      Choices yesChoices = new Choices(new string[] { "yes", "yup", "yah}" });  
      SemanticResultValue yesValue =  
          new SemanticResultValue(yesChoices, (bool)true);  
      Choices noChoices = new Choices(new string[] { "no", "nope", "nah" });  
      SemanticResultValue noValue = new SemanticResultValue(noChoices, (bool)false);  
      SemanticResultKey yesNoKey =  
          new SemanticResultKey("yesno", new Choices(new GrammarBuilder[] { yesValue, noValue }));  
      Grammar yesnoGrammar = new Grammar(yesNoKey);  
      yesnoGrammar.Name = "yesNo";  
  
      // Create "done" grammar.  
      Grammar doneGrammar =  
        new Grammar(new Choices(new string[] { "done", "exit", "quit", "stop" }));  
      doneGrammar.Name = "Done";  
  
      // Create dictation grammar.  
      Grammar dictation = new DictationGrammar();  
      dictation.Name = "Dictation";  
  
      // Load grammars to the recognizer.  
      recognizer.LoadGrammarAsync(yesnoGrammar);  
      recognizer.LoadGrammarAsync(doneGrammar);  
      recognizer.LoadGrammarAsync(dictation);  
  
      // Keep the console window open.  
      Console.ReadLine();  
    }  
  
    // Put the shared speech recognizer into "listening" mode.  
    static void  recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
     if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  
    // Write the text of the recognized phrase to the console.  
    static void  recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
     Console.WriteLine("Grammar({0}): {1}", e.Result.Grammar.Name, e.Result.Text);  
  
      // Add event handler code here.  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void  recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
     string grammarName = e.Grammar.Name;  
      bool grammarLoaded = e.Grammar.Loaded;  
      if (e.Error != null)  
      {  
        Console.WriteLine("LoadGrammar for {0} failed with a {1}.",  
        grammarName, e.Error.GetType().Name);  
      }  
  
      // Add exception handling code here.  
      Console.WriteLine("Grammar {0} {1} loaded.",  
      grammarName, (grammarLoaded) ? "is" : "is not");  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizerState" />
        <altmember cref="T:System.Speech.Recognition.StateChangedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.State" />
      </Docs>
    </Member>
    <Member MemberName="UnloadAllGrammars">
      <MemberSignature Language="C#" Value="public void UnloadAllGrammars ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void UnloadAllGrammars() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
      <MemberSignature Language="VB.NET" Value="Public Sub UnloadAllGrammars ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void UnloadAllGrammars();" />
      <MemberSignature Language="F#" Value="member this.UnloadAllGrammars : unit -&gt; unit" Usage="speechRecognizer.UnloadAllGrammars " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary><span data-ttu-id="52bef-419">共有認識エンジンから、すべての音声認識文法をアンロードします。</span><span class="sxs-lookup"><span data-stu-id="52bef-419">Unloads all speech recognition grammars from the shared recognizer.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-420">認識エンジンが現在読み込んでいる文法を非同期的に場合、このメソッドは、すべての認識エンジンの文法をアンロードする前に、文法が読み込まれるまでを待ちます。</span><span class="sxs-lookup"><span data-stu-id="52bef-420">If the recognizer is currently loading a grammar asynchronously, this method waits until the grammar is loaded, before it unloads all of the recognizer's grammars.</span></span>  
  
 <span data-ttu-id="52bef-421">特定の文法をアンロードするを使用して、<xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A>メソッド。</span><span class="sxs-lookup"><span data-stu-id="52bef-421">To unload a specific grammar, use the <xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A> method.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Grammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
      </Docs>
    </Member>
    <Member MemberName="UnloadGrammar">
      <MemberSignature Language="C#" Value="public void UnloadGrammar (System.Speech.Recognition.Grammar grammar);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void UnloadGrammar(class System.Speech.Recognition.Grammar grammar) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void UnloadGrammar(System::Speech::Recognition::Grammar ^ grammar);" />
      <MemberSignature Language="F#" Value="member this.UnloadGrammar : System.Speech.Recognition.Grammar -&gt; unit" Usage="speechRecognizer.UnloadGrammar grammar" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="grammar" Type="System.Speech.Recognition.Grammar" />
      </Parameters>
      <Docs>
        <param name="grammar"><span data-ttu-id="52bef-422">アンロードする文法。</span><span class="sxs-lookup"><span data-stu-id="52bef-422">The grammar to unload.</span></span></param>
        <summary><span data-ttu-id="52bef-423">共有認識エンジンから、指定された音声認識文法をアンロードします。</span><span class="sxs-lookup"><span data-stu-id="52bef-423">Unloads a specified speech recognition grammar from the shared recognizer.</span></span></summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <span data-ttu-id="52bef-424">認識エンジンが実行されている場合、アプリケーションが使用する必要があります<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>を読み込み、アンロードが有効にすると、または文法を無効にする前に、音声認識エンジンを一時停止します。</span><span class="sxs-lookup"><span data-stu-id="52bef-424">If the recognizer is running, applications must use <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</span></span> <span data-ttu-id="52bef-425">すべての文法をアンロードするを使用して、<xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A>メソッド。</span><span class="sxs-lookup"><span data-stu-id="52bef-425">To unload all grammars, use the <xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A> method.</span></span>  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Grammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
      </Docs>
    </Member>
  </Members>
</Type>