<Type Name="AudioSignalProblemOccurredEventArgs" FullName="System.Speech.Recognition.AudioSignalProblemOccurredEventArgs">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="bf162867ab9802912cb6c331ec0bafcc415c45a0" />
    <Meta Name="ms.sourcegitcommit" Value="5a49536d99d2d0b54e4cb7280870903e043272df" />
    <Meta Name="ms.translationtype" Value="HT" />
    <Meta Name="ms.contentlocale" Value="ja-JP" />
    <Meta Name="ms.lasthandoff" Value="07/03/2018" />
    <Meta Name="ms.locfileid" Value="37755942" />
  </Metadata>
  <TypeSignature Language="C#" Value="public class AudioSignalProblemOccurredEventArgs : EventArgs" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit AudioSignalProblemOccurredEventArgs extends System.EventArgs" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs" />
  <TypeSignature Language="VB.NET" Value="Public Class AudioSignalProblemOccurredEventArgs&#xA;Inherits EventArgs" />
  <TypeSignature Language="C++ CLI" Value="public ref class AudioSignalProblemOccurredEventArgs : EventArgs" />
  <TypeSignature Language="F#" Value="type AudioSignalProblemOccurredEventArgs = class&#xA;    inherit EventArgs" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.EventArgs</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary>
      <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> または <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> の <c>AudioSignalProblemOccurred</c> イベントのデータを提供します。</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 インスタンス<xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>場合は、作成、<xref:System.Speech.Recognition.SpeechRecognitionEngine>または<xref:System.Speech.Recognition.SpeechRecognizer>オブジェクト、`AudioSignalProblemOccurred`イベント。 関連する情報を取得する、`AudioSignalProblemOccurred`イベント、イベントのハンドラーで、次のプロパティにアクセスします。  
  
-   <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioLevel%2A>  
  
-   <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioPosition%2A>  
  
-   <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A>  
  
-   <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.RecognizerAudioPosition%2A>  
  
 <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioPosition%2A>プロパティは、生成されたオーディオ ストリーム内の入力デバイスの位置を参照します。 これに対し、<xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.RecognizerAudioPosition%2A>プロパティ参照がオーディオ入力内の認識エンジンの位置。 これらの位置は、さまざまなであることができます。 詳細については、次を参照してください。[音声認識イベントを使用した](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482)します。  
  
 <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A>プロパティは、どのような問題が発生したことを示します。  
  
 <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs> は、<xref:System.EventArgs> から派生します。  
  
   
  
## Examples  
 次の例は、に関する情報を収集するイベント ハンドラーを定義、<xref:System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred>イベント。  
  
```csharp  
  
private SpeechRecognitionEngine sre;  
  
// Initialize the speech recognition engine.  
private void Initialize()  
{  
  sre = new SpeechRecognitionEngine();  
  
  // Add a handler for the AudioSignalProblemOccurred event.  
  sre.AudioSignalProblemOccurred += new EventHandler<AudioSignalProblemOccurredEventArgs>(sre_AudioSignalProblemOccurred);  
}  
  
// Gather information when the AudioSignalProblemOccurred event is raised.  
void sre_AudioSignalProblemOccurred(object sender, AudioSignalProblemOccurredEventArgs e)  
{  
  StringBuilder details = new StringBuilder();  
  
  details.AppendLine("Audio signal problem information:");  
  details.AppendFormat(  
    " Audio level:               {0}" + Environment.NewLine +  
    " Audio position:            {1}" + Environment.NewLine +  
    " Audio signal problem:      {2}" + Environment.NewLine +  
    " Recognition engine audio position: {3}" + Environment.NewLine,  
    e.AudioLevel, e.AudioPosition,  e.AudioSignalProblem,  
    e.RecognizerAudioPosition);  
  
  // Insert additional event handler code here.  
}  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.AudioSignalProblem" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.AudioSignalProblemOccurred" />
  </Docs>
  <Members>
    <Member MemberName="AudioLevel">
      <MemberSignature Language="C#" Value="public int AudioLevel { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance int32 AudioLevel" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioLevel" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioLevel As Integer" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property int AudioLevel { int get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioLevel : int" Usage="System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioLevel" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Int32</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>イベントに関連付けられているオーディオ レベルを取得します。</summary>
        <value>オーディオのレベルを入力ときに、 <c>AudioSignalProblemOccurred</c>イベントが発生しました。</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AudioPosition">
      <MemberSignature Language="C#" Value="public TimeSpan AudioPosition { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.TimeSpan AudioPosition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioPosition" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioPosition As TimeSpan" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property TimeSpan AudioPosition { TimeSpan get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioPosition : TimeSpan" Usage="System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioPosition" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.TimeSpan</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>問題の発生場所を示す、入力デバイスのオーディオ ストリーム内の位置を取得します。</summary>
        <value>入力デバイス内の位置のオーディオ ストリーム、 <c>AudioSignalProblemOccurred</c>イベントが発生しました。</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioPosition%2A>プロパティは、生成されたオーディオ ストリーム内の入力デバイスの位置を参照します。 これに対し、<xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.RecognizerAudioPosition%2A>プロパティ参照がオーディオ入力内の認識エンジンの位置。 これらの位置は、さまざまなであることができます。 詳細については、次を参照してください。[音声認識イベントを使用した](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482)します。  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="AudioSignalProblem">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.AudioSignalProblem AudioSignalProblem { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.Speech.Recognition.AudioSignalProblem AudioSignalProblem" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioSignalProblem As AudioSignalProblem" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::AudioSignalProblem AudioSignalProblem { System::Speech::Recognition::AudioSignalProblem get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioSignalProblem : System.Speech.Recognition.AudioSignalProblem" Usage="System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.AudioSignalProblem</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>オーディオ信号の問題を取得します。</summary>
        <value>オーディオ信号の問題の原因となった、 <c>AudioSignalProblemOccurred</c>イベントが発生します。</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="RecognizerAudioPosition">
      <MemberSignature Language="C#" Value="public TimeSpan RecognizerAudioPosition { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.TimeSpan RecognizerAudioPosition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.RecognizerAudioPosition" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property RecognizerAudioPosition As TimeSpan" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property TimeSpan RecognizerAudioPosition { TimeSpan get(); };" />
      <MemberSignature Language="F#" Value="member this.RecognizerAudioPosition : TimeSpan" Usage="System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.RecognizerAudioPosition" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.TimeSpan</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>問題の発生場所を示す、認識エンジンが受け取ったオーディオ入力内の位置を取得します。</summary>
        <value>認識エンジンを受信しているときに、オーディオ入力内の位置、 <c>AudioSignalProblemOccurred</c>イベントが発生しました。</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioPosition%2A>プロパティは、生成されたオーディオ ストリーム内の入力デバイスの位置を参照します。 これに対し、<xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.RecognizerAudioPosition%2A>プロパティ参照がオーディオ入力内の認識エンジンの位置。 これらの位置は、さまざまなであることができます。 詳細については、次を参照してください。[音声認識イベントを使用した](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482)します。  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
  </Members>
</Type>